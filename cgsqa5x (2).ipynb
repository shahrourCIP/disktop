{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhRVoCaDMMxL"
   },
   "source": [
    "###**ZeyadAhmed/AraElectra-Arabic-SQuADv2-QA**\n",
    "This is a trial of mimicking zeyad's finetuning process on aubmindlab/araelectra-base-discriminator for building an arabic qa system.\n",
    "\n",
    "Zeyad provided me with two scripts:\n",
    "1. The dataset translator that converts a csv dataset file into 3 clean json files for train, val and test: https://github.com/SubaieiFatemah/Arabic-MRC/blob/main/Translator/translation2dataset.py\n",
    "\n",
    "*Note: this is my modified github script. The modification is found in lines 23-31. The modification is simply reading the csv file manually from colab instead of using an extrnal link*\n",
    "\n",
    "2. The finetuning script: https://github.com/zeyadahmed10/Arabic-MRC/blob/main/AraElectraDecoupling-ASQuADv2.ipynb\n",
    "\n",
    "*Note: I tried to modify the script as shown below in the colab file. The modification is about removing the \"plausible answers\" and \"CLS training\" parts as they are needed in his work to predict if unanswarable questions exist or not. However, I do not need those parts.*\n",
    "\n",
    "FACED ISSUES:\n",
    "1. IN DATASET SCRIPT:\n",
    "\n",
    "A. The dataset is small. Solved: increase dataset\n",
    "\n",
    "B. There is no clear way of how to exactly write the questions and answers but the start of the answer MUST ALWAYS be the exact same of the ground truth found in the context to be able to get the answer start and end correctly. Solved: make them always matching\n",
    "\n",
    "C. Yes/No answers cause some complications when it comes to getting the answer start as the \"yes\" and \"no\" are NOT found in the conext. Solved: eliminate the yes/no part then get the answer start\n",
    "\n",
    "D. Can the context be simply the answers gathered? or should it have more side information? Solved: yes it can simply be the answers gathered\n",
    "\n",
    "E. What comes first? Building the contexts or the questions? I saw how SQUAD v1 and v2 were developed and it was building the context first then extracting possible answers. Solved: context comes first from the CGS guidlines pdf file\n",
    "\n",
    "F. how big can a context be as in how many answers can it have inside of it? There is truncation and batching so clearly there is a limit. How to know what is the limit? for now I have a single context has answers for 60 questions. Solved: for a single context, the context, question and answer MUST all be 512 tokens AFTER tokenization. Thus, keep the contexts, questions and answers as short as possible\n",
    "\n",
    "\n",
    "2. IN FINETUNING SCRIPT:\n",
    "\n",
    "A. I tried to run the finetuning script with the CLS part included on 60 questions and got the acc=100 and exact=0.0. why? is this overfitting? or is the dataset too small? Solved: do finetuning on zeyad's code not araelectra and increase the dataset size\n",
    "\n",
    "B. I tried to run the script again after removing the CLS code blocks and got excat=0.0. i removed it because my dataset is about guidlines and there will always be answers for every question in my dataset. again why zero? is it because the dataset is small? or maybe i messed up the code by removing some parts of it? Solved: the code is the same even after removing the CLS parts and the solution is to do finetuning on zeyad's code not araelectra and increase the dataset size\n",
    "\n",
    "C. at worst cases can i leave the CLS parts and consider it as a good practice? yes it can be left as is. \n",
    "\n",
    "D. How can I finetune ZEYAD'S work and not ARAELECTRA only? I cannot contact zeyad for a month or so because he is on his military service and has no communications. Solved: the code has the modifications in \"Running Zeyad's finetuning script on my own dataset - (WITHOUT CLS PARTS)\"\n",
    "\n",
    "E. Running zeyad's original script on his original dataset consumes almost all my ram. Solved: zeyas used a huge dataset: 200k for training and 9.6k for val and 9.6k for test. my dataset is small and will not consume ram. \n",
    "\n",
    "F. why is he using span train and train datasets? what is the difference? as i've seen in the code span train is for the dataset training and train is for cls training? Solved: yes. the span train is the training of the dataset. the other parts are deleted. \n",
    "\n",
    "G. why is repeating the training process in this way? why didnt he use a loop? he kept injecting the output parameters from one code line into the other. Solved: he used the free colab version and that didnt allow him to train the huge dataset he has in one shot. he had to do it on multiple steps. however, my dataset is small thus, the extra steps are deleted. \n",
    "\n",
    "\n",
    "H. if i want my finetuning process to also include a kuwaiti dialect what should i do? will the script still be able to train the model properly if the whole dataset was in kuwaiti dialect? i mean the modification is only going to be on the dataset level? Solved: No. I need to retrain the whole model for adding new vocab and I must refer to the araelectra original paper to do so\n",
    "\n",
    "\n",
    "I. what is the difference between the functions get raw preds, post raw preds, get preds, get preds 2? Solved: this is a matter of preprocessing the output of the model from token number to strings and some post processing. I don't need to worry about it and I can build my own training script and pre/post-processing (these notebook wasn't meant to be a reference but only for creating state of art model in arabic qa so don't worry about all the details)\n",
    "\n",
    "\n",
    "J. why use both the freeze method and the .from_pretrained() together? i mean isn't .from_pretrained() alone is sufficient to load the model with its trained weights? or does this mean we don't want the previous model weights to be modified while the finetuning process? i don't even know if ALL the weights change during the finetuning process? and how to decide until which layer we want to freeze? i believe u did 6 layers freeze? Solved: simply he did a lot of experiment in different notebooks also uploaded and referring to literature he used the recommended hyperparameter and freezing 6 layers worked for him, If he loaded the data using from_pretrained without freezing the finetuning will be on the whole model not only the last 6 layers and the output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUbivkUqLGco"
   },
   "source": [
    "##**Remaining Questions**\n",
    "1. Should the dataset include the extra diacritics as in hamzah (أ إ آ) or (ة ه)?\n",
    "\n",
    "2. Should the QUESTION start be included in the ANSWER start? \n",
    "Example:\n",
    "\n",
    "Q: متى يمكن للاساتذة والاساتذة المشاركين المتقاعدين ان يشرفوا على رسائل واطروحات طلبة الدراسات العليا؟ \n",
    "\n",
    "\n",
    "A: *يمكن للاساتذة والاساتذة المشاركين المتقاعدين ان يشرفوا على رسائل واطروحات طلبة الدراسات العليا* شريطة عدم ارتباطهم بعقد عمل مع جامعة اخرى\n",
    "\n",
    "\n",
    "Should i always include the bold part in the answer? Although the answer is what comes after it? Because most of the times it is wordy and i need to keep the answer as short as possibsle (10-20) tokens\n",
    "\n",
    "3. Should i have question marks in the questions column? Or it doesn't matter? \n",
    "\n",
    "4. what if the answer to the question contains a hyperlink?\n",
    "example:\n",
    "\n",
    "Q: ما هو الموقع الالكتروني لكلية الدراسات العليا؟\n",
    "\n",
    "A: الموقع الالكتروني لكلية الدراسات العليا هو www.somelink.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfoSwdpsIcuM"
   },
   "source": [
    "### **Installing dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mD0Vez1JMYx7",
    "outputId": "e81748d6-65f2-4798-cb59-a4b5e2f81213"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.27.4\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting preprocess\n",
      "  Downloading preprocess-2.0.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from preprocess) (0.18.3)\n",
      "Installing collected packages: preprocess\n",
      "Successfully installed preprocess-2.0.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting arabert\n",
      "  Downloading arabert-1.0.1-py3-none-any.whl (179 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting PyArabic\n",
      "  Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting farasapy\n",
      "  Downloading farasapy-0.0.14-py3-none-any.whl (11 kB)\n",
      "Collecting emoji==1.4.2\n",
      "  Downloading emoji-1.4.2.tar.gz (184 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.0/185.0 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from farasapy->arabert) (4.65.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from farasapy->arabert) (2.27.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from PyArabic->arabert) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->farasapy->arabert) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->farasapy->arabert) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->farasapy->arabert) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->farasapy->arabert) (2.0.12)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186471 sha256=75d4de735191934189d0a896a464bd33e7513de6f64fff3bd560293c57eeef30\n",
      "  Stored in directory: /root/.cache/pip/wheels/ee/58/81/7879ea1b221a12a46054c29da10a2330bc0dde51d5fb9a6b2b\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji, PyArabic, farasapy, arabert\n",
      "Successfully installed PyArabic-0.6.15 arabert-1.0.1 emoji-1.4.2 farasapy-0.0.14\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n",
      "Collecting dill<0.3.7,>=0.3.0\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.10.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.11.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install preprocess\n",
    "!pip install arabert\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EHDXGMxGHpS"
   },
   "source": [
    "### **Running Zeyad's dataset script on my own dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wkKryTgpz2-E",
    "outputId": "023e0777-1da9-46bd-b3cc-f91e88fac9e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           title  \\\n",
      "0     تنظيم كلية الدراسات العليا   \n",
      "1     تنظيم كلية الدراسات العليا   \n",
      "2     تنظيم كلية الدراسات العليا   \n",
      "3     تنظيم كلية الدراسات العليا   \n",
      "4     تنظيم كلية الدراسات العليا   \n",
      "...                          ...   \n",
      "1499                 أسئلة شائعة   \n",
      "1500                 أسئلة شائعة   \n",
      "1501                 أسئلة شائعة   \n",
      "1502                 أسئلة شائعة   \n",
      "1503                 أسئلة شائعة   \n",
      "\n",
      "                                                context  \\\n",
      "0     رسالة كلية الدراسات العليا هي العمل المخطط اله...   \n",
      "1     رسالة كلية الدراسات العليا هي العمل المخطط اله...   \n",
      "2     رسالة كلية الدراسات العليا هي العمل المخطط اله...   \n",
      "3     رسالة كلية الدراسات العليا هي العمل المخطط اله...   \n",
      "4     رسالة كلية الدراسات العليا هي العمل المخطط اله...   \n",
      "...                                                 ...   \n",
      "1499  يكون موعد التقديم على كلية الدراسات العليا عاد...   \n",
      "1500  يكون موعد التقديم على كلية الدراسات العليا عاد...   \n",
      "1501  يكون موعد التقديم على كلية الدراسات العليا عاد...   \n",
      "1502  يكون موعد التقديم على كلية الدراسات العليا عاد...   \n",
      "1503  يكون موعد التقديم على كلية الدراسات العليا عاد...   \n",
      "\n",
      "                                question  \\\n",
      "0      ما هي رسالة كلية الدراسات العليا؟   \n",
      "1       ما هي غاية كلية الدراسات العليا؟   \n",
      "2      ما هي أهداف كلية الدراسات العليا؟   \n",
      "3       ما هي مهام كلية الدراسات العليا؟   \n",
      "4     ما هي واجبات كلية الدراسات العليا؟   \n",
      "...                                  ...   \n",
      "1499                 ما هو عنوان البريد؟   \n",
      "1500              ما هو العنوان البريدي؟   \n",
      "1501                ما هو الرمز البريدي؟   \n",
      "1502              ما معنى الرمز البريدي؟   \n",
      "1503             أين يوجد الرمز البريدي؟   \n",
      "\n",
      "                                                 answer  answer_start  \\\n",
      "0     العمل المخطط الهادف الى المساهمة في تنمية إمكا...            30   \n",
      "1                                       اتاحة فرص تعليم           159   \n",
      "2                                       اتاحة فرص تعليم           159   \n",
      "3       الموافقة على برامج الدراسات العليا ووضع الأنظمة           278   \n",
      "4       الموافقة على برامج الدراسات العليا ووضع الأنظمة           278   \n",
      "...                                                 ...           ...   \n",
      "1499            اسم المنطقة التي يتواجد بها مكتب البريد         12310   \n",
      "1500            اسم المنطقة التي يتواجد بها مكتب البريد         12310   \n",
      "1501                      رقم خاص يرمز الى بريد المنطقة         12368   \n",
      "1502                      رقم خاص يرمز الى بريد المنطقة         12368   \n",
      "1503                                 ويوجد على الانترنت         12398   \n",
      "\n",
      "      is_impossible  count                        ID  \n",
      "0             False      1  56be85543aeaaa14008c9063  \n",
      "1             False      2  56be85543aeaaa14008c9065  \n",
      "2             False      3  56be85543aeaaa14008c9066  \n",
      "3             False      4  56bf6b0f3aeaaa14008c9601  \n",
      "4             False      5  56bf6b0f3aeaaa14008c9602  \n",
      "...             ...    ...                       ...  \n",
      "1499          False   1500  56cc5fd66d243a140015ef53  \n",
      "1500          False   1501  56cc5fd66d243a140015ef54  \n",
      "1501          False   1502  56cccb3c62d2951400fa64be  \n",
      "1502          False   1503  56cccb3c62d2951400fa64bf  \n",
      "1503          False   1504  56cccb3c62d2951400fa64c0  \n",
      "\n",
      "[1504 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from arabert.preprocess import ArabertPreprocessor\n",
    "import pandas as pd\n",
    "df = pd.read_csv('cgsqa5x.csv')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hvYiCuKQyjFe",
    "outputId": "ea0a53d3-4f5f-41e0-fe46-a531c60d8a72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Arabic-MRC'...\n",
      "remote: Enumerating objects: 461, done.\u001b[K\n",
      "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
      "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
      "remote: Total 461 (delta 15), reused 0 (delta 0), pack-reused 424\u001b[K\n",
      "Receiving objects: 100% (461/461), 47.27 MiB | 24.74 MiB/s, done.\n",
      "Resolving deltas: 100% (215/215), done.\n",
      "Updating files: 100% (53/53), done.\n"
     ]
    }
   ],
   "source": [
    "!rm -r Arabic-MRC\n",
    "!git clone https://github.com/SubaieiFatemah/Arabic-MRC/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qV99sGp4eWC",
    "outputId": "e7e51fa1-3fc7-48f4-f653-d0e24778a90a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1504, 8)\n",
      "Index(['title', 'context', 'question', 'answer', 'answer_start',\n",
      "       'is_impossible', 'count', 'ID'],\n",
      "      dtype='object')\n",
      "(1504, 8)\n",
      "(902, 8) (301, 8) (301, 8)\n"
     ]
    }
   ],
   "source": [
    "!python /content/Arabic-MRC/Translator/translation2dataset.py \\\n",
    "#after running this cell cgsqa5x.csv is splitted into /content/asquadv2-train.json /content/asquadv2-val.json /content/asquadv2-test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IK8V9AAB_IlR"
   },
   "source": [
    "### **Running Zeyad's finetuning script on my own dataset - (WITHOUT CLASSIFICATION)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o24il6kUM8o-",
    "outputId": "fe9fcf60-25e5-4147-d7f2-6b71c257e080"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff43f086b90>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, ElectraForQuestionAnswering, DataCollatorWithPadding,BertModel, ElectraForSequenceClassification, ElectraModel\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "torch.manual_seed(3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "id": "GWLo7JZKU0Wo"
   },
   "outputs": [],
   "source": [
    "def add_end_index(answer, context):\n",
    "  ## 1 if span match the context 0 otherwise\n",
    "  text = answer['text']\n",
    "  start_idx = answer['answer_start']\n",
    "  end_idx = start_idx + len(text)\n",
    "  answer['answer_end'] = end_idx\n",
    "  if text == context[start_idx:end_idx]:\n",
    "    answer['answer_end'] = end_idx\n",
    "    return False\n",
    "  for i in range(1,3):\n",
    "    if text == context[start_idx-i:end_idx-i]:\n",
    "      answer['answer_end']= end_idx-1\n",
    "      answer['answer_start'] = start_idx-1\n",
    "      return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "LvQfFMm_VJ8q"
   },
   "outputs": [],
   "source": [
    "def arabert_preprocess(context,question, answer, arabert_prep):\n",
    "    answer['text'] = arabert_prep.preprocess(answer['text'])\n",
    "    context = arabert_prep.preprocess(context)\n",
    "    question = arabert_prep.preprocess(question)\n",
    "    res = context.find(answer['text'])\n",
    "    if res !=-1:\n",
    "        answer['answer_start'] = res\n",
    "    return context, question, answer, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "qlXKCKLSVMTg"
   },
   "outputs": [],
   "source": [
    "def Read_AAQAD(path,arabert_prep):\n",
    "  contexts =[]\n",
    "  answers =[]\n",
    "  questions =[]\n",
    "  IDs= []\n",
    "  plausible = []\n",
    "  cnt = 0\n",
    "  with open(path) as f:\n",
    "    aaqad_dict = json.load(f)\n",
    "    for article in aaqad_dict['data']:\n",
    "      for passage in article['paragraphs']:\n",
    "        context = passage['context']\n",
    "        for qa in passage['qas']:\n",
    "          question = qa['question']\n",
    "          if 'plausible_answers' in qa.keys():# there is two cases if the question have no answer then use plausible answer\n",
    "            access = 'plausible_answers'\n",
    "            plausible.append(True)\n",
    "          else:\n",
    "            access = 'answers'\n",
    "            plausible.append(False)\n",
    "          for answer in qa[access]:\n",
    "            context,question, answer, res =  arabert_preprocess(context,question, answer, arabert_prep)\n",
    "            #if res==-1:\n",
    "            #  cnt+=1\n",
    "            #  continue\n",
    "            flag = add_end_index(answer, context) #if false dont add the \n",
    "            cnt =cnt + flag\n",
    "            flag = False\n",
    "            if not flag:\n",
    "              contexts.append(context)\n",
    "              answers.append(answer)\n",
    "              questions.append(question)\n",
    "              IDs.append(int(qa['id']))\n",
    "  return contexts,questions,answers,plausible,IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfolZyF6Vehp"
   },
   "source": [
    "why fix them? can i directly use those ids and del id col in original csv?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "5AqMfw46VaFr"
   },
   "outputs": [],
   "source": [
    "def fix_ids(path):\n",
    "  #IDs need to be fixed for evaluating purposes\n",
    "    a_file = open(path, \"r\")\n",
    "    json_object = json.load(a_file)\n",
    "    a_file.close()\n",
    "    idx_cnt = 1\n",
    "    for article in json_object['data']:\n",
    "      for passage in article['paragraphs']:\n",
    "        context = passage['context']\n",
    "        for qa in passage['qas']:\n",
    "            qa['id'] = str(idx_cnt)\n",
    "            idx_cnt = idx_cnt + 1\n",
    "    a_file = open(path, \"w\")\n",
    "    json.dump(json_object, a_file)\n",
    "    a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "6gbHbeWsVlyj"
   },
   "outputs": [],
   "source": [
    "model_name = \"araelectra-base-discriminator\"\n",
    "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
    "fix_ids('/content/asquadv2-train.json')\n",
    "fix_ids('/content/asquadv2-val.json')\n",
    "fix_ids('/content/asquadv2-test.json')\n",
    "asquad_train_contexts, asquad_train_questions, asquad_train_answers,asquad_train_plausible, asquad_train_ids = Read_AAQAD('/content/asquadv2-train.json', arabert_prep)\n",
    "asquad_val_contexts, asquad_val_questions, asquad_val_answers,asquad_val_plausible, asquad_val_ids = Read_AAQAD('/content/asquadv2-val.json', arabert_prep)\n",
    "asquad_test_contexts, asquad_test_questions, asquad_test_answers,asquad_test_plausible, asquad_test_ids = Read_AAQAD('/content/asquadv2-test.json', arabert_prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nl_hVIUuSRW"
   },
   "source": [
    "google Semantic Search — Sentence-Transformers documentation (sbert.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_c-ykyDiVu0I",
    "outputId": "68a0e3db-63a5-4467-c051-dce01319aad6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1504"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(asquad_test_answers)+len(asquad_train_answers)+len(asquad_val_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzajqxVIV4D4",
    "outputId": "4165b0b9-130c-41e6-b069-69e83ae0f047"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(sum(asquad_train_ids)==len(asquad_train_ids)*(len(asquad_train_ids)+1)/2)\n",
    "print(sum(asquad_val_ids)==len(asquad_val_ids)*(len(asquad_val_ids)+1)/2)\n",
    "print(sum(asquad_test_ids)==len(asquad_test_ids)*(len(asquad_test_ids)+1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "id": "nnVObCLCV-Se"
   },
   "outputs": [],
   "source": [
    "def get_answered_feat(contexts, questions, answers, plausible):\n",
    "    new_contexts, new_questions, new_answers = [], [], []\n",
    "    for i in range(len(answers)):\n",
    "        if plausible[i] == False:\n",
    "            new_contexts.append(contexts[i])\n",
    "            new_questions.append(questions[i])\n",
    "            new_answers.append(answers[i])\n",
    "    return new_contexts, new_questions, new_answers\n",
    "span_train_contexts, span_train_questions, span_train_answers = get_answered_feat(asquad_train_contexts, asquad_train_questions, asquad_train_answers, asquad_train_plausible)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "szo3C86vWS_A",
    "outputId": "d11caa31-4253-42ff-aec5-9027ac651f3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902 902\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(span_train_contexts), len(asquad_train_contexts))\n",
    "print(sum(asquad_test_plausible)) #del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "p0DXY1ETWax6"
   },
   "outputs": [],
   "source": [
    "#Creating the tokenizer\n",
    "model_name =  \"aubmindlab/araelectra-base-discriminator\"\n",
    "araelectra_tokenizer = AutoTokenizer.from_pretrained(model_name,do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "cFq9dGn2WnKP"
   },
   "outputs": [],
   "source": [
    "span_train_encodings = araelectra_tokenizer(span_train_questions, span_train_contexts, truncation=True)\n",
    "val_encodings = araelectra_tokenizer(asquad_val_questions, asquad_val_contexts, truncation=True, return_offsets_mapping=True)\n",
    "test_encodings = araelectra_tokenizer(asquad_test_questions, asquad_test_contexts, truncation=True,  return_offsets_mapping=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDSW1eU3W2W8"
   },
   "source": [
    "why del cols?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "id": "XkxEVNOZWuSI"
   },
   "outputs": [],
   "source": [
    "val_offset = val_encodings['offset_mapping']\n",
    "del val_encodings['offset_mapping']\n",
    "test_offset = test_encodings['offset_mapping']\n",
    "del test_encodings['offset_mapping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FiMBHVBTW1o9",
    "outputId": "ae6e8d32-9cc6-464b-9ac4-21d3ca7a24f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16, 18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24, 26: 25, 27: 26, 28: 27, 29: 28, 30: 29, 31: 30, 32: 31, 33: 32, 34: 33, 35: 34, 36: 35, 37: 36, 38: 37, 39: 38, 40: 39, 41: 40, 42: 41, 43: 42, 44: 43, 45: 44, 46: 45, 47: 46, 48: 47, 49: 48, 50: 49, 51: 50, 52: 51, 53: 52, 54: 53, 55: 54, 56: 55, 57: 56, 58: 57, 59: 58, 60: 59, 61: 60, 62: 61, 63: 62, 64: 63, 65: 64, 66: 65, 67: 66, 68: 67, 69: 68, 70: 69, 71: 70, 72: 71, 73: 72, 74: 73, 75: 74, 76: 75, 77: 76, 78: 77, 79: 78, 80: 79, 81: 80, 82: 81, 83: 82, 84: 83, 85: 84, 86: 85, 87: 86, 88: 87, 89: 88, 90: 89, 91: 90, 92: 91, 93: 92, 94: 93, 95: 94, 96: 95, 97: 96, 98: 97, 99: 98, 100: 99, 101: 100, 102: 101, 103: 102, 104: 103, 105: 104, 106: 105, 107: 106, 108: 107, 109: 108, 110: 109, 111: 110, 112: 111, 113: 112, 114: 113, 115: 114, 116: 115, 117: 116, 118: 117, 119: 118, 120: 119, 121: 120, 122: 121, 123: 122, 124: 123, 125: 124, 126: 125, 127: 126, 128: 127, 129: 128, 130: 129, 131: 130, 132: 131, 133: 132, 134: 133, 135: 134, 136: 135, 137: 136, 138: 137, 139: 138, 140: 139, 141: 140, 142: 141, 143: 142, 144: 143, 145: 144, 146: 145, 147: 146, 148: 147, 149: 148, 150: 149, 151: 150, 152: 151, 153: 152, 154: 153, 155: 154, 156: 155, 157: 156, 158: 157, 159: 158, 160: 159, 161: 160, 162: 161, 163: 162, 164: 163, 165: 164, 166: 165, 167: 166, 168: 167, 169: 168, 170: 169, 171: 170, 172: 171, 173: 172, 174: 173, 175: 174, 176: 175, 177: 176, 178: 177, 179: 178, 180: 179, 181: 180, 182: 181, 183: 182, 184: 183, 185: 184, 186: 185, 187: 186, 188: 187, 189: 188, 190: 189, 191: 190, 192: 191, 193: 192, 194: 193, 195: 194, 196: 195, 197: 196, 198: 197, 199: 198, 200: 199, 201: 200, 202: 201, 203: 202, 204: 203, 205: 204, 206: 205, 207: 206, 208: 207, 209: 208, 210: 209, 211: 210, 212: 211, 213: 212, 214: 213, 215: 214, 216: 215, 217: 216, 218: 217, 219: 218, 220: 219, 221: 220, 222: 221, 223: 222, 224: 223, 225: 224, 226: 225, 227: 226, 228: 227, 229: 228, 230: 229, 231: 230, 232: 231, 233: 232, 234: 233, 235: 234, 236: 235, 237: 236, 238: 237, 239: 238, 240: 239, 241: 240, 242: 241, 243: 242, 244: 243, 245: 244, 246: 245, 247: 246, 248: 247, 249: 248, 250: 249, 251: 250, 252: 251, 253: 252, 254: 253, 255: 254, 256: 255, 257: 256, 258: 257, 259: 258, 260: 259, 261: 260, 262: 261, 263: 262, 264: 263, 265: 264, 266: 265, 267: 266, 268: 267, 269: 268, 270: 269, 271: 270, 272: 271, 273: 272, 274: 273, 275: 274, 276: 275, 277: 276, 278: 277, 279: 278, 280: 279, 281: 280, 282: 281, 283: 282, 284: 283, 285: 284, 286: 285, 287: 286, 288: 287, 289: 288, 290: 289, 291: 290, 292: 291, 293: 292, 294: 293, 295: 294, 296: 295, 297: 296, 298: 297, 299: 298, 300: 299, 301: 300}\n"
     ]
    }
   ],
   "source": [
    "val_ids_to_idx = {k:i for i,k in enumerate(asquad_val_ids)}\n",
    "test_ids_to_idx = {k:i for i,k in enumerate(asquad_test_ids)}\n",
    "print(val_ids_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "id": "GphTakdxW_H7"
   },
   "outputs": [],
   "source": [
    "def index_to_token_position(encodings , answers):\n",
    "  start_positions = list()\n",
    "  end_positions = list()\n",
    "  for i in range(len(answers)):\n",
    "    start_positions.append(encodings.char_to_token(i, answers[i]['answer_start'], 1))\n",
    "    end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'], 1))\n",
    "    #if context truncated\n",
    "    if start_positions[-1] is None: \n",
    "      start_positions[-1] = araelectra_tokenizer.model_max_length\n",
    "    #if end index is space\n",
    "    itt = 1\n",
    "    while end_positions[-1] is None: \n",
    "      end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end']-itt, 1)\n",
    "      itt = itt + 1 \n",
    "  encodings.update({'start_positions': torch.tensor(start_positions), 'end_positions': torch.tensor(end_positions)})\n",
    "  encodings['start_positions'] = encodings['start_positions'].view(len(answers), 1)\n",
    "  encodings['end_positions'] = encodings['end_positions'].view(len(answers), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "lLNsPC_BXHn7"
   },
   "outputs": [],
   "source": [
    "index_to_token_position(span_train_encodings, span_train_answers)\n",
    "index_to_token_position(val_encodings, asquad_val_answers)\n",
    "index_to_token_position(test_encodings, asquad_test_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzRXkFoBXd7w"
   },
   "source": [
    "needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "id": "uaIoLi5LXLTI"
   },
   "outputs": [],
   "source": [
    "val_encodings['IDs'] = asquad_val_ids\n",
    "test_encodings['IDs'] = asquad_test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3clGE_xvXcy9",
    "outputId": "94e810c4-13fe-40cd-bf8b-aaf74cef16a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions', 'IDs'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions', 'IDs'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])\n"
     ]
    }
   ],
   "source": [
    "print(val_encodings.keys())\n",
    "print(test_encodings.keys())\n",
    "print(span_train_encodings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "id": "wCoKFHMhXlEi"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "id": "mYHBD6WgXw2Z"
   },
   "outputs": [],
   "source": [
    "class AqadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: val[idx] for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "span_train_dataset = AqadDataset(span_train_encodings)\n",
    "val_dataset = AqadDataset(val_encodings)\n",
    "test_dataset = AqadDataset(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "id": "uTepeinsX9KV"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(araelectra_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "id": "zH9qwvYxYIsd"
   },
   "outputs": [],
   "source": [
    "span_train_loader = DataLoader(span_train_dataset, batch_size=8, shuffle= True, collate_fn = data_collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 8, shuffle = True, collate_fn = data_collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 8, shuffle = True, collate_fn = data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "id": "LsekdnhgYMIa"
   },
   "outputs": [],
   "source": [
    "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
    "    \"\"\"\n",
    "    state: checkpoint to save\n",
    "    is_best: is this the best checkpoint; min validation loss\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    best_model_path: path to save best checkpoint\n",
    "    \"\"\"\n",
    "    f_path = checkpoint_path\n",
    "    # save checkpoint data to the path given, checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    # if it is a best model, min validation loss\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        # copy that checkpoint file to best path given, best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "id": "K1fclfTzYUwy"
   },
   "outputs": [],
   "source": [
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    \"\"\"\n",
    "    checkpoint_path: path to saved checkpoint\n",
    "    model: model to load checkpoint parameters into       \n",
    "    optimizer: optimizer defined in previous training\n",
    "    \"\"\"\n",
    "    # load check point\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    # initialize state_dict from checkpoint to model\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    # initialize optimizer from checkpoint to optimizer\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
    "    results = checkpoint['result_dict']\n",
    "    # return model, optimizer, epoch value, min validation loss \n",
    "    return model, optimizer, checkpoint['epoch'], results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "id": "eESoiGQVYcTL"
   },
   "outputs": [],
   "source": [
    "def order_exp(base_path, exp_name):\n",
    "  exp_path = os.path.join(base_path, exp_name)\n",
    "  if not os.path.exists(exp_path):\n",
    "    os.mkdir(exp_path)\n",
    "  curr_ckp_path = os.path.join(exp_path,'curr.pt')\n",
    "  best_ckp_path = os.path.join(exp_path, 'best.pt')\n",
    "  return curr_ckp_path, best_ckp_path, exp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "id": "dLPYIvZu4MzW"
   },
   "outputs": [],
   "source": [
    "model_name1=\"ZeyadAhmed/AraElectra-Arabic-SQuADv2-QA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "id": "FjbLrSRKYkhe"
   },
   "outputs": [],
   "source": [
    "QA_AraElectra = ElectraForQuestionAnswering.from_pretrained(model_name1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "id": "4-_GoSyiYspA"
   },
   "outputs": [],
   "source": [
    "def freeze(Electra, count=None):\n",
    "    if count is not None:\n",
    "\t      # We freeze here the embeddings of the model\n",
    "        for param in Electra.embeddings.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        if count != -1:\n",
    "\t          # if freeze_layer_count == -1, we only freeze the embedding layer\n",
    "\t          # otherwise we freeze the first `freeze_layer_count` encoder layers\n",
    "            for layer in Electra.encoder.layer[:count]:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False\n",
    "    print(sum(p.numel() for p in Electra.parameters()), sum(p.numel() for p in Electra.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wRpvmx93Yzja",
    "outputId": "4fef89a4-4d1f-49f6-e886-089e04649bd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134602752 42527232\n"
     ]
    }
   ],
   "source": [
    "freeze(QA_AraElectra.electra, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "id": "jUuwIeEwZgXq"
   },
   "outputs": [],
   "source": [
    "def get_raw_preds(data_loader, model,ids_to_index,offset,contexts, max_answer_length, n_best_size): \n",
    "  model.eval()\n",
    "  imd_predictions,script_predictions = dict(), dict()\n",
    "  with torch.no_grad():\n",
    "    #F1 = EM = Total = 0\n",
    "    total_loss = 0.0\n",
    "    total_predictions = dict()\n",
    "    no_probs_pred = dict()\n",
    "    #loop = tqdm(data_loader)\n",
    "    loop = tqdm(data_loader, leave=True)\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "      tokens = batch['input_ids'].to(device)\n",
    "      masks = batch['attention_mask'].to(device)\n",
    "      tokens_type = batch['token_type_ids'].to(device)\n",
    "      gt_start = batch['start_positions'].to(device)\n",
    "      gt_end = batch['end_positions'].to(device)\n",
    "      IDs = batch['IDs'].to(device)\n",
    "      outputs = model(tokens, masks, tokens_type, start_positions=gt_start, end_positions=gt_end)\n",
    "      #calculating loss\n",
    "      loss = outputs.loss\n",
    "      #update average total loss \n",
    "      total_loss = total_loss + ((1 / (batch_idx + 1)) * (loss.item() - total_loss)) \n",
    "      #calculating f1 score and EM\n",
    "      curr_batch_size = tokens.shape[0]\n",
    "      post_raw_preds(IDs, outputs.start_logits, outputs.end_logits, ids_to_index, offset, contexts,max_answer_length, n_best_size, imd_predictions, script_predictions )\n",
    "    #saving evaluation results\n",
    "    #evaluation\n",
    "\n",
    "    model.train()\n",
    "    return imd_predictions,script_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "id": "vh-qfzOWZh9Y"
   },
   "outputs": [],
   "source": [
    "def post_raw_preds(IDs, total_start_logits, total_end_logits,ids_to_index,offset,contexts, max_answer_length, n_best_size,\n",
    " imd_predictions,script_predictions ):\n",
    "    total_start_logits = total_start_logits.cpu().numpy()\n",
    "    total_end_logits = total_end_logits.cpu().numpy()\n",
    "    IDs = IDs.cpu().numpy()\n",
    "    for i in range(IDs.shape[0]):\n",
    "        offset_mapping = offset[ids_to_index[IDs[i].squeeze()]]\n",
    "        # The first feature comes from the first example. For the more general case, we will need to be match the example_id to\n",
    "        # an example index\n",
    "        context = contexts[ids_to_index[IDs[i].squeeze()]]\n",
    "        start_logits = total_start_logits[i]\n",
    "        end_logits = total_end_logits[i]\n",
    "        # Gather the indices the best start/end logits:\n",
    "        start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "        end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "        valid_answers = []\n",
    "        for start_index in start_indexes:\n",
    "            for end_index in end_indexes:\n",
    "                # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
    "                # to part of the input_ids that are not in the context.\n",
    "                if (\n",
    "                    start_index >= len(offset_mapping)\n",
    "                    or end_index >= len(offset_mapping)\n",
    "                    or offset_mapping[start_index] is None\n",
    "                    or offset_mapping[end_index] is None\n",
    "                ):\n",
    "                    continue\n",
    "                # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
    "                if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                    continue\n",
    "                if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char: end_char]\n",
    "                        }\n",
    "                    )\n",
    "        if len(valid_answers) ==0:\n",
    "            valid_answers.append({\"text\":\"\", \"score\":\"\"})\n",
    "\n",
    "        valid_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        imd_predictions[str(IDs[i].squeeze())] = valid_answer\n",
    "        script_predictions[str(IDs[i].squeeze())] = valid_answer['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "id": "9cSCRZCbZqLm"
   },
   "outputs": [],
   "source": [
    "def get_preds(total_preds, no_probs_preds,data_path, log_path):\n",
    "    preds_path = os.path.join(log_path, 'preds')\n",
    "    if not os.path.exists(preds_path):\n",
    "        os.mkdir(preds_path)\n",
    "    text_preds_path = os.path.join(preds_path, 'preds.json')\n",
    "    jsonString = json.dumps(total_preds)\n",
    "    jsonFile = open(text_preds_path, \"w\")\n",
    "    jsonFile.write(jsonString)\n",
    "    jsonFile.close()\n",
    "    \n",
    "    !python /content/Arabic-MRC/evaluatev2.py /content/asquadv2-val.json /content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth/preds/preds.json electra  --out-file /content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth\n",
    "    if log_path:\n",
    "        with open(os.path.join(log_path, 'res.csv')) as f:\n",
    "            DictReader_obj = csv.DictReader(f)\n",
    "            lastrow = None\n",
    "            for item in DictReader_obj:\n",
    "                lastrow = dict(item)\n",
    "        #print(lastrow)\n",
    "        return lastrow\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "id": "R3zJBeMGZy_w"
   },
   "outputs": [],
   "source": [
    "def span_train(model,start_epoch, num_epochs, optimizer,max_compined_metric, train_loader, val_loader, log, exp_name):\n",
    "  curr_ckp_path, best_ckp_path, exp_path = order_exp('/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span', exp_name)\n",
    "  model.train()\n",
    "  for epoch in range(start_epoch,num_epochs):\n",
    "    total_loss = 0.0\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "      tokens = batch['input_ids'].to(device)\n",
    "      masks = batch['attention_mask'].to(device)\n",
    "      tokens_type = batch['token_type_ids'].to(device)\n",
    "      gt_start = batch['start_positions'].to(device)\n",
    "      gt_end = batch['end_positions'].to(device)\n",
    "      outputs = model(tokens, masks, tokens_type, start_positions=gt_start, end_positions=gt_end)\n",
    "      loss = outputs.loss\n",
    "      loss = 2*loss\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "      total_loss = total_loss + ((1 / (batch_idx + 1)) * (loss.item() - total_loss)) \n",
    "      loop.set_description(f'Epoch {epoch}')\n",
    "      loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    imd_preds, script_preds = get_raw_preds(val_loader, model,val_ids_to_idx,val_offset,asquad_val_contexts, 30, 10)\n",
    "    result_dict = get_preds(script_preds, None,'/content/asquadv2-val.json',exp_path )\n",
    "    checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'result_dict':result_dict,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "    curr_compined_metric = float(result_dict['HasAns_exact'])+1.5*float(result_dict['HasAns_f1'])\n",
    "    if curr_compined_metric>=max_compined_metric:\n",
    "      max_compined_metric = curr_compined_metric\n",
    "      save_ckp(checkpoint, True, curr_ckp_path, best_ckp_path)\n",
    "    else:\n",
    "      save_ckp(checkpoint, False, curr_ckp_path, best_ckp_path)\n",
    "    print(\"ckp saved\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nZLnCT6pZ2ax",
    "outputId": "a42a5b32-e5c2-4d8c-f1b4-4945f9aad90b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134602752 42527232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForQuestionAnswering(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_AraElectra = ElectraForQuestionAnswering.from_pretrained(model_name1)\n",
    "freeze(QA_AraElectra.electra, 6)\n",
    "span_num_epochs = 4\n",
    "span_learning_rate = 5e-5\n",
    "span_optimizer = torch.optim.AdamW(QA_AraElectra.parameters(), lr=span_learning_rate, weight_decay=1e-5)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "#criterion_span = nn.CrossEntropyLoss(reduction='none')\n",
    "#cls_criterion = nn.CrossEntropyLoss()\n",
    "QA_AraElectra.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9zEwMnlfPl2"
   },
   "source": [
    "why says 301 for val? where is train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9w8OuZ0sZ98f",
    "outputId": "c1ceb94e-ad25-4977-bc6a-dd437501030e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/113 [00:00<?, ?it/s]You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Epoch 0: 100%|██████████| 113/113 [01:07<00:00,  1.67it/s, loss=0.697]\n",
      "100%|██████████| 38/38 [00:10<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 35.548172757475086,\n",
      "  \"f1\": 43.781352650418945,\n",
      "  \"total\": 301,\n",
      "  \"HasAns_exact\": 35.548172757475086,\n",
      "  \"HasAns_f1\": 43.781352650418945,\n",
      "  \"HasAns_total\": 301\n",
      "}\n",
      "ckp saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 113/113 [01:07<00:00,  1.68it/s, loss=1.58]\n",
      "100%|██████████| 38/38 [00:10<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 38.205980066445186,\n",
      "  \"f1\": 44.575480945816345,\n",
      "  \"total\": 301,\n",
      "  \"HasAns_exact\": 38.205980066445186,\n",
      "  \"HasAns_f1\": 44.575480945816345,\n",
      "  \"HasAns_total\": 301\n",
      "}\n",
      "ckp saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 113/113 [01:07<00:00,  1.68it/s, loss=0.457]\n",
      "100%|██████████| 38/38 [00:10<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 38.205980066445186,\n",
      "  \"f1\": 43.26380903649258,\n",
      "  \"total\": 301,\n",
      "  \"HasAns_exact\": 38.205980066445186,\n",
      "  \"HasAns_f1\": 43.26380903649258,\n",
      "  \"HasAns_total\": 301\n",
      "}\n",
      "ckp saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 113/113 [01:06<00:00,  1.69it/s, loss=0.245]\n",
      "100%|██████████| 38/38 [00:10<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 39.8671096345515,\n",
      "  \"f1\": 44.487283518712424,\n",
      "  \"total\": 301,\n",
      "  \"HasAns_exact\": 39.8671096345515,\n",
      "  \"HasAns_f1\": 44.487283518712424,\n",
      "  \"HasAns_total\": 301\n",
      "}\n",
      "ckp saved\n"
     ]
    }
   ],
   "source": [
    "span_trained_model = span_train(QA_AraElectra,0, span_num_epochs, span_optimizer,0.0, span_train_loader, val_loader, True, '/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "id": "u7KeAJ6-dfdO"
   },
   "outputs": [],
   "source": [
    "qa_model = ElectraForQuestionAnswering.from_pretrained(model_name1)\n",
    "span_learning_rate = 2e-5\n",
    "span_optimizer = torch.optim.AdamW(qa_model.parameters(), lr=span_learning_rate, weight_decay=1e-5)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "qa_model.to(device)\n",
    "qa_model , qa_optim, x, xx = load_ckp('/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth/best.pt', qa_model,span_optimizer)##why load ckp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nFBF20nQdq1_",
    "outputId": "3b48a7b7-ccc3-4ce9-8d47-e9da781c7af3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('AraElectra-ASQuADv2-QA/tokenizer_config.json',\n",
       " 'AraElectra-ASQuADv2-QA/special_tokens_map.json',\n",
       " 'AraElectra-ASQuADv2-QA/vocab.txt',\n",
       " 'AraElectra-ASQuADv2-QA/added_tokens.json',\n",
       " 'AraElectra-ASQuADv2-QA/tokenizer.json')"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_model.save_pretrained('AraElectra-ASQuADv2-QA')##-finetuned-dataset\n",
    "araelectra_tokenizer.save_pretrained('AraElectra-ASQuADv2-QA')##-finetuned-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CXDZkKSNdvzc",
    "outputId": "d144230c-224f-430d-92d1-435e90977c15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForQuestionAnswering(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_model = ElectraForQuestionAnswering.from_pretrained('AraElectra-ASQuADv2-QA') ##modify to -finetuned-dataset?\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "qa_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfhEJ48Sd7Qr",
    "outputId": "9e937773-3c81-4e71-cad3-6128e82f2682"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:10<00:00,  3.53it/s]\n"
     ]
    }
   ],
   "source": [
    "imd_preds, script_preds = get_raw_preds(test_loader, qa_model,test_ids_to_idx,test_offset,asquad_test_contexts, 30, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Uy_optmeH6L",
    "outputId": "db1d8bcc-2449-4f4d-a57f-4e889bb97d3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'52': {'score': 19.190504, 'text': 'مهمة واحدة فقط خلال مدة دراسته'}, '220': {'score': 8.223977, 'text': 'في جميع الفصول الدراسية التالية لاجتياز'}, '218': {'score': 12.757805, 'text': 'يسجل طالب الدكتوراة مقرر'}, '107': {'score': 16.165655, 'text': 'يجوز تمديدها لفصل دراسي واحد'}, '244': {'score': 8.687723, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول'}, '179': {'score': 9.295003, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع'}, '247': {'score': 8.026913, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول'}, '110': {'score': 16.04367, 'text': 'هو 2 . 67'}, '57': {'score': 16.2567, 'text': 'الاشتراك وتذاكر سفر على الدرجة السياحية وبدل سفر يومي'}, '275': {'score': 16.948566, 'text': 'عن طريق الموقع الالكتروني لكلية الدراسات العليا'}, '13': {'score': 13.614878, 'text': 'عدد ساعات الدراسة خلال'}, '188': {'score': 9.3805065, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع'}, '19': {'score': 10.163427, 'text': 'وتكون هذه المستندات مذكورة في اعلان التقديم'}, '259': {'score': 9.645008, 'text': 'يسجل طالب الدكتوراة'}, '273': {'score': 17.46599, 'text': 'يحددها مجلس الجامعة'}, '224': {'score': 7.3853674, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع'}, '49': {'score': 17.878191, 'text': '30 دينار كويتي'}, '177': {'score': 15.356236, 'text': 'ويجوز تمديدها لسنتين اضافتين'}, '255': {'score': 6.4480886, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول الدراسية'}, '77': {'score': 17.236778, 'text': 'الموافقة على برامج الدراسات العليا ووضع الأنظمة'}, '44': {'score': 12.18622, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي الواحد'}, '104': {'score': 17.747244, 'text': 'شهادة الاجازة الجامعية الاولى ومعدل عام 2 . 33 فأعلى'}, '154': {'score': 10.685237, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة'}, '249': {'score': 10.490861, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في'}, '197': {'score': 15.459213, 'text': 'مستوى 500 فاعلى'}, '4': {'score': 15.684178, 'text': 'فصلين دراسيين'}, '24': {'score': 10.784342, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي الواحد ويوجد نوعان'}, '54': {'score': 15.568612, 'text': 'في ضوء دراسة حالتهم الاجتماعية'}, '207': {'score': 7.2891746, 'text': 'في جميع الفصول الدراسية التالية لاجتياز'}, '185': {'score': 10.541199, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول'}, '169': {'score': 8.463665, 'text': 'في جميع الفصول'}, '70': {'score': 19.492151, 'text': 'الأساتذة والأساتذة المشاركين وأحيانا الأساتذة المساعدين أو المتقاعدين'}, '180': {'score': 7.574872, 'text': 'جميع الفصول الدراسية'}, '296': {'score': 7.713031, 'text': 'القانون العام والقانون الخاص والاداب والعلوم والتربية والشريعة الإسلامية وإدارة الاعمال والصحة العامة'}, '93': {'score': 15.621724, 'text': 'يجوز تمديدها لفصل دراسي واحد'}, '239': {'score': 7.2203755, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في'}, '21': {'score': 9.806254, 'text': 'الدوام'}, '268': {'score': 12.369331, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة'}, '147': {'score': 8.871487, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة'}, '245': {'score': 8.490846, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في'}, '221': {'score': 9.920551, 'text': 'في جميع الفصول الدراسية التالية لاجت'}, '242': {'score': 11.957269, 'text': 'في جميع الفصول الدراسية التالية'}, '23': {'score': 12.224514, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي الواحد'}, '251': {'score': 11.404633, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول'}, '82': {'score': 5.5475807, 'text': 'يتولى'}, '130': {'score': 7.7812767, 'text': 'في جميع الفصول الدراسية التالية'}, '83': {'score': 15.021535, 'text': 'الاشراف على برامج الدراسات العليا في الكلية ووضع القواعد التنظيمية والمقترحات'}, '161': {'score': 9.45554, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول الدراسية التالية'}, '10': {'score': 11.405549, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي'}, '231': {'score': 18.196451, 'text': 'طبيعة المشكلة ومنهجية البحث والمراجع الاساسية والامكانات اللازمة لتنفيذه'}, '300': {'score': 14.028888, 'text': 'معدل عام 3 فترة سريان المنحة'}, '6': {'score': 8.603943, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي الواحد ويوجد نوعان :'}, '170': {'score': 12.240941, 'text': 'في جميع الفصول الدراسية التالية'}, '257': {'score': 7.0722795, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول الدراسية التالية لاجت'}, '105': {'score': 16.407051, 'text': 'يجوز تمديدها لفصل دراسي واحد'}, '125': {'score': 16.405098, 'text': 'كامل او جزئي'}, '142': {'score': 12.356838, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في'}, '196': {'score': 9.665797, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول'}, '293': {'score': 18.76861, 'text': 'الجهة الطالبة بالاتفاق مع الكلية المعنية واعتماد مجلس الجامعة'}, '230': {'score': 6.6318283, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول الدراسية التالية لاجتياز'}, '28': {'score': 15.856505, 'text': 'قبول الطالب المشروط باجتيازه مواد دراسية محددة قبل البدء بالدراسات العليا'}, '171': {'score': 9.183149, 'text': 'في جميع الفصول الدراسية'}, '131': {'score': 8.090413, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول الدراسية التالية لاجت'}, '253': {'score': 11.994219, 'text': 'قبل نهاية الفصل الدراسي الثالث'}, '141': {'score': 10.117989, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول'}, '258': {'score': 11.851075, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في'}, '39': {'score': 10.779364, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي الواحد ويوجد نوعان :'}, '238': {'score': 10.518434, 'text': 'المشرف'}, '112': {'score': 16.170326, 'text': 'يجوز تمديدها لفصل دراسي واحد'}, '31': {'score': 12.814886, 'text': 'عدد ساعات الدراسة خلال'}, '87': {'score': 17.01869, 'text': 'أستاذ وأستاذ مساعد ومدرس بموافقة عميد كلية الدراسات العليا'}, '149': {'score': 12.652793, 'text': 'في جميع الفصول الدراسية التالية لاجت'}, '47': {'score': 8.101485, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي الواحد ويوجد نوعان : الدوام الكلي'}, '42': {'score': 9.436557, 'text': 'نوعان'}, '213': {'score': 17.530684, 'text': 'المشرف الاكاديمي'}, '15': {'score': 12.793701, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي الواحد'}, '133': {'score': 8.152683, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في'}, '137': {'score': 12.809887, 'text': 'يسجل طالب الدكتوراة مقرر رسالة'}, '29': {'score': 10.772774, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي'}, '206': {'score': 15.363066, 'text': 'ويجوز تمديدها لسنتين اضافتين'}, '153': {'score': 10.322311, 'text': 'في جميع الفصول الدراسية التالية لاجت'}, '17': {'score': 9.774021, 'text': 'الدوام'}, '94': {'score': 15.840042, 'text': 'يجوز تمديدها لفصل دراسي واحد'}, '12': {'score': 9.830442, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي الواحد ويوجد نوعان'}, '254': {'score': 12.589772, 'text': 'في جميع الفصول الدراسية التالية'}, '101': {'score': 18.213745, 'text': 'تقدير 2 . 67 في المقرر ومدة سنتين بين اجتياز واعتماد المقرر'}, '58': {'score': 19.078386, 'text': 'مهمة واحدة فقط خلال مدة دراسته'}, '265': {'score': 7.0013885, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع'}, '301': {'score': 15.787708, 'text': 'منحة دراسية بمرتب مالي ومزايا متعددة'}, '232': {'score': 11.981354, 'text': 'في جميع الفصول الدراسية التالية'}, '167': {'score': 11.153339, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع'}, '202': {'score': 8.015385, 'text': 'في جميع الفصول الدراسية التالية'}, '26': {'score': 10.682703, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي'}, '235': {'score': 18.256226, 'text': 'خلال مشرفه الاكاديمي'}, '50': {'score': 18.77954, 'text': 'مهمة واحدة فقط خلال مدة دراسته'}, '270': {'score': 7.1059623, 'text': 'الحد الاقصى للعبء الدراسي يجوز وذلك باقتراح من مدير البرنامج وموافقة كلية الدراسات العليا . العبء الدراسي للطالب في النظام السنوي يعتمد'}, '127': {'score': 18.606827, 'text': 'سنة دراسية واحدة'}, '294': {'score': 17.07978, 'text': 'اجتياز المقررات الإضافية بمعدل متوسط لا يقل عن 3'}, '226': {'score': 9.296551, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول'}, '241': {'score': 12.944783, 'text': 'يسجل طالب الدكتوراة مقرر رسالة'}, '144': {'score': 18.76187, 'text': 'طبيعة المشكلة ومنهجية البحث والمراجع الاساسية والامكانات اللازمة لتنفيذه'}, '33': {'score': 13.259475, 'text': 'عدد ساعات الدراسة خلال الفصل'}, '138': {'score': 5.6261806, 'text': 'جميع الفصول الدراسية التالية'}, '63': {'score': 13.451907, 'text': '3 اعضاء فقط'}, '160': {'score': 7.4323, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول الدراسية التالية لاجتياز'}, '2': {'score': 11.831495, 'text': 'عدد ساعات الدراسة خلال الفصل'}, '146': {'score': 4.5337462, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع'}, '71': {'score': 19.143635, 'text': 'الأساتذة والأساتذة المشاركين وأحيانا الأساتذة المساعدين أو المتقاعدين'}, '51': {'score': -5.8405633, 'text': '100 دينار كويتي للاشراف'}, '250': {'score': 12.028571, 'text': 'في جميع الفصول الدراسية التالية'}, '48': {'score': 19.005253, 'text': 'مهمة واحدة فقط خلال مدة دراسته'}, '89': {'score': 17.96252, 'text': 'سنة واحدة قابلة للتجديد'}, '186': {'score': 12.236738, 'text': 'يسجل طالب الدكتوراة مقرر رسالة'}, '113': {'score': 15.886944, 'text': 'يجوز تمديدها لفصل دراسي واحد'}, '289': {'score': 16.046618, 'text': 'مقدرة الطالب على انجاز بحث علمي وعرض نتائج بحثه'}, '92': {'score': 17.739243, 'text': 'اقتراح شروط القبول الإضافية الخاصة بالبرنامج ودراسة الطلبات'}, '246': {'score': 18.182781, 'text': 'خلال مشرفه الاكاديمي'}, '86': {'score': 17.807076, 'text': 'اقتراح شروط القبول الإضافية الخاصة بالبرنامج ودراسة الطلبات'}, '276': {'score': 19.597168, 'text': '21 وحدة دراسية بالاضافة الى الاطروحة'}, '62': {'score': 17.398083, 'text': 'الطالب مسجلا بدوام كامل ولا تقيم اسرته في الكويت'}, '262': {'score': 16.786757, 'text': 'المشرف'}, '30': {'score': 13.065468, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي الواحد'}, '122': {'score': 15.924535, 'text': 'يجوز تمديدها لفصل دراسي واحد'}, '41': {'score': 13.177008, 'text': 'عدد ساعات الدراسة خلال'}, '123': {'score': 18.0456, 'text': 'تقدير 2 . 67 في المقرر ومدة سنتين بين اجتياز واعتماد المقرر'}, '3': {'score': 9.539332, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي الواحد ويوجد نوعان :'}, '56': {'score': 18.316818, 'text': '100 دينار كويتي لكل عضو'}, '228': {'score': 10.452643, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول'}, '76': {'score': 9.466337, 'text': 'تقديمه تقريرا سنويا عن سير برنامج الدراسات العليا وذلك قبل نهاية شهر يوليو'}, '278': {'score': 4.702937, 'text': 'جزئي'}, '174': {'score': 10.32034, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول'}, '102': {'score': 16.934673, 'text': 'هو 2 . 67'}, '291': {'score': 15.960354, 'text': 'مقدرة الطالب على انجاز بحث علمي وعرض نتائج بحثه'}, '67': {'score': 18.58209, 'text': 'مهمة واحدة فقط خلال مدة دراسته'}, '227': {'score': 12.65671, 'text': 'في جميع الفصول الدراسية التالية'}, '292': {'score': 4.902898, 'text': 'جزئي'}, '96': {'score': 16.251873, 'text': 'يجوز تمديدها لفصل دراسي واحد'}, '217': {'score': 9.794892, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول'}, '85': {'score': 18.966604, 'text': 'الأساتذة والأساتذة المشاركين وأحيانا الأساتذة المساعدين أو المتقاعدين'}, '163': {'score': 17.702618, 'text': 'خلال مشرفه الاكاديمي'}, '65': {'score': 18.579838, 'text': 'مهمة واحدة فقط خلال مدة دراسته'}, '252': {'score': 8.784124, 'text': 'ولا تحتسب فترات انقطاع الدراسة'}, '295': {'score': 4.5273633, 'text': 'جزئي'}, '281': {'score': 12.770355, 'text': 'يحددها مجلس الجامعة'}, '103': {'score': 16.440086, 'text': 'يجوز تمديدها لفصل دراسي واحد'}, '9': {'score': 9.352371, 'text': 'ويوجد'}, '27': {'score': 11.562204, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي الواحد ويوجد نوعان'}, '121': {'score': 17.634014, 'text': 'قبول نظامي فقط'}, '284': {'score': 16.78584, 'text': '33 وحدة دراسية'}, '165': {'score': 6.375557, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول'}, '120': {'score': 16.323048, 'text': 'تقدير 2 . 67 على الاقل ولم يمر على اجتيازها اكثر من سنتين'}, '157': {'score': 12.537327, 'text': 'يسجل طالب الدكتوراة مقرر رسالة'}, '195': {'score': 11.6824, 'text': 'قبل نهاية الفصل الدراسي الثالث'}, '91': {'score': 15.260372, 'text': 'سنتان قابلة للتجديد ويجوز بقاء ثلث الأعضاء القدامى عند إعادة التشكيل'}, '88': {'score': 16.281845, 'text': 'اقتراح شروط القبول الإضافية الخاصة بالبرنامج ودراسة الطلبات'}, '216': {'score': 19.027546, 'text': 'بمعدل متوسط لا يقل عن 3 نقاط'}, '143': {'score': 9.691817, 'text': 'مقرر رسالة الدكتوراة في جميع الفصول الدراسية التالية'}, '115': {'score': 19.028955, 'text': 'سنة دراسية واحدة'}, '68': {'score': 16.452131, 'text': 'في ضوء دراسة حالتهم الاجتماعية'}, '260': {'score': 17.795626, 'text': 'لجنة البرنامج'}, '269': {'score': 11.759266, 'text': 'يسجل طالب الدكتوراة مقرر رسالة'}, '209': {'score': 10.3763895, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول الدراسية التالية لاجتياز'}, '37': {'score': 13.315104, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي الواحد ويوجد'}, '204': {'score': 14.2121315, 'text': 'ويجوز تمديدها لسنتين اضافتين'}, '256': {'score': 9.927052, 'text': 'في جميع الفصول الدراسية التالية لاجت'}, '7': {'score': 9.578457, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي الواحد ويوجد نوعان :'}, '135': {'score': 18.79617, 'text': '3 نقاط ولم يمر على اجتيازها اكثر من سنتين'}, '78': {'score': 14.18089, 'text': 'الموافقة على برامج الدراسات العليا ووضع الأنظمة'}, '272': {'score': 17.58281, 'text': 'معدل عام 2 . 33'}, '72': {'score': 18.242992, 'text': 'مدراء البرامج بالكلية المعنية بالإضافة الى عدد من أعضاء هيئة التدريس'}, '53': {'score': 16.08981, 'text': '3 اعضاء فقط'}, '297': {'score': 9.495003, 'text': 'القانون العام والقانون الخاص والاداب والعلوم والتربية والشريعة الإسلامية وإدارة الاعمال والصحة العامة'}, '73': {'score': 17.5929, 'text': 'اقتراح شروط القبول الإضافية الخاصة بالبرنامج ودراسة الطلبات'}, '114': {'score': 15.128108, 'text': 'بالاضافة الى شروط اخرى بالإعلان'}, '299': {'score': 12.429838, 'text': 'الشهادة الجامعية والا يقل المعدل العام عن 3'}, '126': {'score': 18.32071, 'text': '21 وحدة دراسية'}, '290': {'score': 17.066437, 'text': 'اجتياز المقررات الإضافية بمعدل متوسط لا يقل عن 3'}, '194': {'score': 11.889629, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة'}, '99': {'score': 17.012218, 'text': 'اذا انخفض معدله المتوسط عن 2 . 33 نقطة'}, '181': {'score': 7.625114, 'text': 'في جميع الفصول الدراسية التالية لاجتياز'}, '214': {'score': 7.1667414, 'text': 'في جميع الفصول الدراسية التالية'}, '203': {'score': 9.382111, 'text': 'يسجل طالب'}, '139': {'score': 8.205693, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول الدراسية التالية'}, '187': {'score': 8.79413, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع'}, '36': {'score': 9.4152775, 'text': 'نوعان'}, '222': {'score': 7.84033, 'text': 'في جميع الفصول الدراسية'}, '189': {'score': 10.346859, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول'}, '158': {'score': 10.961309, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع'}, '148': {'score': 9.022889, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول الدراسية التالية'}, '32': {'score': 10.605375, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي'}, '40': {'score': 8.925606, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي'}, '271': {'score': 1.0055118, 'text': 'يعتمد على نوع الدوام'}, '159': {'score': 7.293219, 'text': 'تحويل المشروع التفصيلي لطالب الدكتوراة الى ادارة الابحاث بالجامعة لدعم تمويله'}, '229': {'score': 11.226294, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع'}, '277': {'score': 8.595545, 'text': 'القانون العام والقانون الخاص والاداب والعلوم والتربية والشريعة الإسلامية وإدارة الاعمال والصحة العامة'}, '14': {'score': 11.411552, 'text': 'عدد'}, '219': {'score': 9.794543, 'text': 'في جميع الفصول الدراسية'}, '237': {'score': 7.508218, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول الدراسية التالية لاجتياز'}, '117': {'score': 16.339838, 'text': 'كامل او جزئي'}, '34': {'score': 12.407026, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي'}, '183': {'score': 11.6298485, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة'}, '212': {'score': 4.589398, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع'}, '234': {'score': 13.929274, 'text': 'يسجل طالب الدكتوراة مقرر رسالة'}, '178': {'score': 8.122709, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في'}, '59': {'score': 15.708126, 'text': 'في ضوء دراسة حالتهم الاجتماعية'}, '119': {'score': 17.878279, 'text': '3 سنوات'}, '90': {'score': 17.454226, 'text': 'الموافقة على برامج الدراسات العليا ووضع الأنظمة'}, '140': {'score': 13.926373, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة'}, '208': {'score': 8.398891, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في'}, '266': {'score': 10.358627, 'text': 'قبل نهاية الفصل الدراسي الثالث'}, '150': {'score': 16.55613, 'text': '15 وحدة دراسية على الاقل بالاضافة الى الرسالة'}, '100': {'score': 16.127783, 'text': 'مستوى 500 فاعلى بحد اقصى 9 وحدات'}, '61': {'score': 18.673046, 'text': 'كطالب نظامي بدوام كامل وان لا يقل معدله المتوسط عن 3 . 5 نقاط وقد اجتاز 15 وحدة'}, '35': {'score': 9.710117, 'text': 'عدد'}, '145': {'score': 19.036306, 'text': 'بمعدل متوسط لا يقل عن 3 نقاط'}, '151': {'score': 6.985173, 'text': 'في جميع الفصول الدراسية التالية'}, '109': {'score': 15.910362, 'text': 'تقدير 2 . 67 على الاقل ولم يمر على اجتيازها اكثر من سنتين'}, '111': {'score': 15.49902, 'text': 'سنتين'}, '116': {'score': 15.3829565, 'text': 'سنتين'}, '5': {'score': 9.51483, 'text': 'نوعان'}, '124': {'score': 16.126118, 'text': 'يجوز تمديدها لفصل دراسي واحد'}, '79': {'score': 15.187823, 'text': 'المسؤول أكاديميا واداريا'}, '191': {'score': 7.4604893, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول'}, '45': {'score': 9.289871, 'text': 'نوعان'}, '210': {'score': 13.111942, 'text': 'يسجل طالب الدكتوراة مقرر رسالة'}, '69': {'score': 19.239597, 'text': 'مهمة واحدة فقط خلال مدة دراسته'}, '240': {'score': 11.697699, 'text': 'في جميع الفصول الدراسية التالية'}, '193': {'score': 6.25557, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول'}, '55': {'score': 17.493767, 'text': 'الفصل الاول للعام الجامعي التالي لاعتمادها'}, '156': {'score': 16.097752, 'text': 'رسالة بحثية يعدها الطالب بتوجيه المشرف الاكاديمي'}, '1': {'score': 5.576753, 'text': 'الدوام الكلي'}, '182': {'score': 19.108965, 'text': 'بمعدل متوسط لا يقل عن 3 نقاط'}, '129': {'score': 17.460564, 'text': 'شهادة الاجازة الجامعية الاولى ومعدل عام 2 . 33 فأعلى'}, '136': {'score': 11.230185, 'text': 'في جميع الفصول الدراسية التالية'}, '283': {'score': 4.902898, 'text': 'جزئي'}, '172': {'score': 18.36493, 'text': 'خلال مشرفه الاكاديمي'}, '20': {'score': 11.107039, 'text': 'عدد ساعات الدراسة خلال الفصل'}, '211': {'score': 12.842052, 'text': 'يسجل طالب الدكتوراة مقرر'}, '16': {'score': 9.342558, 'text': 'الدوام'}, '84': {'score': 16.73368, 'text': 'الهيئة العليا لبحث شؤون الكلية'}, '60': {'score': 19.061123, 'text': 'كطالب نظامي بدوام كامل وان لا يقل معدله المتوسط عن 3 . 5 نقاط وقد اجتاز 15 وحدة'}, '223': {'score': 8.001256, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول الدراسية التالية لاجتياز'}, '38': {'score': 11.662319, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي'}, '201': {'score': 6.9773664, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول'}, '155': {'score': 9.582178, 'text': 'يسجل طالب'}, '215': {'score': 8.265757, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول الدراسية التالية لاجت'}, '288': {'score': 12.20424, 'text': 'يعتمد على نوع الدوام اما جزئي او كامل'}, '166': {'score': 9.800005, 'text': 'في جميع الفصول الدراسية التالية لاجت'}, '8': {'score': 9.9979925, 'text': 'الدوام'}, '267': {'score': 7.9266663, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع'}, '264': {'score': 10.635576, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع'}, '263': {'score': 18.465881, 'text': 'عقب او قرب انتهاء اجتياز جميع المقررات المحددة'}, '18': {'score': 13.729829, 'text': 'عدد ساعات الدراسة خلال الفصل'}, '286': {'score': 8.0278225, 'text': '33 وحدة دراسية'}, '118': {'score': 15.832731, 'text': 'يجوز تمديدها لفصل دراسي واحد'}, '298': {'score': 15.104145, 'text': 'مذكورة في موقع كلية الدراسات العليا'}, '176': {'score': 10.944351, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة'}, '128': {'score': 15.455887, 'text': 'سنتين'}, '198': {'score': 9.551266, 'text': 'يسجل طالب الدكتوراة'}, '261': {'score': 9.410145, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول الدراسية'}, '168': {'score': 14.860368, 'text': 'دكتوراة الفلسفة'}, '200': {'score': 14.842691, 'text': 'قبل بداية الفصل الدراسي الثاني'}, '152': {'score': 10.783172, 'text': 'يسجل طالب الدكتوراة مقرر رسالة'}, '25': {'score': 9.727325, 'text': 'ويوجد'}, '22': {'score': 7.7995567, 'text': 'ويوجد نوعان :'}, '287': {'score': 13.47434, 'text': 'ولا يشترط اجتياز الامتحان الشامل او اعداد أطروحة'}, '66': {'score': 19.099121, 'text': 'كطالب نظامي بدوام كامل وان لا يقل معدله المتوسط عن 3 . 5 نقاط وقد اجتاز 15 وحدة'}, '205': {'score': 11.117472, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول الدراسية التالية لاجت'}, '280': {'score': 10.058491, 'text': '33 وحدة دراسية'}, '190': {'score': 13.326393, 'text': '5 سنوات'}, '282': {'score': 4.809528, 'text': 'العب'}, '285': {'score': 4.1550527, 'text': 'يعتمد على'}, '233': {'score': 7.714534, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول الدراسية التالية لاجتياز'}, '236': {'score': 18.698053, 'text': 'طبيعة المشكلة ومنهجية البحث والمراجع الاساسية والامكانات اللازمة لتنفيذه'}, '134': {'score': 12.625929, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع'}, '64': {'score': 17.73767, 'text': '30 دينار كويتي'}, '248': {'score': 14.88833, 'text': 'سنتان'}, '97': {'score': 16.418533, 'text': 'يجوز تمديدها لفصل دراسي واحد'}, '274': {'score': 8.001307, 'text': 'خلال فترة السحب والإضافة ولا يمكن استردادها بعد ذلك'}, '164': {'score': 9.4091835, 'text': 'في جميع الفصول الدراسية التالية لاجت'}, '11': {'score': 7.99656, 'text': 'ويوجد نوعان :'}, '75': {'score': 17.717274, 'text': 'الاشراف على برامج الدراسات العليا في الكلية ووضع القواعد التنظيمية والمقترحات'}, '225': {'score': 12.456294, 'text': 'في جميع الفصول الدراسية التالية'}, '243': {'score': 14.170708, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة'}, '74': {'score': 17.392204, 'text': 'الموافقة على برامج الدراسات العليا ووضع الأنظمة'}, '108': {'score': 17.692505, 'text': '21 وحدة دراسية'}, '46': {'score': 10.605279, 'text': 'عدد ساعات الدراسة خلال'}, '106': {'score': 19.085379, 'text': 'سنة دراسية واحدة'}, '175': {'score': 8.683919, 'text': 'في جميع الفصول الدراسية التالية لاجت'}, '192': {'score': 9.274571, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول'}, '43': {'score': 11.605289, 'text': 'عدد ساعات الدراسة خلال الفصل الدراسي الواحد ويوجد نوعان'}, '132': {'score': 16.687874, 'text': 'المشرف'}, '184': {'score': 10.502776, 'text': 'قبل نهاية الفصل الدراسي الثالث'}, '279': {'score': 1.4110231, 'text': 'يعتمد على نوع الدوام'}, '199': {'score': 12.924944, 'text': 'في جميع الفصول الدراسية التالية'}, '98': {'score': 18.33397, 'text': '21 وحدة دراسية'}, '173': {'score': 16.670061, 'text': 'المشرف'}, '81': {'score': 17.11383, 'text': 'عميد الكلية والعمداء المساعدون ورؤساء اللجان وأعضاء هيئة التدريس وأعضاء'}, '95': {'score': 19.114725, 'text': 'سنة دراسية واحدة'}, '80': {'score': 7.257634, 'text': 'تقديمه تقريرا سنويا عن سير برنامج الدراسات العليا وذلك قبل نهاية شهر يوليو'}, '162': {'score': 13.556878, 'text': 'في جميع الفصول الدراسية التالية'}}\n"
     ]
    }
   ],
   "source": [
    "print(imd_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "id": "A4mSAjUIeNsz"
   },
   "outputs": [],
   "source": [
    "def get_preds2(total_preds,data_path): \n",
    "  preds_path = os.path.join('preds')\n",
    "  if not os.path.exists(preds_path):\n",
    "    os.mkdir(preds_path)\n",
    "  text_preds_path = os.path.join(preds_path, 'preds.json')\n",
    "  jsonString = json.dumps(total_preds)\n",
    "  jsonFile = open(text_preds_path, \"w\")\n",
    "  jsonFile.write(jsonString)\n",
    "  jsonFile.close()\n",
    "  !python /content/Arabic-MRC/evaluatev2.py /content/asquadv2-test.json /content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth/preds/preds.json electra  \n",
    "\n",
    "  ##return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m8wWiOx1eVIu",
    "outputId": "9170793a-3691-404f-d9f4-956fc6b8370f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 2.990033222591362,\n",
      "  \"f1\": 6.300050253230052,\n",
      "  \"total\": 301,\n",
      "  \"HasAns_exact\": 2.990033222591362,\n",
      "  \"HasAns_f1\": 6.300050253230052,\n",
      "  \"HasAns_total\": 301\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "qa_result_dict = get_preds2(script_preds, \"/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth/preds\" ) \n",
    "##'Data/asquadv2-test.json','Runs/AraElectraDecoupledAsquadv2/train/span/fourth/test-eval\n",
    "### '/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth/preds' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANtllpIzN8mR"
   },
   "source": [
    "### **updates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LSnbR3geN8mR",
    "outputId": "9231917b-e735-4926-ccbb-0275026a7576"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff43f086b90>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, ElectraForQuestionAnswering, DataCollatorWithPadding,BertModel, ElectraForSequenceClassification, ElectraModel\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "torch.manual_seed(3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "id": "3b_4DjjYN8mS"
   },
   "outputs": [],
   "source": [
    "def add_end_index(answer, context):\n",
    "  ## 1 if span match the context 0 otherwise\n",
    "  text = answer['text']\n",
    "  start_idx = answer['answer_start']\n",
    "  end_idx = start_idx + len(text)\n",
    "  answer['answer_end'] = end_idx\n",
    "  if text == context[start_idx:end_idx]:\n",
    "    answer['answer_end'] = end_idx\n",
    "    return False\n",
    "  for i in range(1,3):\n",
    "    if text == context[start_idx-i:end_idx-i]:\n",
    "      answer['answer_end']= end_idx-1\n",
    "      answer['answer_start'] = start_idx-1\n",
    "      return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "id": "mzvMGYDmN8mS"
   },
   "outputs": [],
   "source": [
    "def arabert_preprocess(context,question, answer, arabert_prep):\n",
    "    answer['text'] = arabert_prep.preprocess(answer['text'])\n",
    "    context = arabert_prep.preprocess(context)\n",
    "    question = arabert_prep.preprocess(question)\n",
    "    res = context.find(answer['text'])\n",
    "    if res !=-1:\n",
    "        answer['answer_start'] = res\n",
    "    return context, question, answer, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "id": "4kfx6xUwN8mS"
   },
   "outputs": [],
   "source": [
    "def Read_Dataset(path,arabert_prep):\n",
    "  contexts =[]\n",
    "  answers =[]\n",
    "  questions =[]\n",
    "  IDs= []\n",
    " ## plausible = []\n",
    "  cnt = 0\n",
    "  with open(path) as f:\n",
    "    aaqad_dict = json.load(f)\n",
    "    for article in aaqad_dict['data']:\n",
    "      for passage in article['paragraphs']:\n",
    "        context = passage['context']\n",
    "        for qa in passage['qas']:\n",
    "          question = qa['question']\n",
    "          '''if 'plausible_answers' in qa.keys():# there is two cases if the question have no answer then use plausible answer\n",
    "            access = 'plausible_answers'\n",
    "            plausible.append(True)\n",
    "          else:\n",
    "            access = 'answers'\n",
    "            plausible.append(False)'''\n",
    "          access = 'answers'\n",
    "          for answer in qa[access]:\n",
    "            context,question, answer, res =  arabert_preprocess(context,question, answer, arabert_prep)\n",
    "            #if res==-1:\n",
    "            #  cnt+=1\n",
    "            #  continue\n",
    "            flag = add_end_index(answer, context) #if false dont add the \n",
    "            cnt =cnt + flag\n",
    "            flag = False\n",
    "            if not flag:\n",
    "              contexts.append(context)\n",
    "              answers.append(answer)\n",
    "              questions.append(question)\n",
    "              IDs.append(int(qa['id']))\n",
    "  return contexts,questions,answers,IDs #plausible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEbnbZR3N8mS"
   },
   "source": [
    "why fix them? can i directly use those ids and del id col in original csv?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "id": "vibZioSvN8mS"
   },
   "outputs": [],
   "source": [
    "def fix_ids(path):\n",
    "  #IDs need to be fixed for evaluating purposes\n",
    "    a_file = open(path, \"r\")\n",
    "    json_object = json.load(a_file)\n",
    "    a_file.close()\n",
    "    idx_cnt = 1\n",
    "    for article in json_object['data']:\n",
    "      for passage in article['paragraphs']:\n",
    "        context = passage['context']\n",
    "        for qa in passage['qas']:\n",
    "            qa['id'] = str(idx_cnt)\n",
    "            idx_cnt = idx_cnt + 1\n",
    "    a_file = open(path, \"w\")\n",
    "    json.dump(json_object, a_file)\n",
    "    a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "id": "_avBIDv4N8mS"
   },
   "outputs": [],
   "source": [
    "model_name = \"araelectra-base-discriminator\"\n",
    "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
    "fix_ids('/content/asquadv2-train.json')\n",
    "fix_ids('/content/asquadv2-val.json')\n",
    "fix_ids('/content/asquadv2-test.json')\n",
    "asquad_span_train_contexts, asquad_span_train_questions, asquad_span_train_answers, asquad_span_train_ids = Read_Dataset('/content/asquadv2-train.json', arabert_prep)#,asquad_train_plausible\n",
    "asquad_val_contexts, asquad_val_questions, asquad_val_answers, asquad_val_ids = Read_Dataset('/content/asquadv2-val.json', arabert_prep)#,asquad_val_plausible\n",
    "asquad_test_contexts, asquad_test_questions, asquad_test_answers, asquad_test_ids = Read_Dataset('/content/asquadv2-test.json', arabert_prep)#,asquad_test_plausible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ute3zhdQN8mT"
   },
   "source": [
    "google Semantic Search — Sentence-Transformers documentation (sbert.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fm9OvEfN8mT",
    "outputId": "09517fd4-79c5-4493-e0d7-6c446b3fdfc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1504"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(asquad_test_answers)+len(asquad_span_train_answers)+len(asquad_val_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8is_f-tgN8mT",
    "outputId": "441e9d72-2164-402d-c17b-4eef958ad9fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(sum(asquad_span_train_ids)==len(asquad_span_train_ids)*(len(asquad_span_train_ids)+1)/2)\n",
    "print(sum(asquad_val_ids)==len(asquad_val_ids)*(len(asquad_val_ids)+1)/2)\n",
    "print(sum(asquad_test_ids)==len(asquad_test_ids)*(len(asquad_test_ids)+1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "id": "Qmg88DRWN8mT"
   },
   "outputs": [],
   "source": [
    "def get_answered_feat(contexts, questions, answers):#, plausible\n",
    "    new_contexts, new_questions, new_answers = [], [], []\n",
    "    for i in range(len(answers)):\n",
    "          new_contexts.append(contexts[i])\n",
    "          new_questions.append(questions[i])\n",
    "          new_answers.append(answers[i])\n",
    "    return new_contexts, new_questions, new_answers\n",
    "span_train_contexts, span_train_questions, span_train_answers = get_answered_feat(asquad_span_train_contexts, asquad_span_train_questions, asquad_span_train_answers)  ##, asquad_train_plausible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EWth-FJoN8mT",
    "outputId": "2b610089-5efd-4c4d-ca05-02b7d69136f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902 902\n"
     ]
    }
   ],
   "source": [
    "print(len(span_train_contexts), len(asquad_span_train_contexts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "id": "8YiBnbN7N8mT"
   },
   "outputs": [],
   "source": [
    "#Creating the tokenizer\n",
    "model_name =  \"aubmindlab/araelectra-base-discriminator\"\n",
    "araelectra_tokenizer = AutoTokenizer.from_pretrained(model_name,do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "id": "knjsvAzGN8mT"
   },
   "outputs": [],
   "source": [
    "span_train_encodings = araelectra_tokenizer(span_train_questions, span_train_contexts, truncation=True, return_offsets_mapping=True)##remove , return_offsets_mapping=True\n",
    "val_encodings = araelectra_tokenizer(asquad_val_questions, asquad_val_contexts, truncation=True, return_offsets_mapping=True)\n",
    "test_encodings = araelectra_tokenizer(asquad_test_questions, asquad_test_contexts, truncation=True,  return_offsets_mapping=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yop9Hz-ON8mT"
   },
   "source": [
    "why del cols?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "id": "TYmrAGIMN8mU"
   },
   "outputs": [],
   "source": [
    "span_train_offset = span_train_encodings['offset_mapping']\n",
    "del span_train_encodings['offset_mapping']\n",
    "\n",
    "val_offset = val_encodings['offset_mapping']\n",
    "del val_encodings['offset_mapping']\n",
    "test_offset = test_encodings['offset_mapping']\n",
    "del test_encodings['offset_mapping']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P7wX-ks6N8mU",
    "outputId": "e6bac68f-8e59-4d1c-bfc4-7d62db4ee268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16, 18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24, 26: 25, 27: 26, 28: 27, 29: 28, 30: 29, 31: 30, 32: 31, 33: 32, 34: 33, 35: 34, 36: 35, 37: 36, 38: 37, 39: 38, 40: 39, 41: 40, 42: 41, 43: 42, 44: 43, 45: 44, 46: 45, 47: 46, 48: 47, 49: 48, 50: 49, 51: 50, 52: 51, 53: 52, 54: 53, 55: 54, 56: 55, 57: 56, 58: 57, 59: 58, 60: 59, 61: 60, 62: 61, 63: 62, 64: 63, 65: 64, 66: 65, 67: 66, 68: 67, 69: 68, 70: 69, 71: 70, 72: 71, 73: 72, 74: 73, 75: 74, 76: 75, 77: 76, 78: 77, 79: 78, 80: 79, 81: 80, 82: 81, 83: 82, 84: 83, 85: 84, 86: 85, 87: 86, 88: 87, 89: 88, 90: 89, 91: 90, 92: 91, 93: 92, 94: 93, 95: 94, 96: 95, 97: 96, 98: 97, 99: 98, 100: 99, 101: 100, 102: 101, 103: 102, 104: 103, 105: 104, 106: 105, 107: 106, 108: 107, 109: 108, 110: 109, 111: 110, 112: 111, 113: 112, 114: 113, 115: 114, 116: 115, 117: 116, 118: 117, 119: 118, 120: 119, 121: 120, 122: 121, 123: 122, 124: 123, 125: 124, 126: 125, 127: 126, 128: 127, 129: 128, 130: 129, 131: 130, 132: 131, 133: 132, 134: 133, 135: 134, 136: 135, 137: 136, 138: 137, 139: 138, 140: 139, 141: 140, 142: 141, 143: 142, 144: 143, 145: 144, 146: 145, 147: 146, 148: 147, 149: 148, 150: 149, 151: 150, 152: 151, 153: 152, 154: 153, 155: 154, 156: 155, 157: 156, 158: 157, 159: 158, 160: 159, 161: 160, 162: 161, 163: 162, 164: 163, 165: 164, 166: 165, 167: 166, 168: 167, 169: 168, 170: 169, 171: 170, 172: 171, 173: 172, 174: 173, 175: 174, 176: 175, 177: 176, 178: 177, 179: 178, 180: 179, 181: 180, 182: 181, 183: 182, 184: 183, 185: 184, 186: 185, 187: 186, 188: 187, 189: 188, 190: 189, 191: 190, 192: 191, 193: 192, 194: 193, 195: 194, 196: 195, 197: 196, 198: 197, 199: 198, 200: 199, 201: 200, 202: 201, 203: 202, 204: 203, 205: 204, 206: 205, 207: 206, 208: 207, 209: 208, 210: 209, 211: 210, 212: 211, 213: 212, 214: 213, 215: 214, 216: 215, 217: 216, 218: 217, 219: 218, 220: 219, 221: 220, 222: 221, 223: 222, 224: 223, 225: 224, 226: 225, 227: 226, 228: 227, 229: 228, 230: 229, 231: 230, 232: 231, 233: 232, 234: 233, 235: 234, 236: 235, 237: 236, 238: 237, 239: 238, 240: 239, 241: 240, 242: 241, 243: 242, 244: 243, 245: 244, 246: 245, 247: 246, 248: 247, 249: 248, 250: 249, 251: 250, 252: 251, 253: 252, 254: 253, 255: 254, 256: 255, 257: 256, 258: 257, 259: 258, 260: 259, 261: 260, 262: 261, 263: 262, 264: 263, 265: 264, 266: 265, 267: 266, 268: 267, 269: 268, 270: 269, 271: 270, 272: 271, 273: 272, 274: 273, 275: 274, 276: 275, 277: 276, 278: 277, 279: 278, 280: 279, 281: 280, 282: 281, 283: 282, 284: 283, 285: 284, 286: 285, 287: 286, 288: 287, 289: 288, 290: 289, 291: 290, 292: 291, 293: 292, 294: 293, 295: 294, 296: 295, 297: 296, 298: 297, 299: 298, 300: 299, 301: 300}\n",
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16, 18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24, 26: 25, 27: 26, 28: 27, 29: 28, 30: 29, 31: 30, 32: 31, 33: 32, 34: 33, 35: 34, 36: 35, 37: 36, 38: 37, 39: 38, 40: 39, 41: 40, 42: 41, 43: 42, 44: 43, 45: 44, 46: 45, 47: 46, 48: 47, 49: 48, 50: 49, 51: 50, 52: 51, 53: 52, 54: 53, 55: 54, 56: 55, 57: 56, 58: 57, 59: 58, 60: 59, 61: 60, 62: 61, 63: 62, 64: 63, 65: 64, 66: 65, 67: 66, 68: 67, 69: 68, 70: 69, 71: 70, 72: 71, 73: 72, 74: 73, 75: 74, 76: 75, 77: 76, 78: 77, 79: 78, 80: 79, 81: 80, 82: 81, 83: 82, 84: 83, 85: 84, 86: 85, 87: 86, 88: 87, 89: 88, 90: 89, 91: 90, 92: 91, 93: 92, 94: 93, 95: 94, 96: 95, 97: 96, 98: 97, 99: 98, 100: 99, 101: 100, 102: 101, 103: 102, 104: 103, 105: 104, 106: 105, 107: 106, 108: 107, 109: 108, 110: 109, 111: 110, 112: 111, 113: 112, 114: 113, 115: 114, 116: 115, 117: 116, 118: 117, 119: 118, 120: 119, 121: 120, 122: 121, 123: 122, 124: 123, 125: 124, 126: 125, 127: 126, 128: 127, 129: 128, 130: 129, 131: 130, 132: 131, 133: 132, 134: 133, 135: 134, 136: 135, 137: 136, 138: 137, 139: 138, 140: 139, 141: 140, 142: 141, 143: 142, 144: 143, 145: 144, 146: 145, 147: 146, 148: 147, 149: 148, 150: 149, 151: 150, 152: 151, 153: 152, 154: 153, 155: 154, 156: 155, 157: 156, 158: 157, 159: 158, 160: 159, 161: 160, 162: 161, 163: 162, 164: 163, 165: 164, 166: 165, 167: 166, 168: 167, 169: 168, 170: 169, 171: 170, 172: 171, 173: 172, 174: 173, 175: 174, 176: 175, 177: 176, 178: 177, 179: 178, 180: 179, 181: 180, 182: 181, 183: 182, 184: 183, 185: 184, 186: 185, 187: 186, 188: 187, 189: 188, 190: 189, 191: 190, 192: 191, 193: 192, 194: 193, 195: 194, 196: 195, 197: 196, 198: 197, 199: 198, 200: 199, 201: 200, 202: 201, 203: 202, 204: 203, 205: 204, 206: 205, 207: 206, 208: 207, 209: 208, 210: 209, 211: 210, 212: 211, 213: 212, 214: 213, 215: 214, 216: 215, 217: 216, 218: 217, 219: 218, 220: 219, 221: 220, 222: 221, 223: 222, 224: 223, 225: 224, 226: 225, 227: 226, 228: 227, 229: 228, 230: 229, 231: 230, 232: 231, 233: 232, 234: 233, 235: 234, 236: 235, 237: 236, 238: 237, 239: 238, 240: 239, 241: 240, 242: 241, 243: 242, 244: 243, 245: 244, 246: 245, 247: 246, 248: 247, 249: 248, 250: 249, 251: 250, 252: 251, 253: 252, 254: 253, 255: 254, 256: 255, 257: 256, 258: 257, 259: 258, 260: 259, 261: 260, 262: 261, 263: 262, 264: 263, 265: 264, 266: 265, 267: 266, 268: 267, 269: 268, 270: 269, 271: 270, 272: 271, 273: 272, 274: 273, 275: 274, 276: 275, 277: 276, 278: 277, 279: 278, 280: 279, 281: 280, 282: 281, 283: 282, 284: 283, 285: 284, 286: 285, 287: 286, 288: 287, 289: 288, 290: 289, 291: 290, 292: 291, 293: 292, 294: 293, 295: 294, 296: 295, 297: 296, 298: 297, 299: 298, 300: 299, 301: 300}\n",
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16, 18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24, 26: 25, 27: 26, 28: 27, 29: 28, 30: 29, 31: 30, 32: 31, 33: 32, 34: 33, 35: 34, 36: 35, 37: 36, 38: 37, 39: 38, 40: 39, 41: 40, 42: 41, 43: 42, 44: 43, 45: 44, 46: 45, 47: 46, 48: 47, 49: 48, 50: 49, 51: 50, 52: 51, 53: 52, 54: 53, 55: 54, 56: 55, 57: 56, 58: 57, 59: 58, 60: 59, 61: 60, 62: 61, 63: 62, 64: 63, 65: 64, 66: 65, 67: 66, 68: 67, 69: 68, 70: 69, 71: 70, 72: 71, 73: 72, 74: 73, 75: 74, 76: 75, 77: 76, 78: 77, 79: 78, 80: 79, 81: 80, 82: 81, 83: 82, 84: 83, 85: 84, 86: 85, 87: 86, 88: 87, 89: 88, 90: 89, 91: 90, 92: 91, 93: 92, 94: 93, 95: 94, 96: 95, 97: 96, 98: 97, 99: 98, 100: 99, 101: 100, 102: 101, 103: 102, 104: 103, 105: 104, 106: 105, 107: 106, 108: 107, 109: 108, 110: 109, 111: 110, 112: 111, 113: 112, 114: 113, 115: 114, 116: 115, 117: 116, 118: 117, 119: 118, 120: 119, 121: 120, 122: 121, 123: 122, 124: 123, 125: 124, 126: 125, 127: 126, 128: 127, 129: 128, 130: 129, 131: 130, 132: 131, 133: 132, 134: 133, 135: 134, 136: 135, 137: 136, 138: 137, 139: 138, 140: 139, 141: 140, 142: 141, 143: 142, 144: 143, 145: 144, 146: 145, 147: 146, 148: 147, 149: 148, 150: 149, 151: 150, 152: 151, 153: 152, 154: 153, 155: 154, 156: 155, 157: 156, 158: 157, 159: 158, 160: 159, 161: 160, 162: 161, 163: 162, 164: 163, 165: 164, 166: 165, 167: 166, 168: 167, 169: 168, 170: 169, 171: 170, 172: 171, 173: 172, 174: 173, 175: 174, 176: 175, 177: 176, 178: 177, 179: 178, 180: 179, 181: 180, 182: 181, 183: 182, 184: 183, 185: 184, 186: 185, 187: 186, 188: 187, 189: 188, 190: 189, 191: 190, 192: 191, 193: 192, 194: 193, 195: 194, 196: 195, 197: 196, 198: 197, 199: 198, 200: 199, 201: 200, 202: 201, 203: 202, 204: 203, 205: 204, 206: 205, 207: 206, 208: 207, 209: 208, 210: 209, 211: 210, 212: 211, 213: 212, 214: 213, 215: 214, 216: 215, 217: 216, 218: 217, 219: 218, 220: 219, 221: 220, 222: 221, 223: 222, 224: 223, 225: 224, 226: 225, 227: 226, 228: 227, 229: 228, 230: 229, 231: 230, 232: 231, 233: 232, 234: 233, 235: 234, 236: 235, 237: 236, 238: 237, 239: 238, 240: 239, 241: 240, 242: 241, 243: 242, 244: 243, 245: 244, 246: 245, 247: 246, 248: 247, 249: 248, 250: 249, 251: 250, 252: 251, 253: 252, 254: 253, 255: 254, 256: 255, 257: 256, 258: 257, 259: 258, 260: 259, 261: 260, 262: 261, 263: 262, 264: 263, 265: 264, 266: 265, 267: 266, 268: 267, 269: 268, 270: 269, 271: 270, 272: 271, 273: 272, 274: 273, 275: 274, 276: 275, 277: 276, 278: 277, 279: 278, 280: 279, 281: 280, 282: 281, 283: 282, 284: 283, 285: 284, 286: 285, 287: 286, 288: 287, 289: 288, 290: 289, 291: 290, 292: 291, 293: 292, 294: 293, 295: 294, 296: 295, 297: 296, 298: 297, 299: 298, 300: 299, 301: 300, 302: 301, 303: 302, 304: 303, 305: 304, 306: 305, 307: 306, 308: 307, 309: 308, 310: 309, 311: 310, 312: 311, 313: 312, 314: 313, 315: 314, 316: 315, 317: 316, 318: 317, 319: 318, 320: 319, 321: 320, 322: 321, 323: 322, 324: 323, 325: 324, 326: 325, 327: 326, 328: 327, 329: 328, 330: 329, 331: 330, 332: 331, 333: 332, 334: 333, 335: 334, 336: 335, 337: 336, 338: 337, 339: 338, 340: 339, 341: 340, 342: 341, 343: 342, 344: 343, 345: 344, 346: 345, 347: 346, 348: 347, 349: 348, 350: 349, 351: 350, 352: 351, 353: 352, 354: 353, 355: 354, 356: 355, 357: 356, 358: 357, 359: 358, 360: 359, 361: 360, 362: 361, 363: 362, 364: 363, 365: 364, 366: 365, 367: 366, 368: 367, 369: 368, 370: 369, 371: 370, 372: 371, 373: 372, 374: 373, 375: 374, 376: 375, 377: 376, 378: 377, 379: 378, 380: 379, 381: 380, 382: 381, 383: 382, 384: 383, 385: 384, 386: 385, 387: 386, 388: 387, 389: 388, 390: 389, 391: 390, 392: 391, 393: 392, 394: 393, 395: 394, 396: 395, 397: 396, 398: 397, 399: 398, 400: 399, 401: 400, 402: 401, 403: 402, 404: 403, 405: 404, 406: 405, 407: 406, 408: 407, 409: 408, 410: 409, 411: 410, 412: 411, 413: 412, 414: 413, 415: 414, 416: 415, 417: 416, 418: 417, 419: 418, 420: 419, 421: 420, 422: 421, 423: 422, 424: 423, 425: 424, 426: 425, 427: 426, 428: 427, 429: 428, 430: 429, 431: 430, 432: 431, 433: 432, 434: 433, 435: 434, 436: 435, 437: 436, 438: 437, 439: 438, 440: 439, 441: 440, 442: 441, 443: 442, 444: 443, 445: 444, 446: 445, 447: 446, 448: 447, 449: 448, 450: 449, 451: 450, 452: 451, 453: 452, 454: 453, 455: 454, 456: 455, 457: 456, 458: 457, 459: 458, 460: 459, 461: 460, 462: 461, 463: 462, 464: 463, 465: 464, 466: 465, 467: 466, 468: 467, 469: 468, 470: 469, 471: 470, 472: 471, 473: 472, 474: 473, 475: 474, 476: 475, 477: 476, 478: 477, 479: 478, 480: 479, 481: 480, 482: 481, 483: 482, 484: 483, 485: 484, 486: 485, 487: 486, 488: 487, 489: 488, 490: 489, 491: 490, 492: 491, 493: 492, 494: 493, 495: 494, 496: 495, 497: 496, 498: 497, 499: 498, 500: 499, 501: 500, 502: 501, 503: 502, 504: 503, 505: 504, 506: 505, 507: 506, 508: 507, 509: 508, 510: 509, 511: 510, 512: 511, 513: 512, 514: 513, 515: 514, 516: 515, 517: 516, 518: 517, 519: 518, 520: 519, 521: 520, 522: 521, 523: 522, 524: 523, 525: 524, 526: 525, 527: 526, 528: 527, 529: 528, 530: 529, 531: 530, 532: 531, 533: 532, 534: 533, 535: 534, 536: 535, 537: 536, 538: 537, 539: 538, 540: 539, 541: 540, 542: 541, 543: 542, 544: 543, 545: 544, 546: 545, 547: 546, 548: 547, 549: 548, 550: 549, 551: 550, 552: 551, 553: 552, 554: 553, 555: 554, 556: 555, 557: 556, 558: 557, 559: 558, 560: 559, 561: 560, 562: 561, 563: 562, 564: 563, 565: 564, 566: 565, 567: 566, 568: 567, 569: 568, 570: 569, 571: 570, 572: 571, 573: 572, 574: 573, 575: 574, 576: 575, 577: 576, 578: 577, 579: 578, 580: 579, 581: 580, 582: 581, 583: 582, 584: 583, 585: 584, 586: 585, 587: 586, 588: 587, 589: 588, 590: 589, 591: 590, 592: 591, 593: 592, 594: 593, 595: 594, 596: 595, 597: 596, 598: 597, 599: 598, 600: 599, 601: 600, 602: 601, 603: 602, 604: 603, 605: 604, 606: 605, 607: 606, 608: 607, 609: 608, 610: 609, 611: 610, 612: 611, 613: 612, 614: 613, 615: 614, 616: 615, 617: 616, 618: 617, 619: 618, 620: 619, 621: 620, 622: 621, 623: 622, 624: 623, 625: 624, 626: 625, 627: 626, 628: 627, 629: 628, 630: 629, 631: 630, 632: 631, 633: 632, 634: 633, 635: 634, 636: 635, 637: 636, 638: 637, 639: 638, 640: 639, 641: 640, 642: 641, 643: 642, 644: 643, 645: 644, 646: 645, 647: 646, 648: 647, 649: 648, 650: 649, 651: 650, 652: 651, 653: 652, 654: 653, 655: 654, 656: 655, 657: 656, 658: 657, 659: 658, 660: 659, 661: 660, 662: 661, 663: 662, 664: 663, 665: 664, 666: 665, 667: 666, 668: 667, 669: 668, 670: 669, 671: 670, 672: 671, 673: 672, 674: 673, 675: 674, 676: 675, 677: 676, 678: 677, 679: 678, 680: 679, 681: 680, 682: 681, 683: 682, 684: 683, 685: 684, 686: 685, 687: 686, 688: 687, 689: 688, 690: 689, 691: 690, 692: 691, 693: 692, 694: 693, 695: 694, 696: 695, 697: 696, 698: 697, 699: 698, 700: 699, 701: 700, 702: 701, 703: 702, 704: 703, 705: 704, 706: 705, 707: 706, 708: 707, 709: 708, 710: 709, 711: 710, 712: 711, 713: 712, 714: 713, 715: 714, 716: 715, 717: 716, 718: 717, 719: 718, 720: 719, 721: 720, 722: 721, 723: 722, 724: 723, 725: 724, 726: 725, 727: 726, 728: 727, 729: 728, 730: 729, 731: 730, 732: 731, 733: 732, 734: 733, 735: 734, 736: 735, 737: 736, 738: 737, 739: 738, 740: 739, 741: 740, 742: 741, 743: 742, 744: 743, 745: 744, 746: 745, 747: 746, 748: 747, 749: 748, 750: 749, 751: 750, 752: 751, 753: 752, 754: 753, 755: 754, 756: 755, 757: 756, 758: 757, 759: 758, 760: 759, 761: 760, 762: 761, 763: 762, 764: 763, 765: 764, 766: 765, 767: 766, 768: 767, 769: 768, 770: 769, 771: 770, 772: 771, 773: 772, 774: 773, 775: 774, 776: 775, 777: 776, 778: 777, 779: 778, 780: 779, 781: 780, 782: 781, 783: 782, 784: 783, 785: 784, 786: 785, 787: 786, 788: 787, 789: 788, 790: 789, 791: 790, 792: 791, 793: 792, 794: 793, 795: 794, 796: 795, 797: 796, 798: 797, 799: 798, 800: 799, 801: 800, 802: 801, 803: 802, 804: 803, 805: 804, 806: 805, 807: 806, 808: 807, 809: 808, 810: 809, 811: 810, 812: 811, 813: 812, 814: 813, 815: 814, 816: 815, 817: 816, 818: 817, 819: 818, 820: 819, 821: 820, 822: 821, 823: 822, 824: 823, 825: 824, 826: 825, 827: 826, 828: 827, 829: 828, 830: 829, 831: 830, 832: 831, 833: 832, 834: 833, 835: 834, 836: 835, 837: 836, 838: 837, 839: 838, 840: 839, 841: 840, 842: 841, 843: 842, 844: 843, 845: 844, 846: 845, 847: 846, 848: 847, 849: 848, 850: 849, 851: 850, 852: 851, 853: 852, 854: 853, 855: 854, 856: 855, 857: 856, 858: 857, 859: 858, 860: 859, 861: 860, 862: 861, 863: 862, 864: 863, 865: 864, 866: 865, 867: 866, 868: 867, 869: 868, 870: 869, 871: 870, 872: 871, 873: 872, 874: 873, 875: 874, 876: 875, 877: 876, 878: 877, 879: 878, 880: 879, 881: 880, 882: 881, 883: 882, 884: 883, 885: 884, 886: 885, 887: 886, 888: 887, 889: 888, 890: 889, 891: 890, 892: 891, 893: 892, 894: 893, 895: 894, 896: 895, 897: 896, 898: 897, 899: 898, 900: 899, 901: 900, 902: 901}\n"
     ]
    }
   ],
   "source": [
    "val_ids_to_idx = {k:i for i,k in enumerate(asquad_val_ids)}\n",
    "test_ids_to_idx = {k:i for i,k in enumerate(asquad_test_ids)}\n",
    "span_train_ids_to_idx = {k:i for i,k in enumerate(asquad_span_train_ids)}\n",
    "\n",
    "print(val_ids_to_idx)\n",
    "print(test_ids_to_idx)\n",
    "print(span_train_ids_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "id": "EuCOqZm9N8mV"
   },
   "outputs": [],
   "source": [
    "def index_to_token_position(encodings , answers):\n",
    "  start_positions = list()\n",
    "  end_positions = list()\n",
    "  for i in range(len(answers)):\n",
    "    start_positions.append(encodings.char_to_token(i, answers[i]['answer_start'], 1))\n",
    "    end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'], 1))\n",
    "    #if context truncated\n",
    "    if start_positions[-1] is None: \n",
    "      start_positions[-1] = araelectra_tokenizer.model_max_length\n",
    "    #if end index is space\n",
    "    itt = 1\n",
    "    while end_positions[-1] is None: \n",
    "      end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end']-itt, 1)\n",
    "      itt = itt + 1 \n",
    "  encodings.update({'start_positions': torch.tensor(start_positions), 'end_positions': torch.tensor(end_positions)})\n",
    "  encodings['start_positions'] = encodings['start_positions'].view(len(answers), 1)\n",
    "  encodings['end_positions'] = encodings['end_positions'].view(len(answers), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "id": "HJaY37xpN8mV"
   },
   "outputs": [],
   "source": [
    "index_to_token_position(span_train_encodings, span_train_answers)\n",
    "index_to_token_position(val_encodings, asquad_val_answers)\n",
    "index_to_token_position(test_encodings, asquad_test_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vE6hWr_xN8mV"
   },
   "source": [
    "needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "id": "TVlZZpfSN8mV"
   },
   "outputs": [],
   "source": [
    "val_encodings['IDs'] = asquad_val_ids\n",
    "test_encodings['IDs'] = asquad_test_ids\n",
    "span_train_encodings['IDs'] = asquad_span_train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sf3TYJwxN8mV",
    "outputId": "3d1429ef-3dd5-400c-a495-059e99554811"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions', 'IDs'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions', 'IDs'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions', 'IDs'])\n"
     ]
    }
   ],
   "source": [
    "print(val_encodings.keys())\n",
    "print(test_encodings.keys())\n",
    "print(span_train_encodings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "id": "8lArmPxzN8mV"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "id": "lo0QtFl8N8mV"
   },
   "outputs": [],
   "source": [
    "class cgsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: val[idx] for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "span_train_dataset = cgsDataset(span_train_encodings)\n",
    "val_dataset = cgsDataset(val_encodings)\n",
    "test_dataset = cgsDataset(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "id": "4LcmjU9fN8mV"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(araelectra_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "id": "IZF6GrD2N8mW"
   },
   "outputs": [],
   "source": [
    "span_train_loader = DataLoader(span_train_dataset, batch_size=8, shuffle= True, collate_fn = data_collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size =8, shuffle = True, collate_fn = data_collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 8, shuffle = True, collate_fn = data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "id": "ZTYOGlLWN8mW"
   },
   "outputs": [],
   "source": [
    "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
    "    \"\"\"\n",
    "    state: checkpoint to save\n",
    "    is_best: is this the best checkpoint; min validation loss\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    best_model_path: path to save best checkpoint\n",
    "    \"\"\"\n",
    "    f_path = checkpoint_path\n",
    "    # save checkpoint data to the path given, checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    # if it is a best model, min validation loss\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        # copy that checkpoint file to best path given, best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "id": "t4eDej1EN8mW"
   },
   "outputs": [],
   "source": [
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    \"\"\"\n",
    "    checkpoint_path: path to saved checkpoint\n",
    "    model: model to load checkpoint parameters into       \n",
    "    optimizer: optimizer defined in previous training\n",
    "    \"\"\"\n",
    "    # load check point\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    # initialize state_dict from checkpoint to model\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    # initialize optimizer from checkpoint to optimizer\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
    "    results = checkpoint['result_dict']\n",
    "    # return model, optimizer, epoch value, min validation loss \n",
    "    return model, optimizer, checkpoint['epoch'], results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "id": "R_jihE5rN8mW"
   },
   "outputs": [],
   "source": [
    "def order_exp(base_path, exp_name):\n",
    "  exp_path = os.path.join(base_path, exp_name)\n",
    "  if not os.path.exists(exp_path):\n",
    "    os.mkdir(exp_path)\n",
    "  curr_ckp_path = os.path.join(exp_path,'curr.pt')\n",
    "  best_ckp_path = os.path.join(exp_path, 'best.pt')\n",
    "  return curr_ckp_path, best_ckp_path, exp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "id": "K9jlDzqmN8mW"
   },
   "outputs": [],
   "source": [
    "model_name1=\"ZeyadAhmed/AraElectra-Arabic-SQuADv2-QA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "id": "mjgKPlJFN8mW"
   },
   "outputs": [],
   "source": [
    "QA_AraElectra = ElectraForQuestionAnswering.from_pretrained(model_name1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "id": "hq9GFHe0N8mW"
   },
   "outputs": [],
   "source": [
    "def freeze(Electra, count=None):\n",
    "    if count is not None:\n",
    "\t      # We freeze here the embeddings of the model\n",
    "        for param in Electra.embeddings.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        if count != -1:\n",
    "\t          # if freeze_layer_count == -1, we only freeze the embedding layer\n",
    "\t          # otherwise we freeze the first `freeze_layer_count` encoder layers\n",
    "            for layer in Electra.encoder.layer[:count]:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False\n",
    "    print(sum(p.numel() for p in Electra.parameters()), sum(p.numel() for p in Electra.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jk-vv4WxN8mW",
    "outputId": "624367e1-81cb-42fc-c230-5ea1a5e37f61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134602752 42527232\n"
     ]
    }
   ],
   "source": [
    "freeze(QA_AraElectra.electra, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "id": "3YdaFOyCN8mW"
   },
   "outputs": [],
   "source": [
    "def get_raw_preds(data_loader, model,ids_to_index,offset,contexts, max_answer_length, n_best_size): \n",
    "  model.eval()\n",
    "  imd_predictions,script_predictions = dict(), dict()\n",
    "  with torch.no_grad():\n",
    "    #F1 = EM = Total = 0\n",
    "    total_loss = 0.0\n",
    "    total_predictions = dict()\n",
    "    no_probs_pred = dict()\n",
    "    #loop = tqdm(data_loader)\n",
    "    loop = tqdm(data_loader, leave=True)\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "      tokens = batch['input_ids'].to(device)\n",
    "      masks = batch['attention_mask'].to(device)\n",
    "      tokens_type = batch['token_type_ids'].to(device)\n",
    "      gt_start = batch['start_positions'].to(device)\n",
    "      gt_end = batch['end_positions'].to(device)\n",
    "      IDs = batch['IDs'].to(device)\n",
    "      outputs = model(tokens, masks, tokens_type, start_positions=gt_start, end_positions=gt_end)\n",
    "      #calculating loss\n",
    "      loss = outputs.loss\n",
    "      #update average total loss \n",
    "      total_loss = total_loss + ((1 / (batch_idx + 1)) * (loss.item() - total_loss)) \n",
    "      #calculating f1 score and EM\n",
    "      curr_batch_size = tokens.shape[0]\n",
    "      post_raw_preds(IDs, outputs.start_logits, outputs.end_logits, ids_to_index, offset, contexts,max_answer_length, n_best_size, imd_predictions, script_predictions )\n",
    "    #saving evaluation results\n",
    "    #evaluation\n",
    "\n",
    "    model.train()\n",
    "    return imd_predictions,script_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "id": "W9pyXei0N8mX"
   },
   "outputs": [],
   "source": [
    "def post_raw_preds(IDs, total_start_logits, total_end_logits,ids_to_index,offset,contexts, max_answer_length, n_best_size,\n",
    " imd_predictions,script_predictions ):\n",
    "    total_start_logits = total_start_logits.cpu().numpy()\n",
    "    total_end_logits = total_end_logits.cpu().numpy()\n",
    "    IDs = IDs.cpu().numpy()\n",
    "    for i in range(IDs.shape[0]):\n",
    "        offset_mapping = offset[ids_to_index[IDs[i].squeeze()]]\n",
    "        # The first feature comes from the first example. For the more general case, we will need to be match the example_id to\n",
    "        # an example index\n",
    "        context = contexts[ids_to_index[IDs[i].squeeze()]]\n",
    "        start_logits = total_start_logits[i]\n",
    "        end_logits = total_end_logits[i]\n",
    "        # Gather the indices the best start/end logits:\n",
    "        start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "        end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "        valid_answers = []\n",
    "        for start_index in start_indexes:\n",
    "            for end_index in end_indexes:\n",
    "                # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
    "                # to part of the input_ids that are not in the context.\n",
    "                if (\n",
    "                    start_index >= len(offset_mapping)\n",
    "                    or end_index >= len(offset_mapping)\n",
    "                    or offset_mapping[start_index] is None\n",
    "                    or offset_mapping[end_index] is None\n",
    "                ):\n",
    "                    continue\n",
    "                # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
    "                if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                    continue\n",
    "                if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char: end_char]\n",
    "                        }\n",
    "                    )\n",
    "        if len(valid_answers) ==0:\n",
    "            valid_answers.append({\"text\":\"\", \"score\":\"\"})\n",
    "\n",
    "        valid_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        imd_predictions[str(IDs[i].squeeze())] = valid_answer\n",
    "        script_predictions[str(IDs[i].squeeze())] = valid_answer['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "id": "YQOAEcnzN8mX"
   },
   "outputs": [],
   "source": [
    "def get_preds(total_preds, no_probs_preds,data_path, log_path):\n",
    "    preds_path = os.path.join(log_path, 'preds')\n",
    "    if not os.path.exists(preds_path):\n",
    "        os.mkdir(preds_path)\n",
    "    text_preds_path = os.path.join(preds_path, 'preds.json')\n",
    "    jsonString = json.dumps(total_preds)\n",
    "    jsonFile = open(text_preds_path, \"w\")\n",
    "    jsonFile.write(jsonString)\n",
    "    jsonFile.close()\n",
    "    \n",
    "    !python /content/Arabic-MRC/evaluatev2.py /content/asquadv2-val.json /content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth/preds/preds.json electra  --out-file /content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth\n",
    "    if log_path:\n",
    "        with open(os.path.join(log_path, 'res.csv')) as f:\n",
    "            DictReader_obj = csv.DictReader(f)\n",
    "            lastrow = None\n",
    "            for item in DictReader_obj:\n",
    "                lastrow = dict(item)\n",
    "        #print(lastrow)\n",
    "        return lastrow\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "id": "z_-9AGpUN8mX"
   },
   "outputs": [],
   "source": [
    "def span_train(model,start_epoch, num_epochs, optimizer,max_compined_metric, train_loader, val_loader, log, exp_name):\n",
    "  curr_ckp_path, best_ckp_path, exp_path = order_exp('/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span', exp_name)\n",
    "  model.train()\n",
    "  for epoch in range(start_epoch,num_epochs):\n",
    "    total_loss = 0.0\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "      tokens = batch['input_ids'].to(device)\n",
    "      masks = batch['attention_mask'].to(device)\n",
    "      tokens_type = batch['token_type_ids'].to(device)\n",
    "      gt_start = batch['start_positions'].to(device)\n",
    "      gt_end = batch['end_positions'].to(device)\n",
    "      outputs = model(tokens, masks, tokens_type, start_positions=gt_start, end_positions=gt_end)\n",
    "      loss = outputs.loss\n",
    "      loss = 2*loss\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "      total_loss = total_loss + ((1 / (batch_idx + 1)) * (loss.item() - total_loss)) \n",
    "      loop.set_description(f'Epoch {epoch}')\n",
    "      loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    imd_preds, script_preds = get_raw_preds(val_loader, model,val_ids_to_idx,val_offset,asquad_val_contexts, 30, 10)\n",
    "    result_dict = get_preds(script_preds, None,'/content/asquadv2-val.json',exp_path )\n",
    "    checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'result_dict':result_dict,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "    curr_compined_metric = float(result_dict['HasAns_exact'])+1.5*float(result_dict['HasAns_f1'])\n",
    "    if curr_compined_metric>=max_compined_metric:\n",
    "      max_compined_metric = curr_compined_metric\n",
    "      save_ckp(checkpoint, True, curr_ckp_path, best_ckp_path)\n",
    "    else:\n",
    "      save_ckp(checkpoint, False, curr_ckp_path, best_ckp_path)\n",
    "    print(\"ckp saved\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0HmmtoUN8mX",
    "outputId": "d96aaa7c-8b8e-4b3f-941d-d8b9aa4a9335"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134602752 42527232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForQuestionAnswering(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_AraElectra = ElectraForQuestionAnswering.from_pretrained(model_name1)\n",
    "freeze(QA_AraElectra.electra, 6)\n",
    "span_num_epochs = 4\n",
    "span_learning_rate = 2e-5\n",
    "span_optimizer = torch.optim.AdamW(QA_AraElectra.parameters(), lr=span_learning_rate, weight_decay=1e-5)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "#criterion_span = nn.CrossEntropyLoss(reduction='none')\n",
    "#cls_criterion = nn.CrossEntropyLoss()\n",
    "QA_AraElectra.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoIu3iVdN8mX"
   },
   "source": [
    "why says 301 for val? where is train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ww3BAH6_N8mX",
    "outputId": "9fa6fbca-7b3d-4441-95f3-b31064223ec9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/113 [00:00<?, ?it/s]You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Epoch 0: 100%|██████████| 113/113 [01:07<00:00,  1.67it/s, loss=2.66]\n",
      "100%|██████████| 38/38 [00:11<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 30.564784053156146,\n",
      "  \"f1\": 43.48152589725722,\n",
      "  \"total\": 301,\n",
      "  \"HasAns_exact\": 30.564784053156146,\n",
      "  \"HasAns_f1\": 43.48152589725722,\n",
      "  \"HasAns_total\": 301\n",
      "}\n",
      "ckp saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 113/113 [01:07<00:00,  1.68it/s, loss=1.68]\n",
      "100%|██████████| 38/38 [00:10<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 36.87707641196013,\n",
      "  \"f1\": 44.22926166731683,\n",
      "  \"total\": 301,\n",
      "  \"HasAns_exact\": 36.87707641196013,\n",
      "  \"HasAns_f1\": 44.22926166731683,\n",
      "  \"HasAns_total\": 301\n",
      "}\n",
      "ckp saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 113/113 [01:07<00:00,  1.68it/s, loss=0.514]\n",
      "100%|██████████| 38/38 [00:10<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 37.87375415282392,\n",
      "  \"f1\": 44.24931179699838,\n",
      "  \"total\": 301,\n",
      "  \"HasAns_exact\": 37.87375415282392,\n",
      "  \"HasAns_f1\": 44.24931179699838,\n",
      "  \"HasAns_total\": 301\n",
      "}\n",
      "ckp saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 113/113 [01:07<00:00,  1.68it/s, loss=0.0343]\n",
      "100%|██████████| 38/38 [00:10<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 38.538205980066444,\n",
      "  \"f1\": 44.6924495971346,\n",
      "  \"total\": 301,\n",
      "  \"HasAns_exact\": 38.538205980066444,\n",
      "  \"HasAns_f1\": 44.6924495971346,\n",
      "  \"HasAns_total\": 301\n",
      "}\n",
      "ckp saved\n"
     ]
    }
   ],
   "source": [
    "span_trained_model = span_train(QA_AraElectra,0, span_num_epochs, span_optimizer,0.0, span_train_loader, val_loader, True, '/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DC_400TyN8mX",
    "outputId": "143d4905-9876-4896-dc92-36937c28eed9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForQuestionAnswering(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_model = ElectraForQuestionAnswering.from_pretrained(model_name1)\n",
    "span_learning_rate = 2e-5\n",
    "span_optimizer = torch.optim.AdamW(qa_model.parameters(), lr=span_learning_rate, weight_decay=1e-5)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "qa_model.to(device)\n",
    "##qa_model , qa_optim, x, xx = load_ckp('/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth/best.pt', qa_model,span_optimizer)##why load ckp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q7ywHZPrN8mY",
    "outputId": "8c8b5a76-7592-4e49-82d6-a692fa6a97fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('AraElectra-ASQuADv2-QA/tokenizer_config.json',\n",
       " 'AraElectra-ASQuADv2-QA/special_tokens_map.json',\n",
       " 'AraElectra-ASQuADv2-QA/vocab.txt',\n",
       " 'AraElectra-ASQuADv2-QA/added_tokens.json',\n",
       " 'AraElectra-ASQuADv2-QA/tokenizer.json')"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_model.save_pretrained('AraElectra-ASQuADv2-QA')##-finetuned-dataset\n",
    "araelectra_tokenizer.save_pretrained('AraElectra-ASQuADv2-QA')##-finetuned-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y6xVUnzqN8mY",
    "outputId": "0402d428-4a17-4673-a43e-39e73f7eef77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForQuestionAnswering(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_model = ElectraForQuestionAnswering.from_pretrained('AraElectra-ASQuADv2-QA') ##modify to -finetuned-dataset?\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "qa_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H5jr262fN8mY",
    "outputId": "11d46944-9ebe-40fa-e30a-da322ec6a2a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:10<00:00,  3.52it/s]\n"
     ]
    }
   ],
   "source": [
    "imd_preds, script_preds = get_raw_preds(test_loader, qa_model,test_ids_to_idx,test_offset,asquad_test_contexts, 30, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HzlR2__CN8mY",
    "outputId": "1f0bb6bb-7574-4eff-9a52-8d8b17df2714"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'52': {'score': 9.824321, 'text': 'واحدة'}, '220': {'score': 5.4642625, 'text': 'عقب او قرب انتهاء اجتياز جميع المقررات المحددة'}, '218': {'score': 0.85698354, 'text': '4 سنوات ويجوز تمديدها لسنتين اضافتين بموافقة كلية الدراسات العليا . الحد الزمني الاقصى لطالب الدكتوراة بدوام جزئي'}, '107': {'score': 5.2785273, 'text': 'ويجوز تمديدها لفصل دراسي واحد'}, '244': {'score': 4.5828457, 'text': 'وتسقط كسور الازمنة الاعتبارية'}, '179': {'score': 2.2761552, 'text': 'وتسقط كسور الازمنة الاعتبارية'}, '247': {'score': 6.0235167, 'text': 'كسور الازمنة الاعتبارية'}, '110': {'score': 10.623768, 'text': '2 . 67'}, '57': {'score': 11.660757, 'text': 'نفقات الاشتراك وتذاكر سفر على الدرجة السياحية وبدل سفر يومي قدره 30 دينار كويتي'}, '275': {'score': 15.670231, 'text': 'الموقع الالكتروني لكلية الدراسات العليا'}, '13': {'score': 2.6145058, 'text': 'شروط التقديم على كلية الدراسات العليا متغيرة'}, '188': {'score': 3.8604045, 'text': 'وتسقط كسور الازمنة الاعتبارية'}, '19': {'score': 10.760812, 'text': 'صورة الجواز'}, '259': {'score': -1.3953853, 'text': 'الحد الزمني الادنى لاستكمال متطلبات درجة الدكتوراة هو سنتان ولا تحتسب فترات انقطاع الدراسة'}, '273': {'score': 3.615975, 'text': 'يمكن دراسة مقررات لغير المقيدين ببرامج الدراسات العليا بموافقة لجنة البرنامج'}, '224': {'score': -2.996343, 'text': 'الحد الزمني الاقصى لطالب الدكتوراة بدوام كامل هو 4 سنوات ويجوز تمديدها لسنتين اضافتين بموافقة كلية الدراسات العليا'}, '49': {'score': 13.808552, 'text': '30 دينار كويتي'}, '177': {'score': 9.444994, 'text': '4 سنوات'}, '255': {'score': 1.1068518, 'text': 'المشرف الاكاديمي'}, '77': {'score': 10.672335, 'text': 'الموافقة على برامج الدراسات العليا ووضع الأنظمة وتحديد أسس القبول وعمل التقويم الدوري وطرح برامج اختصاصية'}, '44': {'score': 4.7885127, 'text': 'المستندات المطلوبة'}, '104': {'score': 11.177922, 'text': 'شهادة الاجازة الجامعية الاولى ومعدل عام 2 . 33 فأعلى وان لا يكون قد سبق فصله من البرنامج'}, '154': {'score': 3.1420214, 'text': 'بدوام كامل'}, '249': {'score': -1.2966398, 'text': 'يقدم الطالب طلب اداء الامتحان التأهيلي للدكتوراة عقب او قرب انتهاء اجتياز جميع المقررات المحددة بمعدل متوسط لا يقل عن 3 نقاط .'}, '197': {'score': 14.309414, 'text': 'مستوى 500 فاعلى'}, '4': {'score': 10.617722, 'text': 'فصلين دراسيين'}, '24': {'score': 13.631627, 'text': 'قبل بداية الفصل الدراسي الأول'}, '54': {'score': 8.39016, 'text': 'نعم يجوز'}, '207': {'score': 1.9445121, 'text': 'عقب او قرب انتهاء اجتياز جميع المقررات المحددة بمعدل متوسط لا يقل عن 3 نقاط'}, '185': {'score': 3.8216789, 'text': 'يقدم الطالب طلب اداء الامتحان التأهيلي للدكتوراة عقب او قرب انتهاء اجتياز جميع المقررات المحددة بمعدل متوسط لا يقل عن 3 نقاط .'}, '169': {'score': 3.6965427, 'text': '5 سنوات'}, '70': {'score': 7.4415483, 'text': 'الأساتذة والأساتذة المشاركين'}, '180': {'score': 5.269085, 'text': 'شروط قبول المتقدم في برنامج الدكتوراة الحصول على درجة الماجستير بالاضافة الى شروط اخرى مذكورة في لائحة الكلية . متطلبات البرنامج نفسه'}, '296': {'score': 5.567051, 'text': 'القانون العام والقانون الخاص والاداب والعلوم والتربية والشريعة الإسلامية وإدارة الاعمال والصحة العامة'}, '93': {'score': 5.5741844, 'text': 'ويجوز تمديدها لفصل دراسي واحد'}, '239': {'score': 0.06851584, 'text': 'يفصل'}, '21': {'score': -2.156657, 'text': 'الجواز'}, '268': {'score': 2.027345, 'text': 'يمكن تحويل المشروع التفصيلي لطالب الدكتوراة الى ادارة الابحاث بالجامعة'}, '147': {'score': 3.272368, 'text': 'بدوام كامل'}, '245': {'score': 0.33908296, 'text': 'يفصل'}, '221': {'score': 12.023495, 'text': 'المشرف كرئيس اللجنة'}, '242': {'score': 12.40624, 'text': 'بناء على توصية من لجنة البرنامج'}, '23': {'score': -1.6612132, 'text': '2 . 67 نقاط من أصل 4 . 00 نقاط اما المعدل المطلوب للطالب الغير مقيد هو معدل عام 2 . 50 نقاط من أصل 4 . 00 نقاط'}, '251': {'score': -1.8044713, 'text': 'الحد الزمني الادنى لاستكمال متطلبات درجة الدكتوراة هو سنتان ولا تحتسب فترات انقطاع الدراسة'}, '82': {'score': 4.9146442, 'text': 'لجنة المجال'}, '130': {'score': 3.2934828, 'text': 'المشرف الاكاديمي'}, '83': {'score': 11.371716, 'text': 'الاشراف على برامج الدراسات العليا في الكلية'}, '161': {'score': 2.9501445, 'text': 'متطلبات البرنامج نفسه'}, '10': {'score': 5.668771, 'text': 'شريطة أن يجتاز الطالب البرنامج الدراسي المسجل عليه أولا'}, '231': {'score': 5.5411386, 'text': 'طبيعة المشكلة ومنهجية البحث والمراجع الاساسية والامكانات اللازمة لتنفيذه'}, '300': {'score': 12.327576, 'text': 'معدل عام 3 فترة سريان المنحة'}, '6': {'score': -0.46214676, 'text': 'اعلان التقديم'}, '170': {'score': 3.2351074, 'text': 'شروط قبول المتقدم في برنامج الدكتوراة الحصول على درجة الماجستير'}, '257': {'score': 6.775278, 'text': 'وتسقط كسور الازمنة الاعتبارية'}, '105': {'score': 5.163063, 'text': 'يجوز تمديدها لفصل دراسي واحد'}, '125': {'score': 7.274437, 'text': 'نوع الدوام في دبلوم الدراسات العليا اما كامل او جزئي'}, '142': {'score': -0.20681685, 'text': 'العبء الدراسي'}, '196': {'score': 5.9352145, 'text': 'الحد المسموح به للوحدات الدراسية المعتمدة التي يستطيع طالب الدكتوراة الحصول عليها من خارج الجامعة هو 30 % من الوحدات المطلوبة'}, '293': {'score': 9.668007, 'text': 'الكلية المعنية'}, '230': {'score': 1.5360408, 'text': 'وتسقط كسور الازمنة الاعتبارية'}, '28': {'score': 10.233963, 'text': 'قبول الطالب المشروط باجتيازه مواد دراسية محددة قبل البدء بالدراسات العليا'}, '171': {'score': 6.2311754, 'text': 'شروط قبول المتقدم في برنامج الدكتوراة الحصول على درجة الماجستير'}, '131': {'score': 6.630625, 'text': 'وتسقط كسور الازمنة الاعتبارية'}, '253': {'score': 14.071732, 'text': 'قبل نهاية الفصل الدراسي الثالث'}, '141': {'score': -1.1634711, 'text': 'يسجل طالب الدكتوراة مقرر رسالة الدكتوراة في جميع الفصول'}, '258': {'score': -0.61983454, 'text': 'الحد الزمني الادنى لاستكمال متطلبات درجة الدكتوراة هو سنتان ولا تحتسب فترات انقطاع الدراسة'}, '39': {'score': 5.6387873, 'text': '2 . 67'}, '238': {'score': 10.17921, 'text': 'المشرف كرئيس اللجنة'}, '112': {'score': 3.3833663, 'text': 'الحد الزمني الاعلى لاستكمال متطلبات دبلوم الدراسات العليا لطالب الدوام الكامل هو سنتين يجوز تمديدها لفصل دراسي واحد'}, '31': {'score': 3.2405472, 'text': 'المستندات المطلوبة'}, '87': {'score': 9.674297, 'text': 'ثلاثة أعضاء على الأقل . درجة أعضاء لجنة البرنامج تشمل أستاذ وأستاذ مساعد ومدرس'}, '149': {'score': 8.110413, 'text': 'مشرفه الاكاديمي'}, '47': {'score': 5.8437595, 'text': 'اعلان التقديم'}, '42': {'score': 7.0609717, 'text': 'اعلان التقديم'}, '213': {'score': 14.93676, 'text': 'المشرف الاكاديمي'}, '15': {'score': 3.6398356, 'text': 'المستندات المطلوبة'}, '133': {'score': 6.876177, 'text': 'ادارة الابحاث بالجامعة'}, '137': {'score': 4.0194206, 'text': 'ومن الممكن اضافة متطلبات اضافية عامة ضمن برنامج الدكتوراة او خاصة ضمن برنامج الطالب .'}, '29': {'score': 2.3266363, 'text': 'يمكن التقديم على أكثر من برنامج مختلف في أوقات مختلفة شريطة أن يجتاز الطالب البرنامج الدراسي المسجل عليه أولا'}, '206': {'score': 10.84307, 'text': '4 سنوات'}, '153': {'score': 10.390457, 'text': 'كلية الدراسات العليا بناء على توصية من لجنة البرنامج'}, '17': {'score': 7.285448, 'text': '2 . 67'}, '94': {'score': 3.7789636, 'text': 'الحد الزمني الاعلى لاستكمال متطلبات دبلوم الدراسات العليا لطالب الدوام الكامل هو سنتين يجوز تمديدها لفصل دراسي واحد'}, '12': {'score': 3.999535, 'text': '6 ساعات أسبوعيا'}, '254': {'score': 7.8095384, 'text': 'عقب او قرب انتهاء اجتياز جميع المقررات المحددة'}, '101': {'score': 12.570886, 'text': 'تقدير 2 . 67 في المقرر ومدة سنتين بين اجتياز واعتماد المقرر بحد اقصى وان يكون المقرر ضمن متطلبات البرنامج'}, '58': {'score': 8.591778, 'text': 'واحدة'}, '265': {'score': -0.38140368, 'text': 'الحد الزمني الادنى لاستكمال متطلبات درجة الدكتوراة هو سنتان ولا تحتسب فترات انقطاع الدراسة'}, '301': {'score': 11.0918865, 'text': 'منحة دراسية بمرتب مالي ومزايا متعددة'}, '232': {'score': 2.4606106, 'text': 'رسالة الدكتوراة هي رسالة بحثية يعدها الطالب بتوجيه المشرف الاكاديمي'}, '167': {'score': -1.1748111, 'text': 'شريطة ان لا يكون قد سبق للطالب دراستها .'}, '202': {'score': 0.9035334, 'text': 'عقب او قرب انتهاء اجتياز جميع المقررات المحددة'}, '26': {'score': 4.6088037, 'text': 'شريطة أن يجتاز الطالب البرنامج الدراسي المسجل عليه أولا'}, '235': {'score': 12.593543, 'text': 'من خلال مشرفه الاكاديمي'}, '50': {'score': 6.8795595, 'text': 'واحدة'}, '270': {'score': 2.7137728, 'text': 'الحد الاقصى للعبء الدراسي'}, '127': {'score': 5.320858, 'text': '2 . 67'}, '294': {'score': 9.176544, 'text': 'اجتياز المقررات الإضافية بمعدل متوسط لا يقل عن 3 نقاط ثم التحويل الى القبول النظامي'}, '226': {'score': 4.504438, 'text': 'وتسقط كسور الازمنة الاعتبارية'}, '241': {'score': 3.945826, 'text': '15'}, '144': {'score': 6.8641567, 'text': 'طبيعة المشكلة ومنهجية البحث والمراجع الاساسية والامكانات اللازمة لتنفيذه'}, '33': {'score': 2.8173537, 'text': 'شروط التقديم على كلية الدراسات العليا متغيرة'}, '138': {'score': 11.437067, 'text': 'المشرف كرئيس اللجنة'}, '63': {'score': 8.919695, 'text': '100 دينار كويتي'}, '160': {'score': 6.935235, 'text': 'يمكن تحويل المشروع التفصيلي لطالب الدكتوراة الى ادارة الابحاث بالجامعة لدعم تمويله .'}, '2': {'score': 2.0730011, 'text': 'يمكن التقديم على أكثر من برنامج مختلف في أوقات مختلفة شريطة أن يجتاز الطالب البرنامج الدراسي المسجل عليه أولا'}, '146': {'score': 5.530845, 'text': 'يفصل'}, '71': {'score': 8.011267, 'text': 'الأساتذة والأساتذة المشاركين'}, '51': {'score': 10.66845, 'text': '100 دينار كويتي'}, '250': {'score': 7.081638, 'text': 'عقب او قرب انتهاء اجتياز جميع المقررات المحددة'}, '48': {'score': 9.459288, 'text': 'واحدة'}, '89': {'score': 9.954783, 'text': 'سنة واحدة'}, '186': {'score': 2.211467, 'text': '4 سنوات ويجوز تمديدها لسنتين اضافتين بموافقة كلية الدراسات العليا . الحد الزمني الاقصى لطالب الدكتوراة بدوام جزئي'}, '113': {'score': 2.979714, 'text': 'الحد الزمني الاعلى لاستكمال متطلبات دبلوم الدراسات العليا لطالب الدوام الكامل هو سنتين يجوز تمديدها لفصل دراسي واحد'}, '289': {'score': 14.906903, 'text': 'مقدرة الطالب على انجاز بحث علمي'}, '92': {'score': 10.742643, 'text': 'الاشراف على برامج الدراسات العليا في الكلية ووضع القواعد التنظيمية والمقترحات والنظر فيها'}, '246': {'score': 12.6884365, 'text': 'من خلال مشرفه الاكاديمي'}, '86': {'score': 11.744108, 'text': 'الاشراف على برامج الدراسات العليا في الكلية'}, '276': {'score': 11.88489, 'text': '21'}, '62': {'score': 8.840891, 'text': 'ان يكون الطالب مسجلا بدوام كامل ولا تقيم اسرته في الكويت'}, '262': {'score': 9.244036, 'text': 'لجنة البرنامج'}, '30': {'score': 4.7398267, 'text': '3 . 00 نقاط من أصل 4 . 00 نقاط'}, '122': {'score': 4.6166615, 'text': 'الحد الزمني الاعلى لاستكمال متطلبات دبلوم الدراسات العليا لطالب الدوام الجزئي هو 3 سنوات ويجوز تمديدها لفصل دراسي واحد'}, '41': {'score': 2.4295197, 'text': 'المستندات المطلوبة عند التقديم على كلية الدراسات العليا هي الشهادة الاصلية ، البطاقة المدنية ، صور شخصية ، شهادة الخبرة الوظيفية'}, '123': {'score': 12.230196, 'text': 'تقدير 2 . 67 في المقرر ومدة سنتين بين اجتياز واعتماد المقرر بحد اقصى وان يكون المقرر ضمن متطلبات البرنامج'}, '3': {'score': 0.35751787, 'text': 'قبول نظامي أو قبول مشروط'}, '56': {'score': 10.838913, 'text': '100'}, '228': {'score': 5.523158, 'text': 'يقدم الطالب طلب اداء الامتحان التأهيلي للدكتوراة عقب او قرب انتهاء اجتياز جميع المقررات المحددة بمعدل متوسط لا يقل عن 3 نقاط .'}, '76': {'score': 7.9890676, 'text': 'عميد كلية الدراسات العليا'}, '278': {'score': 3.4538164, 'text': 'اجتياز 21 وحدة دراسية بمعدل متوسط 2 . 67 نقطه على الاقل'}, '174': {'score': 4.465693, 'text': 'يقدم الطالب طلب اداء الامتحان التأهيلي للدكتوراة عقب او قرب انتهاء اجتياز جميع المقررات المحددة بمعدل متوسط لا يقل عن 3 نقاط .'}, '102': {'score': 10.306496, 'text': '2 . 67'}, '291': {'score': 15.397613, 'text': 'مقدرة الطالب على انجاز بحث علمي'}, '67': {'score': 7.683527, 'text': 'واحدة'}, '227': {'score': 11.509684, 'text': 'بناء على توصية من لجنة البرنامج'}, '292': {'score': 3.586185, 'text': 'اجتياز 21 وحدة دراسية بمعدل متوسط 2 . 67 نقطه على الاقل'}, '96': {'score': 4.3792815, 'text': 'الحد الزمني الاعلى لاستكمال متطلبات دبلوم الدراسات العليا لطالب الدوام الكامل هو سنتين يجوز تمديدها لفصل دراسي واحد'}, '217': {'score': 0.16367838, 'text': 'شروط قبول المتقدم في برنامج الدكتوراة الحصول على درجة الماجستير بالاضافة الى شروط اخرى مذكورة في لائحة الكلية'}, '85': {'score': 5.9616785, 'text': 'لجنة المجال'}, '163': {'score': 12.283391, 'text': 'من خلال مشرفه الاكاديمي'}, '65': {'score': 9.9298115, 'text': 'واحدة'}, '252': {'score': 4.9561415, 'text': 'ولا تحتسب فترات انقطاع الدراسة'}, '295': {'score': 2.9264522, 'text': 'اجتياز 21 وحدة دراسية على الاقل من مقررات الدراسات العليا بمستوى 500 او اعلى . الشروط هي اجتياز 21 وحدة دراسية بمعدل متوسط 2 . 67 نقطه على الاقل'}, '281': {'score': 3.8979034, 'text': 'الرسوم يحددها مجلس الجامعة بناء على توصية مجلس كلية الدراسات العليا'}, '103': {'score': 4.691811, 'text': 'يجوز تمديدها لفصل دراسي واحد'}, '9': {'score': 3.4250023, 'text': 'صورة الجواز'}, '27': {'score': 8.447661, 'text': 'اختبار اللغة'}, '121': {'score': 13.825983, 'text': 'قبول نظامي'}, '284': {'score': 12.587925, 'text': '21'}, '165': {'score': -1.277489, 'text': 'يفصل'}, '120': {'score': 11.322889, 'text': 'تقدير 2 . 67 في المقرر ومدة سنتين بين اجتياز واعتماد المقرر بحد اقصى وان يكون المقرر ضمن متطلبات البرنامج'}, '157': {'score': 1.374227, 'text': 'الحد الزمني الاقصى لطالب الدكتوراة بدوام كامل'}, '195': {'score': 14.20043, 'text': 'قبل نهاية الفصل الدراسي الثالث'}, '91': {'score': 11.5185375, 'text': 'سنة واحدة'}, '88': {'score': 7.392387, 'text': 'لجنة تتولى إدارة البرنامج الخاص بها'}, '216': {'score': 4.518977, 'text': 'عقب او قرب انتهاء اجتياز جميع المقررات المحددة بمعدل متوسط لا يقل عن 3 نقاط'}, '143': {'score': 6.5757785, 'text': 'شروط قبول المتقدم في برنامج الدكتوراة الحصول على درجة الماجستير'}, '115': {'score': 5.450777, 'text': 'سنة دراسية واحدة'}, '68': {'score': 8.482713, 'text': 'نعم يجوز'}, '260': {'score': 8.80802, 'text': 'لجنة البرنامج'}, '269': {'score': 1.4744527, 'text': '500'}, '209': {'score': 6.4462194, 'text': 'رسالة الدكتوراة'}, '37': {'score': 7.0751314, 'text': 'قبل بداية الفصل الدراسي الأول'}, '204': {'score': 4.0319166, 'text': 'بموافقة كلية الدراسات العليا'}, '256': {'score': 11.739282, 'text': 'المشرف كرئيس اللجنة'}, '7': {'score': 4.358334, 'text': 'اعلان التقديم'}, '135': {'score': 9.18809, 'text': 'لا يقل تقديره في اي منها عن 3 نقاط'}, '78': {'score': 8.320143, 'text': 'المؤسسة المسؤولة عن الدراسات العليا في جامعة الكويت'}, '272': {'score': 8.917032, 'text': 'معدل عام 2 . 33'}, '72': {'score': 12.578888, 'text': 'مدراء البرامج بالكلية المعنية'}, '53': {'score': 9.91193, 'text': '3'}, '297': {'score': 8.232683, 'text': 'القانون العام والقانون الخاص والاداب والعلوم والتربية والشريعة الإسلامية وإدارة الاعمال والصحة العامة'}, '73': {'score': 4.85299, 'text': 'اتاحة فرص تعليم ومواكبة التطور العالمي وصنع المثقف العصري وتناول قضايا المجتمع الكويتي'}, '114': {'score': 5.1525574, 'text': 'وان يكون المقرر ضمن متطلبات البرنامج'}, '299': {'score': 9.936636, 'text': 'الشهادة الجامعية والا يقل المعدل العام عن 3 نقاط'}, '126': {'score': 12.9081955, 'text': '21'}, '290': {'score': 8.498577, 'text': 'اجتياز المقررات الإضافية بمعدل متوسط لا يقل عن 3 نقاط ثم التحويل الى القبول النظامي'}, '194': {'score': 2.515297, 'text': 'الحد الزمني الاقصى لطالب الدكتوراة بدوام كامل'}, '99': {'score': 13.624825, 'text': 'اذا انخفض معدله المتوسط عن 2 . 33 نقطة'}, '181': {'score': 4.816071, 'text': 'عقب او قرب انتهاء اجتياز جميع المقررات المحددة بمعدل متوسط لا يقل عن 3 نقاط'}, '214': {'score': 3.1661663, 'text': 'الماجستير'}, '203': {'score': -1.8514745, 'text': 'الحد الزمني الاقصى لطالب الدكتوراة بدوام جزئي'}, '139': {'score': -1.2097855, 'text': 'العبء الدراسي'}, '187': {'score': 3.9679341, 'text': 'وتسقط كسور الازمنة الاعتبارية'}, '36': {'score': -0.55583847, 'text': 'عن طريق الموقع الالكتروني'}, '222': {'score': 4.909452, 'text': 'متطلبات البرنامج نفسه'}, '189': {'score': 4.4558353, 'text': 'يقدم الطالب طلب اداء الامتحان التأهيلي للدكتوراة عقب او قرب انتهاء اجتياز جميع المقررات المحددة بمعدل متوسط لا يقل عن 3 نقاط .'}, '158': {'score': 5.6915226, 'text': 'يقدم الطالب طلب اداء الامتحان التأهيلي للدكتوراة عقب او قرب انتهاء اجتياز جميع المقررات المحددة بمعدل متوسط لا يقل عن 3 نقاط .'}, '148': {'score': 6.475847, 'text': '15 وحدة دراسية على الاقل'}, '32': {'score': 3.411396, 'text': 'شريطة أن يجتاز الطالب البرنامج الدراسي المسجل عليه أولا'}, '40': {'score': 0.2920211, 'text': 'ولا يمكن التقديم على أكثر من برنامج مختلف في نفس الوقت .'}, '271': {'score': 1.2536323, 'text': 'يكون القبول للدراسات العليا مشروطا'}, '159': {'score': 10.952869, 'text': 'يمكن تحويل المشروع التفصيلي لطالب الدكتوراة الى ادارة الابحاث بالجامعة لدعم تمويله'}, '229': {'score': 5.0272026, 'text': 'الحد المسموح به للوحدات الدراسية المعتمدة التي يستطيع طالب الدكتوراة الحصول عليها من خارج الجامعة هو 30 % من الوحدات المطلوبة'}, '277': {'score': 6.413102, 'text': 'القانون العام والقانون الخاص والاداب والعلوم والتربية والشريعة الإسلامية وإدارة الاعمال والصحة العامة'}, '14': {'score': 3.811998, 'text': '200 دينار كويتي'}, '219': {'score': 7.285714, 'text': 'عقب او قرب انتهاء اجتياز جميع المقررات المحددة'}, '237': {'score': 4.1797056, 'text': 'وتسقط كسور الازمنة الاعتبارية'}, '117': {'score': 7.2738113, 'text': 'نوع الدوام في دبلوم الدراسات العليا اما كامل او جزئي'}, '34': {'score': -2.9745855, 'text': 'الطالب الغير مقيد'}, '183': {'score': 4.5975003, 'text': '4 سنوات'}, '212': {'score': 2.066352, 'text': 'يفصل'}, '234': {'score': 3.8082166, 'text': 'ومن الممكن اضافة متطلبات اضافية عامة ضمن برنامج الدكتوراة او خاصة ضمن برنامج الطالب .'}, '178': {'score': -0.49069, 'text': 'يفصل'}, '59': {'score': 8.089381, 'text': 'نعم يجوز'}, '119': {'score': 9.491535, 'text': '3 سنوات'}, '90': {'score': 12.878808, 'text': 'الموافقة على برامج الدراسات العليا ووضع الأنظمة وتحديد أسس القبول وعمل التقويم الدوري وطرح برامج اختصاصية'}, '140': {'score': 1.2195537, 'text': 'الحد الزمني الاقصى لطالب الدكتوراة بدوام كامل هو 4 سنوات ويجوز تمديدها لسنتين اضافتين بموافقة كلية الدراسات العليا'}, '208': {'score': 2.386745, 'text': 'يفصل'}, '266': {'score': 12.749796, 'text': 'قبل نهاية الفصل الدراسي الثالث'}, '150': {'score': 14.360876, 'text': '15 وحدة دراسية على الاقل'}, '100': {'score': 4.6890244, 'text': 'الجوانب النظرية والتطبيقية'}, '61': {'score': 11.054682, 'text': 'ان يكون مسجلا ومستمرا كطالب نظامي بدوام كامل'}, '35': {'score': -1.2835246, 'text': 'الطالب الغير مقيد'}, '145': {'score': 4.4456825, 'text': 'عقب او قرب انتهاء اجتياز جميع المقررات المحددة بمعدل متوسط لا يقل عن 3 نقاط'}, '151': {'score': 6.568383, 'text': 'رسالة الدكتوراة'}, '109': {'score': 10.367318, 'text': 'تقدير 2 . 67 في المقرر ومدة سنتين بين اجتياز واعتماد المقرر بحد اقصى وان يكون المقرر ضمن متطلبات البرنامج'}, '111': {'score': 3.6477773, 'text': 'الحد الزمني الاعلى لاستكمال متطلبات دبلوم الدراسات العليا لطالب الدوام الكامل هو سنتين'}, '116': {'score': 4.6862874, 'text': 'سنتين'}, '5': {'score': 5.9122753, 'text': 'قبل بداية الفصل الدراسي الأول'}, '124': {'score': 5.020707, 'text': 'ويجوز تمديدها لفصل دراسي واحد'}, '79': {'score': 1.493772, 'text': 'مدير البرنامج'}, '191': {'score': -0.7053967, 'text': 'الحد الزمني الادنى لاستكمال متطلبات درجة الدكتوراة هو سنتان ولا تحتسب فترات انقطاع الدراسة'}, '45': {'score': 4.4590216, 'text': 'بتحويله'}, '210': {'score': 0.29227751, 'text': 'الحد الزمني الاقصى لطالب الدكتوراة بدوام كامل هو 4 سنوات ويجوز تمديدها لسنتين اضافتين بموافقة كلية الدراسات العليا'}, '69': {'score': 9.262292, 'text': 'واحدة'}, '240': {'score': 0.4340472, 'text': 'رسالة الدكتوراة هي رسالة بحثية يعدها الطالب بتوجيه المشرف الاكاديمي . يجب ان تثبت رسالة الدكتوراة قدرة الطالب على الاستقلالية في اجراء البحوث المبتكرة'}, '193': {'score': 7.612178, 'text': 'كسور الازمنة الاعتبارية'}, '55': {'score': 10.661117, 'text': 'الفصل الاول'}, '156': {'score': 8.142998, 'text': 'رسالة الدكتوراة هي رسالة بحثية'}, '1': {'score': 8.468614, 'text': 'قبل بداية الفصل الدراسي الأول'}, '182': {'score': 4.6602736, 'text': 'عقب او قرب انتهاء اجتياز جميع المقررات المحددة بمعدل متوسط لا يقل عن 3 نقاط'}, '129': {'score': 11.732464, 'text': 'شهادة الاجازة الجامعية الاولى ومعدل عام 2 . 33 فأعلى وان لا يكون قد سبق فصله من البرنامج'}, '136': {'score': 4.706998, 'text': 'متطلبات البرنامج نفسه'}, '283': {'score': 3.586185, 'text': 'اجتياز 21 وحدة دراسية بمعدل متوسط 2 . 67 نقطه على الاقل'}, '172': {'score': 13.078513, 'text': 'من خلال مشرفه الاكاديمي'}, '20': {'score': 9.571274, 'text': '2 . 67 نقاط من أصل 4 . 00 نقاط'}, '211': {'score': 1.9360564, 'text': '5'}, '16': {'score': 7.476257, 'text': '2 . 67'}, '84': {'score': 9.574905, 'text': 'مجلس كلية الدراسات العليا'}, '60': {'score': 6.3017235, 'text': 'شروط حضور المهمات العلمية لطالب الدراسات العليا ان يكون مسجلا ومستمرا كطالب نظامي بدوام كامل'}, '223': {'score': 0.39888176, 'text': 'يمكن تحويل المشروع التفصيلي لطالب الدكتوراة الى ادارة الابحاث بالجامعة لدعم تمويله .'}, '38': {'score': 0.83505166, 'text': 'فيقبل قبولا مشروطا وليس قبولا نظاميا . يوجد اعانة مالية لطلبة الدراسات العليا وهي نوعان : المعاونة العلمية والمنحة'}, '201': {'score': -0.27236986, 'text': 'الحد الزمني الادنى لاستكمال متطلبات درجة الدكتوراة هو سنتان ولا تحتسب فترات انقطاع الدراسة'}, '155': {'score': -1.7635884, 'text': 'الحد الزمني الاقصى لطالب الدكتوراة بدوام جزئي'}, '215': {'score': 5.235196, 'text': 'وتسقط كسور الازمنة الاعتبارية'}, '288': {'score': 6.6430893, 'text': 'جزئي او كامل'}, '166': {'score': 11.1399975, 'text': 'المشرف كرئيس اللجنة'}, '8': {'score': -1.9749371, 'text': 'سنوي قبل بداية الفصل الدراسي الأول'}, '267': {'score': 8.15773, 'text': 'وتسقط كسور الازمنة الاعتبارية'}, '264': {'score': -2.0115187, 'text': 'الحد الزمني الاقصى لطالب الدكتوراة بدوام كامل هو 4 سنوات ويجوز تمديدها لسنتين اضافتين بموافقة كلية الدراسات العليا'}, '263': {'score': 10.21286, 'text': 'عقب او قرب انتهاء اجتياز جميع المقررات المحددة'}, '18': {'score': 2.9323688, 'text': 'المستندات المطلوبة'}, '286': {'score': 6.297626, 'text': '15'}, '118': {'score': 4.7900343, 'text': 'ويجوز تمديدها لفصل دراسي واحد'}, '298': {'score': 8.094496, 'text': 'القانون العام والقانون الخاص'}, '176': {'score': 5.8662, 'text': 'بدوام كامل'}, '128': {'score': 3.912833, 'text': 'الحد الزمني الاعلى لاستكمال متطلبات دبلوم الدراسات العليا لطالب الدوام الكامل هو سنتين'}, '198': {'score': -2.14713, 'text': 'الحد الزمني الاقصى لطالب الدكتوراة بدوام جزئي'}, '261': {'score': 4.814356, 'text': 'متطلبات البرنامج نفسه'}, '168': {'score': 10.589937, 'text': 'دكتوراة الفلسفة'}, '200': {'score': 14.180855, 'text': 'قبل بداية الفصل الدراسي الثاني'}, '152': {'score': 3.6652164, 'text': 'يقدم الطالب طلب اداء الامتحان التأهيلي للدكتوراة عقب او قرب انتهاء اجتياز جميع المقررات المحددة بمعدل متوسط لا يقل عن 3 نقاط .'}, '25': {'score': 8.78879, 'text': 'ولا يمكن التقديم على أكثر من برنامج مختلف في نفس الوقت'}, '22': {'score': 9.013311, 'text': 'اعلان التقديم'}, '287': {'score': 5.949338, 'text': 'ولا يشترط اجتياز الامتحان الشامل او اعداد أطروحة .'}, '66': {'score': 6.036269, 'text': 'شروط حضور المهمات العلمية لطالب الدراسات العليا ان يكون مسجلا ومستمرا كطالب نظامي بدوام كامل'}, '205': {'score': -0.5145903, 'text': '500'}, '280': {'score': 5.785778, 'text': '15'}, '190': {'score': 10.901949, 'text': '5 سنوات'}, '282': {'score': 8.8376045, 'text': 'ولا يمكن استردادها بعد ذلك'}, '285': {'score': 4.858967, 'text': 'كشف درجات'}, '233': {'score': -0.96067476, 'text': 'وتسقط كسور الازمنة الاعتبارية'}, '236': {'score': 8.9631815, 'text': 'طبيعة المشكلة ومنهجية البحث والمراجع الاساسية والامكانات اللازمة لتنفيذه'}, '134': {'score': -0.5473193, 'text': 'الحد الزمني الادنى لاستكمال متطلبات درجة الدكتوراة هو سنتان ولا تحتسب فترات انقطاع الدراسة'}, '64': {'score': 13.239241, 'text': '30 دينار كويتي'}, '248': {'score': 9.857248, 'text': 'سنتين'}, '97': {'score': 5.1572247, 'text': 'يجوز تمديدها لفصل دراسي واحد'}, '274': {'score': 5.380171, 'text': 'ولا يمكن استردادها بعد ذلك'}, '164': {'score': 11.529011, 'text': 'المشرف كرئيس اللجنة'}, '11': {'score': 5.294935, 'text': 'الموقع الالكتروني'}, '75': {'score': 12.442391, 'text': 'الاشراف على برامج الدراسات العليا في الكلية'}, '225': {'score': 3.690165, 'text': 'شروط قبول المتقدم في برنامج الدكتوراة الحصول على درجة الماجستير بالاضافة الى شروط اخرى مذكورة في لائحة الكلية . متطلبات البرنامج نفسه'}, '243': {'score': 1.5963142, 'text': 'الحد المسموح به للوحدات الدراسية المعتمدة التي يستطيع طالب الدكتوراة الحصول عليها من خارج الجامعة هو 30 % من الوحدات المطلوبة'}, '74': {'score': 10.231618, 'text': 'تخطيطا وتنفيذا وتطويرا'}, '108': {'score': 13.156446, 'text': '21'}, '46': {'score': 7.0403147, 'text': 'الطالب المقيد ليس بالضرورة أن يقبل قبولا نظاميا في كل الأحوال لأنه قد يكون مستوفيا لشرط المعدل المطلوب للقبول'}, '106': {'score': 8.747679, 'text': 'سنة دراسية واحدة'}, '175': {'score': 10.317669, 'text': 'المشرف كرئيس اللجنة'}, '192': {'score': 1.6592977, 'text': 'متطلبات البرنامج نفسه'}, '43': {'score': 13.4020405, 'text': 'قبل بداية الفصل الدراسي الأول'}, '132': {'score': 10.68755, 'text': 'لجنة البرنامج'}, '184': {'score': 13.630596, 'text': 'قبل نهاية الفصل الدراسي الثالث'}, '279': {'score': 1.5239782, 'text': 'شروط القبول المشروط باجتياز مقررات اضافية هي اجتياز المقررات الإضافية بمعدل متوسط لا يقل عن 3 نقاط ثم التحويل الى القبول النظامي'}, '199': {'score': 8.109787, 'text': 'عقب او قرب انتهاء اجتياز جميع المقررات المحددة'}, '98': {'score': 12.905382, 'text': '21'}, '173': {'score': 9.950726, 'text': 'لجنة البرنامج'}, '81': {'score': 8.451508, 'text': 'عميد الكلية والعمداء المساعدون ورؤساء اللجان وأعضاء هيئة التدريس وأعضاء يسميهم مدير الجامعة'}, '95': {'score': 5.9453516, 'text': 'سنة دراسية واحدة'}, '80': {'score': 7.328558, 'text': 'عميد كلية الدراسات العليا'}, '162': {'score': 4.7701073, 'text': 'شروط قبول المتقدم في برنامج الدكتوراة الحصول على درجة الماجستير'}}\n"
     ]
    }
   ],
   "source": [
    "print(imd_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "id": "ARsmW00kN8mY"
   },
   "outputs": [],
   "source": [
    "def get_preds2(total_preds,data_path): \n",
    "  preds_path = os.path.join('preds')\n",
    "  if not os.path.exists(preds_path):\n",
    "    os.mkdir(preds_path)\n",
    "  text_preds_path = os.path.join(preds_path, 'preds.json')\n",
    "  jsonString = json.dumps(total_preds)\n",
    "  jsonFile = open(text_preds_path, \"w\")\n",
    "  jsonFile.write(jsonString)\n",
    "  jsonFile.close()\n",
    "  !python /content/Arabic-MRC/evaluatev2.py /content/asquadv2-test.json /content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth/preds/preds.json electra  \n",
    "\n",
    "  ##return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tO-J62nRN8mY",
    "outputId": "46350fcd-a0e9-4a2f-cf0e-e6abcfb2758e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 2.990033222591362,\n",
      "  \"f1\": 6.1972921266246885,\n",
      "  \"total\": 301,\n",
      "  \"HasAns_exact\": 2.990033222591362,\n",
      "  \"HasAns_f1\": 6.1972921266246885,\n",
      "  \"HasAns_total\": 301\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "qa_result_dict = get_preds2(script_preds, \"/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth/preds\" ) \n",
    "##'Data/asquadv2-test.json','Runs/AraElectraDecoupledAsquadv2/train/span/fourth/test-eval\n",
    "### '/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth/preds' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EgSc8ION8mY",
    "outputId": "38c4b109-bd0b-46ee-cbf3-18541827522c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title                                   تنظيم كلية الدراسات العليا\n",
      "context          رسالة كلية الدراسات العليا هي العمل المخطط اله...\n",
      "question                         ما هي رسالة كلية الدراسات العليا؟\n",
      "answer           العمل المخطط الهادف الى المساهمة في تنمية إمكا...\n",
      "answer_start                                                    30\n",
      "is_impossible                                                False\n",
      "count                                                            1\n",
      "ID                                        56be85543aeaaa14008c9063\n",
      "Name: 0, dtype: object\n",
      "title                                               درجة الماجستير\n",
      "context          شروط القبول النظامي للماجستير هي الحصول على در...\n",
      "question                     ما هي موانع القبول النظامي للماجستير؟\n",
      "answer           الفصل الأكاديمي أو حصول المتقدم على دبلوم دراس...\n",
      "answer_start                                                   251\n",
      "is_impossible                                                False\n",
      "count                                                          105\n",
      "ID                                        56bf89cfa10cfb1400551163\n",
      "Name: 104, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0])\n",
    "\n",
    "print(df.iloc[104])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFGZoBl2G5fL"
   },
   "source": [
    "### **Useful tools** (IGNORE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHZUEQXwDMfU"
   },
   "source": [
    "**Zeyad Ahmed recommendations**\n",
    " https://huggingface.co/ZeyadAhmed/AraElectra-Arabic-SQuADv2-QA \n",
    "In part a:\n",
    "- you are loading the model into something called huggingface pipeline (essentially it's like the whole process of tokenization and passing this tokenization to the model and preprocess the output to get the answer)\n",
    "-So based on the previous declaration you can't fine tune the model through the pipeline.\n",
    "\n",
    "in part b)\n",
    "-I'm showing how can you load the model only so you can treat it as a normal pytorch model and finetune it or use it as you want\n",
    "-So part b does not affect the process at all it's just an extra reference to how to load and use the model separately.\n",
    "\n",
    "\n",
    "**Using Zeyad Ahmed Script for Finetuning**\n",
    "\n",
    "1-To change you file from csv format to json format I have the dataset initially as csv format and changed to json using this script https://github.com/zeyadahmed10/Arabic-MRC/blob/main/Translator/translation2dataset.py my csv obviously differs from you but it can guide you\n",
    "\n",
    "2-regarding the finetuing this notebook https://github.com/zeyadahmed10/Arabic-MRC/blob/main/AraElectraDecoupling-ASQuADv2.ipynb will help you it includes the whole process of data processing, checkpoint loading , training and testing\n",
    "\n",
    "3-you can have any number of questions for a one context as you want no maximum limit\n",
    "\n",
    "4-you can create the missing fields in the csv in the fly like answer_start, id and any some fields will not contribute to the training you can make it as null refer to the notebook in (2) to know more about the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sk9AsoiBMMLg",
    "outputId": "822fecc8-4cbc-4e9a-ebd4-b49044895787"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "{'score': 0.27281802892684937, 'start': 41, 'end': 82, 'answer': 'المعدل المطلوب للطالب الغير مقيد هو 2 . 5'}\n"
     ]
    }
   ],
   "source": [
    "###Direct usage of zeyads code\n",
    "from transformers import ElectraForQuestionAnswering, ElectraForSequenceClassification, AutoTokenizer, pipeline\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "#only preprocessing\n",
    "model_name=\"aubmindlab/araelectra-base-discriminator\"\n",
    "prep_object = ArabertPreprocessor(model_name=model_name)\n",
    "question = prep_object.preprocess('ما هو المعدل المطلوب للطالب الغير مقيد؟')\n",
    "context = prep_object.preprocess('''\n",
    "\n",
    "المعدل المطلوب للطالب المقيد هو 2.67. المعدل المطلوب للطالب الغير مقيد هو 2.5. من شروط التقديم على الدراسات العليا هو شهادة التخرج وشهادة اللغة وكشف الدرجات.\n",
    "\n",
    "''')\n",
    "# a) Get predictions using his finetuned model\n",
    "#solution: train his model using the script?\n",
    "qa_modelname = '/content/AraElectra-ASQuADv2-QA'\n",
    "##cls_modelname = '/content/AraElectra-ASQuADv2-CLS'\n",
    "qa_pipe = pipeline('question-answering', model=qa_modelname, tokenizer=qa_modelname)\n",
    "##cls_pipe = pipeline('question-answering', model=cls_modelname, tokenizer=cls_modelname)\n",
    "QA_input = {\n",
    "    'question': question,\n",
    "    'context': context\n",
    "}\n",
    "'''\n",
    "CLS_input = {\n",
    "    'question': question,\n",
    "    'context': context\n",
    "}'''\n",
    "##print(CLS_input)\n",
    "qa_res = qa_pipe(QA_input)\n",
    "##cls_res = cls_pipe(CLS_input)\n",
    "##print(CLS_input)\n",
    "threshold = 0.5 #hyperparameter can be tweaked\n",
    "## note classification results label0 probability it can be answered label1 probability can't be answered \n",
    "## if label1 probability > threshold then consider the output of qa_res is empty string else take the qa_res\n",
    "# b) Load model & tokenizer\n",
    "'''\n",
    "qa_model = ElectraForQuestionAnswering.from_pretrained(qa_modelname)\n",
    "cls_model = ElectraForSequenceClassification.from_pretrained(cls_modelname)\n",
    "tokenizer = AutoTokenizer.from_pretrained(qa_modelname)'''\n",
    "print('here')\n",
    "print(qa_res)\n",
    "##print(cls_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "TvZg3dqY32P2",
    "outputId": "0f1d1565-ba76-40ca-97c1-7e52487cf6db"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"ولن نبالغ إذا قلنا: إن 'هاتف'أو'كمبيوتر المكتب' في زمننا هذا ضروري\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arabert.preprocess import ArabertPreprocessor\n",
    "\n",
    "model_name = \"araelectra-base-discriminator\"\n",
    "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
    "\n",
    "text = \"ولن نبالغ إذا قلنا: إن 'هاتف' أو 'كمبيوتر المكتب' في زمننا هذا ضروري\"\n",
    "arabert_prep.unpreprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "46uLq-SnahRf",
    "outputId": "0cc054d7-4398-4211-bcda-36f4da168286"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"ولن نبالغ إذا قلنا : إن ' هاتف ' أو ' كمبيوتر المكتب ' في زمننا هذا ضروري\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arabert.preprocess import ArabertPreprocessor\n",
    "\n",
    "model_name=\"araelectra-base-discriminator\"\n",
    "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
    "\n",
    "text = \"ولن نبالغ إذا قلنا: إن 'هاتف' أو 'كمبيوتر المكتب' في زمننا هذا ضروري\"\n",
    "arabert_prep.preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408,
     "referenced_widgets": [
      "6c8a589295454e188871f3c8dd707f58",
      "fd2ed96c8faa4b5abe527042fc33f197",
      "8a09c6b2e8644fb7b850527098137cbd",
      "1b529ac77c134ca6bb8929f07522a6b7",
      "11d51caf3b1e429db31f5174298030d4",
      "e2c6c1279df648f8a737bd6aacea9d09",
      "37a511e1a79c4c37843f2fb44fc8348e",
      "e6620bec34dd4ea7b53d0c5bbcee4cff",
      "39c5233a832442ea836fc5f405f44432",
      "1035b3d53d484ffe8e0c9c6ab2c99e9c",
      "5804ae2ab5084942934399ed4f621085",
      "b24f6fed241a425d95190f61ab6bac70",
      "93ffd6e701ff4869b02ad4e4763b9469",
      "2131168451d447ea8b614276b40b8ebb",
      "fbd86e127f964081957643f20c3f28fe",
      "dd323521333a40db938dbe2af3a57a1e",
      "d385cf2a9494442ca3874c387297f8b7",
      "171b86ecf305422b94d31f6248230307",
      "e562d0c7ad87476e8f078fbaafaed409",
      "0ab612c6e90e4ee09ce8ffb0b6b603b0",
      "0d9017fb0936420ba3bb9aabd68f21fe",
      "3d14824c8aa04bc0ab6517b1968f9afc",
      "41e2fe39171845688d1f41897c158d3c",
      "2bc85cdaa11f41f990fc46e9bf6140b2",
      "54bd585c006a4d06a2a5153fe9ecd9d5",
      "bf90c8944f31454288a5bdfe3d065f7d",
      "d9997e34d75042cfb7222bb61ac500e9",
      "5b019d94b0084be592882615837bdac2",
      "26388ede28624e5c92b20f12e7b8c74d",
      "aa4326673dbd4d69948f4c609b355a40",
      "0ef25984b04b442ea7d66451037cdbec",
      "8922e243365c412b95be7d25ce91fb44",
      "7b479e6b74934476b068037af7f148d8",
      "54fd8561f22646289638cfd5d4d6f039",
      "131733d1e4994e32973f4b83da3c4c78",
      "81eab8c6a699452bb12f8033cee6eb73",
      "8c8e61761df842e1b9642692c614a450",
      "5c6df69d8be940bfa167f0626f292e9a",
      "61b61332907a4b67847c6b8545e510f4",
      "720af14c3f344c70b2d6dc46eabd275f",
      "db501948d1d148a29977a85b88eed860",
      "8fd03680baca4154afc5f32419490176",
      "06503c92b2d04f1b898163a8b9583741",
      "08c418a7c1ca4a4da60f8373cd953147"
     ]
    },
    "id": "WrEkuv8k-zjA",
    "outputId": "5791606e-33d8-4195-ce65-007928de91f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration FatemahAlsubaiei--mydata-9ebc89f6a833abe9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/FatemahAlsubaiei--mydata to /root/.cache/huggingface/datasets/FatemahAlsubaiei___csv/FatemahAlsubaiei--mydata-9ebc89f6a833abe9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8a589295454e188871f3c8dd707f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24f6fed241a425d95190f61ab6bac70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/175M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e2fe39171845688d1f41897c158d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54fd8561f22646289638cfd5d4d6f039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/FatemahAlsubaiei___csv/FatemahAlsubaiei--mydata-9ebc89f6a833abe9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n",
      "{'title': 'بيونسيه', 'context': 'بيونسيه جيزيل نولز-كارتر (بالإنجليزية: Beyoncé Giselle Knowles-Carter) هي مغنية وكاتبة أغاني ومنتجة أسطوانات وممثلة أمريكية، ولدت في 4 سبتمبر 1981. ولدت وترعرعت في هيوستن ، تكساس ، وأدت في العديد من مسابقات الغناء والرقص عندما كانت طفلة ، وارتفعت إلى الشهرة في أواخر 1990s كمغنية رئيسية في مجموعة R & B للفتيات Destiny\\'s Child. شهدت فترة توقفهما إصدار ألبوم بيونسيه الأول ، Dangerously in Love (2003) ، الذي أسسها كفنانة منفردة في جميع أنحاء العالم ، وحصل على خمس جوائز غرامي وعرض بيلبورد هوت 100 أغنية منفردة رقم واحد \"Crazy in Love\" و \"Baby Boy\".', 'question': 'ما هي المجالات التي تنافست فيها بيونسيه عندما كانت تكبر؟', 'answer': 'الغناء والرقص', 'answer_start': 207, 'is_impossible': False, 'count': 2, 'ID': '56be85543aeaaa14008c9065'} here1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#to check zeyad dataset is actually being read by importing it from hf\n",
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset(\n",
    "  'FatemahAlsubaiei/mydata', split='train'\n",
    ")\n",
    "print(dataset[1],\"here1\")\n",
    "print(dataset['answer'],\"here2\")\n",
    "print(\"here3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-823FrXxGU-G"
   },
   "source": [
    "### **Running Zeyad's finetuning script on my own dataset - (WITH CLASSIFICATION)** NEGLECT THIS PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yPEMA_oik8Jl",
    "outputId": "f04e8cee-de8b-4e77-d2a8-6953096e61b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f126f1f7a30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "import os\n",
    "import shutil\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, ElectraForQuestionAnswering, DataCollatorWithPadding,BertModel, ElectraForSequenceClassification, ElectraModel\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "torch.manual_seed(3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "m_OrF8lzlz8S"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def add_end_index(answer, context):\n",
    "  ## 1 if span match the context 0 otherwise\n",
    "  text = answer['text']\n",
    "  start_idx = answer['answer_start']\n",
    "  end_idx = start_idx + len(text)\n",
    "  answer['answer_end'] = end_idx\n",
    "  if text == context[start_idx:end_idx]:\n",
    "    answer['answer_end'] = end_idx\n",
    "    return False\n",
    "  for i in range(1,3):\n",
    "    if text == context[start_idx-i:end_idx-i]:\n",
    "      answer['answer_end']= end_idx-1\n",
    "      answer['answer_start'] = start_idx-1\n",
    "      return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Z-E7-G0nmAoh"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def arabert_preprocess(context,question, answer, arabert_prep):\n",
    "    answer['text'] = arabert_prep.preprocess(answer['text'])\n",
    "    context = arabert_prep.preprocess(context)\n",
    "    question = arabert_prep.preprocess(question)\n",
    "    res = context.find(answer['text'])\n",
    "    if res !=-1:\n",
    "        answer['answer_start'] = res\n",
    "    return context, question, answer, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "_fFGb5KLmWpg"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def Read_AAQAD(path,arabert_prep):\n",
    "  contexts =[]\n",
    "  answers =[]\n",
    "  questions =[]\n",
    "  IDs= []\n",
    "  plausible = []\n",
    "  cnt = 0\n",
    "  with open(path) as f:\n",
    "    aaqad_dict = json.load(f)\n",
    "    for article in aaqad_dict['data']:\n",
    "      for passage in article['paragraphs']:\n",
    "        context = passage['context']\n",
    "        for qa in passage['qas']:\n",
    "          question = qa['question']\n",
    "          if 'plausible_answers' in qa.keys():# there is two cases if the question have no answer then use plausible answer\n",
    "            access = 'plausible_answers'\n",
    "            plausible.append(True)\n",
    "          else:\n",
    "            access = 'answers'\n",
    "            plausible.append(False)\n",
    "          for answer in qa[access]:\n",
    "            context,question, answer, res =  arabert_preprocess(context,question, answer, arabert_prep)\n",
    "            #if res==-1:\n",
    "            #  cnt+=1\n",
    "            #  continue\n",
    "            flag = add_end_index(answer, context) #if false dont add the \n",
    "            cnt =cnt + flag\n",
    "            flag = False\n",
    "            if not flag:\n",
    "              contexts.append(context)\n",
    "              answers.append(answer)\n",
    "              questions.append(question)\n",
    "              IDs.append(int(qa['id']))\n",
    "  return contexts,questions,answers,plausible,IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "BOCUMTUtmYbn"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def fix_ids(path):\n",
    "  #IDs need to be fixed for evaluating purposes\n",
    "    a_file = open(path, \"r\")\n",
    "    json_object = json.load(a_file)\n",
    "    a_file.close()\n",
    "    idx_cnt = 1\n",
    "    for article in json_object['data']:\n",
    "      for passage in article['paragraphs']:\n",
    "        context = passage['context']\n",
    "        for qa in passage['qas']:\n",
    "            qa['id'] = str(idx_cnt)\n",
    "            idx_cnt = idx_cnt + 1\n",
    "    a_file = open(path, \"w\")\n",
    "    json.dump(json_object, a_file)\n",
    "    a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "QTzUAKVcmhno"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "model_name = \"araelectra-base-discriminator\"\n",
    "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
    "fix_ids('/content/asquadv2-train.json')\n",
    "fix_ids('/content/asquadv2-val.json')\n",
    "fix_ids('/content/asquadv2-test.json')\n",
    "asquad_train_contexts, asquad_train_questions, asquad_train_answers,asquad_train_plausible, asquad_train_ids = Read_AAQAD('/content/asquadv2-train.json', arabert_prep)\n",
    "asquad_val_contexts, asquad_val_questions, asquad_val_answers,asquad_val_plausible, asquad_val_ids = Read_AAQAD('/content/asquadv2-val.json', arabert_prep)\n",
    "asquad_test_contexts, asquad_test_questions, asquad_test_answers,asquad_test_plausible, asquad_test_ids = Read_AAQAD('/content/asquadv2-test.json', arabert_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DMNxH4_0nFau",
    "outputId": "a9f45f0e-ceeb-456b-a6e3-3a7297210a8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "len(asquad_test_answers)+len(asquad_train_answers)+len(asquad_val_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0R9HLAkDnLry",
    "outputId": "867d7758-1742-4108-9cf8-16343660e538"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "print(len(asquad_test_answers))\n",
    "print(len(asquad_val_answers))\n",
    "print(len(asquad_train_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xd5KiLb4nN96",
    "outputId": "62af6745-c694-4552-8a56-54064079d93c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "sum(asquad_test_plausible)/len(asquad_test_plausible) #shows the percentage of not answerd questions\n",
    "#zero because i have no unanswerable questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_Afq-6cnUrS",
    "outputId": "e4492586-4088-46c5-fb28-bfabbafb6022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "print(sum(asquad_train_ids)==len(asquad_train_ids)*(len(asquad_train_ids)+1)/2)\n",
    "print(sum(asquad_val_ids)==len(asquad_val_ids)*(len(asquad_val_ids)+1)/2)\n",
    "print(sum(asquad_test_ids)==len(asquad_test_ids)*(len(asquad_test_ids)+1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "cgh7OGHinZR1"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def get_answered_feat(contexts, questions, answers, plausible):\n",
    "    new_contexts, new_questions, new_answers = [], [], []\n",
    "    for i in range(len(answers)):\n",
    "        if plausible[i] == False:\n",
    "            new_contexts.append(contexts[i])\n",
    "            new_questions.append(questions[i])\n",
    "            new_answers.append(answers[i])\n",
    "    return new_contexts, new_questions, new_answers\n",
    "span_train_contexts, span_train_questions, span_train_answers = get_answered_feat(asquad_train_contexts, asquad_train_questions, asquad_train_answers, asquad_train_plausible)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I7_u7eqLnh6o",
    "outputId": "019659bc-a58f-456d-d36f-c1ec1426f57c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 48\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "print(len(span_train_contexts), len(asquad_train_contexts))\n",
    "print(sum(asquad_test_plausible))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "fbf0e5cf51374c0ab505b35386e48d59",
      "bd66c9d0d7dc4d8cb3ccaf3f71f44698",
      "85a7df6412b54bbeb15eba4b9765787e",
      "2c367e5b50b34f0c89fc27067eb73be8",
      "e55678f7981d4af6b371b2615609ce9b",
      "59e7609502424d7aa735d28b00bf3c3f",
      "16316f23dfaa43899810eca09b7a051d",
      "7eeaec8211414d2d93b60e1351a8adf4",
      "1182976732e2448abce96f45dba0a8ea",
      "6077d913f11b45d88e251fcac820aad8",
      "32615ff938604385978cf6bc49167cda",
      "97bb20443249423f9c3ba7b9d21c3d5b",
      "4aa5c1072cd74d4e9d66ce721a3a292f",
      "f92fae07611a4011812c111a95adfe6b",
      "c0314b6cfae14bbaa499ffbbcccab3cf",
      "a42e5f811a3d4d8a8750f445aab6b775",
      "7884180dc346496db0cdbb90dada18bc",
      "db982adddeff48088c05eabc29c89db5",
      "064c4d8c864b48d88135fdb93cc853b9",
      "6b0e89231e2a452588d0bb8f7d7300e7",
      "faf432c7ccd84d25834f852069db1113",
      "a66d4a21a0914ddb980e44db84eaf024",
      "5ec6af70f9ed411287ec2c90a8db6f01",
      "5d6c42c1057c42c7a3e29cb5a04ed2c0",
      "196c2ade28e14fa0b4ae9879c61d6a1f",
      "d6d78188526b4e2eb1fb67a9d63f6d95",
      "8aa0851d6f5f4aaa8d711faa772986ed",
      "99a83e39880a4251a0929e4dadd1fe97",
      "bf6f9af431714ce281de717ef35e8126",
      "c8f7b403065f4e1fbe34631a1abe5881",
      "f1a54f32f1e6409b87e84658c9162089",
      "53b804755cc049228a7c2ac564770d3b",
      "0615f6816b6d4ad8ac7688a0a3ac5193",
      "dfb800463b774ea989e890f42da41796",
      "35650f40623a434c97c8aecdb142e1a4",
      "6dc6962a844b4870bfcaf9aa901f80ce",
      "e06ddf92c7d54867893a753d78becca8",
      "661d4b3ea00a4d839b130e043fe0266f",
      "4d739003cb1a456490a3628d470b8389",
      "99a11033c6d14a77bc8974f6d940bee6",
      "85c19587d95b468187f9deed9ef66a30",
      "a116dae153944f31bad2308c6f6866fd",
      "60064dfff525411fa1a6584bf6dac7d3",
      "52b6e26c188c4c1d985ba9c6a2080cd3",
      "71616382b393460ba4337e52d37d366d",
      "ed31b1b1d5714b398426da46ce9f790d",
      "d5fd24ef28cf4dd0aafb95c4c4d68cca",
      "1614656c3d9a431e8d4e55aea72ba8ef",
      "b2b63a8e9440448abf2bf5497115b3fa",
      "7fc9fb117c024527a77041901fdc082f",
      "82e18e571a354972952310f397b8cdb9",
      "7779c82868944e8cbff7ea825bee092e",
      "f889e5bd292645a0b52a63ea8a2014b7",
      "2cf62d2389a940e4824857b31f5f0fd4",
      "70e0b8d910514582be69f3c39a0113cc"
     ]
    },
    "id": "YtKoP2RvntjM",
    "outputId": "1c8ec521-fca5-41f3-e3a0-dc0182207e4f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf0e5cf51374c0ab505b35386e48d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/392 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97bb20443249423f9c3ba7b9d21c3d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/503 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec6af70f9ed411287ec2c90a8db6f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/825k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb800463b774ea989e890f42da41796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.64M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71616382b393460ba4337e52d37d366d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title\n",
    "#Creating the tokenizer\n",
    "model_name =  \"aubmindlab/araelectra-base-discriminator\"\n",
    "araelectra_tokenizer = AutoTokenizer.from_pretrained(model_name,do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "GyhSNlsPnv9n"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "train_encodings = araelectra_tokenizer(asquad_train_questions, asquad_train_contexts, truncation = True )\n",
    "span_train_encodings = araelectra_tokenizer(span_train_questions, span_train_contexts, truncation=True)\n",
    "val_encodings = araelectra_tokenizer(asquad_val_questions, asquad_val_contexts, truncation=True, return_offsets_mapping=True)\n",
    "test_encodings = araelectra_tokenizer(asquad_test_questions, asquad_test_contexts, truncation=True,  return_offsets_mapping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ui9f252Unz_2"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "val_offset = val_encodings['offset_mapping']\n",
    "del val_encodings['offset_mapping']\n",
    "test_offset = test_encodings['offset_mapping']\n",
    "del test_encodings['offset_mapping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MGpU1vPWn2rW",
    "outputId": "1acca252-dbeb-4195-fcf9-9921a1ca69eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5}\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "val_ids_to_idx = {k:i for i,k in enumerate(asquad_val_ids)}\n",
    "test_ids_to_idx = {k:i for i,k in enumerate(asquad_test_ids)}\n",
    "print(val_ids_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "i-ZdZREzn5cn"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def index_to_token_position(encodings , answers):\n",
    "  start_positions = list()\n",
    "  end_positions = list()\n",
    "  for i in range(len(answers)):\n",
    "    start_positions.append(encodings.char_to_token(i, answers[i]['answer_start'], 1))\n",
    "    end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'], 1))\n",
    "    #if context truncated\n",
    "    if start_positions[-1] is None: \n",
    "      start_positions[-1] = araelectra_tokenizer.model_max_length\n",
    "    #if end index is space\n",
    "    itt = 1\n",
    "    while end_positions[-1] is None: \n",
    "      end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end']-itt, 1)\n",
    "      itt = itt + 1 \n",
    "  encodings.update({'start_positions': torch.tensor(start_positions), 'end_positions': torch.tensor(end_positions)})\n",
    "  encodings['start_positions'] = encodings['start_positions'].view(len(answers), 1)\n",
    "  encodings['end_positions'] = encodings['end_positions'].view(len(answers), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Gm9LWGWjn-iz"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "index_to_token_position(span_train_encodings, span_train_answers)\n",
    "index_to_token_position(val_encodings, asquad_val_answers)\n",
    "index_to_token_position(test_encodings, asquad_test_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlU2dKW3LIcN"
   },
   "source": [
    "not needed? because i will remove CLS parts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "sbgAYz_LoM9J"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def add_weights_labels_tensors(encodings, plausible):\n",
    "  plausible = torch.tensor(plausible)\n",
    "  weights = torch.ones(plausible.shape)\n",
    "  no_ans = torch.ones(plausible.shape)\n",
    "  weights[plausible==False]=2.0\n",
    "  no_ans[plausible==False]=0.0\n",
    "  weights = weights.view(-1,1)\n",
    "  no_ans = no_ans.view(-1,1)\n",
    "  encodings.update({'weights':weights, 'no_ans':no_ans})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Uckn46W7oO5o"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "add_weights_labels_tensors(train_encodings, asquad_train_plausible)\n",
    "add_weights_labels_tensors(val_encodings, asquad_val_plausible)\n",
    "add_weights_labels_tensors(test_encodings, asquad_test_plausible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "i4xtkpPYoRVe"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "val_encodings['IDs'] = asquad_val_ids\n",
    "test_encodings['IDs'] = asquad_test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yUd3z0b4oUCL",
    "outputId": "cdfd8c5b-8a55-462c-b0c9-9d0245eb3a73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'weights', 'no_ans'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions', 'weights', 'no_ans', 'IDs'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions', 'weights', 'no_ans', 'IDs'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "print(train_encodings.keys())\n",
    "print(val_encodings.keys())\n",
    "print(test_encodings.keys())\n",
    "print(span_train_encodings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "6bYUEEZFoYyd"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "uXSXero7oeCi"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "class AqadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: val[idx] for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "cls_train_dataset = AqadDataset(train_encodings)\n",
    "span_train_dataset = AqadDataset(span_train_encodings)\n",
    "val_dataset = AqadDataset(val_encodings)\n",
    "test_dataset = AqadDataset(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "NVqPv55EohT0"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "data_collator = DataCollatorWithPadding(araelectra_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "E19QEriioj_2"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "cls_train_loader = DataLoader(cls_train_dataset, batch_size=8, shuffle= True, collate_fn= data_collator)\n",
    "span_train_loader = DataLoader(span_train_dataset, batch_size=8, shuffle= True, collate_fn = data_collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 8, shuffle = True, collate_fn = data_collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 8, shuffle = True, collate_fn = data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "V7J1nppMonIO"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
    "    \"\"\"\n",
    "    state: checkpoint to save\n",
    "    is_best: is this the best checkpoint; min validation loss\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    best_model_path: path to save best checkpoint\n",
    "    \"\"\"\n",
    "    f_path = checkpoint_path\n",
    "    # save checkpoint data to the path given, checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    # if it is a best model, min validation loss\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        # copy that checkpoint file to best path given, best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "KHVvcyQwosqG"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    \"\"\"\n",
    "    checkpoint_path: path to saved checkpoint\n",
    "    model: model to load checkpoint parameters into       \n",
    "    optimizer: optimizer defined in previous training\n",
    "    \"\"\"\n",
    "    # load check point\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    # initialize state_dict from checkpoint to model\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    # initialize optimizer from checkpoint to optimizer\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
    "    results = checkpoint['result_dict']\n",
    "    # return model, optimizer, epoch value, min validation loss \n",
    "    return model, optimizer, checkpoint['epoch'], results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "9E5IOBGOoxDh"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def order_exp(base_path, exp_name):\n",
    "  exp_path = os.path.join(base_path, exp_name)\n",
    "  if not os.path.exists(exp_path):\n",
    "    os.mkdir(exp_path)\n",
    "  curr_ckp_path = os.path.join(exp_path,'curr.pt')\n",
    "  best_ckp_path = os.path.join(exp_path, 'best.pt')\n",
    "  return curr_ckp_path, best_ckp_path, exp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "4TthCLwWo0a3"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def cls_eval(model, data_loader, exp_path, train_loss):\n",
    "    model.eval()\n",
    "    total_acc = 0\n",
    "    total_pred = None\n",
    "    total_IDs = None\n",
    "    soft = torch.nn.Softmax(dim=1)\n",
    "    with open(os.path.join(exp_path,'preds.txt'),'w') as f:\n",
    "        pass\n",
    "    for batch in data_loader:\n",
    "      tokens = batch['input_ids'].to(device)\n",
    "      masks = batch['attention_mask'].to(device)\n",
    "      tokens_type = batch['token_type_ids'].to(device)\n",
    "      IDs = batch['IDs'].to(device)\n",
    "      gt_no_ans = batch['no_ans'].to(device)\n",
    "      output = model(tokens, masks, tokens_type)\n",
    "      pred = output.logits.view(masks.shape[0],2,)\n",
    "      with open(os.path.join(exp_path,'preds.txt'),'a') as f:\n",
    "        preds_soft = soft(pred)[:,1]\n",
    "        IDs\n",
    "        for i in range(preds_soft.shape[0]):\n",
    "            f.write(f\"{IDs[i].item()},{preds_soft[i].item()}\\n\")\n",
    "        \n",
    "      pred = torch.argmax(pred, dim=1)\n",
    "      target = batch['no_ans'].to(device).view(masks.shape[0],)\n",
    "      total_acc += torch.sum(target==pred)\n",
    "\n",
    "    total_acc = total_acc/ val_dataset.__len__()\n",
    "    res_dict = {'acc':total_acc.item()*100, 'train_loss':train_loss}\n",
    "    if exp_path:\n",
    "        log_path = os.path.join(exp_path,'res.csv')\n",
    "        if not os.path.exists(log_path):\n",
    "            with open(log_path,'w') as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=res_dict.keys())\n",
    "                writer.writeheader()\n",
    "        with open(log_path, 'a') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=res_dict.keys())\n",
    "            #writer.writeheader()\n",
    "            writer.writerow(res_dict)\n",
    "    model.train()\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "RZXCw3sno74X"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def cls_train(model,start_epoch, num_epochs, optimizer,max_acc, train_loader, val_loader, log, exp_name):\n",
    "  curr_ckp_path, best_ckp_path, exp_path = order_exp('/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/cls', exp_name)\n",
    "  model.train()\n",
    "  cls_pred = None\n",
    "  for epoch in range(start_epoch,num_epochs):\n",
    "    total_loss = 0.0\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "      tokens = batch['input_ids'].to(device)\n",
    "      masks = batch['attention_mask'].to(device)\n",
    "      tokens_type = batch['token_type_ids'].to(device)\n",
    "      weights = batch['weights'].to(device)\n",
    "      output = model(tokens, masks, tokens_type)\n",
    "      pred = output.logits.view(masks.shape[0],2,)\n",
    "      target = batch['no_ans'].type(torch.LongTensor)\n",
    "      target = target.to(device)\n",
    "      loss = cls_criterion(pred, target.view(masks.shape[0],))\n",
    "      loss = loss*(weights.view(masks.shape[0],))\n",
    "      loss = torch.mean(loss)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "      total_loss = total_loss + ((1 / (batch_idx + 1)) * (loss.item() - total_loss)) \n",
    "      loop.set_description(f'Epoch {epoch}')\n",
    "      loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    result_dict= cls_eval(model, val_loader,exp_path,total_loss )\n",
    "    checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'result_dict':result_dict,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "    curr_acc = result_dict['acc']\n",
    "    if curr_acc>=max_acc:\n",
    "      max_acc = curr_acc\n",
    "      save_ckp(checkpoint, True, curr_ckp_path, best_ckp_path)\n",
    "    else:\n",
    "      save_ckp(checkpoint, False, curr_ckp_path, best_ckp_path)\n",
    "    print(result_dict)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "_fWMQedDgv99"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "model_namex=\"ZeyadAhmed/AraElectra-Arabic-SQuADv2-CLS\"\n",
    "model_namexx=\"ZeyadAhmed/AraElectra-Arabic-SQuADv2-QA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "45c5d6b1431a41fe8e8203cbc2d00337",
      "fd91a05872ec420ca308474a6471a921",
      "86efa8e815b341d89a2b4f8e21f43524",
      "1680e30cd1af45659951a4fa6e8b0cb4",
      "560712fcda95450f8235ff50add74706",
      "ad81f61ce6df4b3295613a5fed6ba6a8",
      "2e10b8c62de9419493f8ee4714e27ac0",
      "7d3c83362c4f45aca326732f47a05c7a",
      "39582197f76c4e279bee702f41bc035e",
      "3c8ec8998a444caca2a112fa53a8741e",
      "3a225a4909c94200976db2a2a9357173",
      "7bd0eefea82b42c8884cbc65d92861f7",
      "3bfa8666af4b4b98bd494150e2b9ec42",
      "80595b69dbb949049bfb89a6d031f7bb",
      "fa135a3b63444ef5a210dab7c941d17b",
      "dc8c672f6fac480b9822912f92850486",
      "729d8b0e2f414f928a24928949dd0604",
      "85f16718913a4228b5517b606fb6d07d",
      "a57c9d09fdc74cfbab5a6a71141bb96f",
      "15e5605f657b41c5a799f0189c8e12f4",
      "6781fd5159bc4495b0d105203a583b9a",
      "22fca5802b834baf8d349a0f51c0febf",
      "2f92bfa57cc34cc5bc454194d60c5fa5",
      "ec2a6a9ad03f4834a037de4cbca6095e",
      "8bc99859620e460fa9f5968073ea66ef",
      "2df02be8d7f34d69b079e5289c662953",
      "68013c6f50b740bd9f4f17568bc0798d",
      "000a4ad8840042d798d57c3bc8678979",
      "0b765e0f90fe4ee0ae72aceae44cb5d9",
      "3d8087fddd2a48199732737fb4f2e1b3",
      "79219ea38aba40ce99d58d296b846a60",
      "46bfab55e5e041c78864ec964013680b",
      "da02ed14350d435997914c8bb5ffc4a2",
      "782d38e303e1463a8e2d14b4b75c15c6",
      "10e1bc273fcb41d09f3001048157c23f",
      "e07c5aa04c9e492a87098e012d3e23df",
      "d6cf026691b547c6b3b8e5f339b2b289",
      "f7ef21a5238e4f648ad0413673b60cfe",
      "d12197dd13c24493aa1c872172c7e234",
      "b796a6d1707d482b84a8ffc301372018",
      "27c766ee31684eb4ac31507088580195",
      "0fb47c9963b04c0db4b04739d51893db",
      "92f7912f081a4a369567156c307cd354",
      "0e8a0a8c83584856a82281c28e9ccbdf"
     ]
    },
    "id": "aL1LvCLfpDT5",
    "outputId": "511b48d2-d2fd-4fcd-cd43-02738f58df5a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c5d6b1431a41fe8e8203cbc2d00337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/857 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd0eefea82b42c8884cbc65d92861f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/541M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f92bfa57cc34cc5bc454194d60c5fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/851 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782d38e303e1463a8e2d14b4b75c15c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/538M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title\n",
    "Cls_AraElectra = ElectraForSequenceClassification.from_pretrained(model_namex, num_labels=2)\n",
    "QA_AraElectra = ElectraForQuestionAnswering.from_pretrained(model_namexx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOuaBDn2PXHk"
   },
   "source": [
    "why use freeze and not .from_pretrained() only?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "vDKKKFiIpMI2"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def freeze(Electra, count=None):\n",
    "    if count is not None:\n",
    "\t      # We freeze here the embeddings of the model\n",
    "        for param in Electra.embeddings.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        if count != -1:\n",
    "\t          # if freeze_layer_count == -1, we only freeze the embedding layer\n",
    "\t          # otherwise we freeze the first `freeze_layer_count` encoder layers\n",
    "            for layer in Electra.encoder.layer[:count]:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False\n",
    "    print(sum(p.numel() for p in Electra.parameters()), sum(p.numel() for p in Electra.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3PzKxtQpQyc",
    "outputId": "9f39b653-3776-4020-f3e4-226dd3258fb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134602752 42527232\n",
      "134602752 42527232\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "freeze(Cls_AraElectra.electra,6)\n",
    "freeze(QA_AraElectra.electra, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KyGs6pvUpYDA",
    "outputId": "616cb565-7d6f-45d6-b02d-84db97507a3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "num_epochs = 2\n",
    "learning_rate = 3e-5\n",
    "optimizer = torch.optim.Adam(Cls_AraElectra.parameters(), lr=learning_rate)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "#criterion_span = nn.CrossEntropyLoss(reduction='none')\n",
    "cls_criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "Cls_AraElectra.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y1mx4YjNpbXr",
    "outputId": "f2a22816-592e-4852-9d14-41d0cf4b73a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Epoch 0: 100%|██████████| 6/6 [00:05<00:00,  1.02it/s, loss=0.0737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 100.0, 'train_loss': 0.5758701711893082}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.00716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 100.0, 'train_loss': 0.015093949235354861}\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "cls_trained_model= cls_train(Cls_AraElectra, 0, 2, optimizer, 0, cls_train_loader, val_loader , True, '/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/cls/third')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pfiAjOIuvhdg",
    "outputId": "b3939b6a-19b8-4331-aed5-0555ff979f9d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 6/6 [00:02<00:00,  2.07it/s, loss=0.00382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 100.0, 'train_loss': 0.0053530742491905885}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.00228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 100.0, 'train_loss': 0.0031442715165515738}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 6/6 [00:02<00:00,  2.04it/s, loss=0.00219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 100.0, 'train_loss': 0.0022031382735197744}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 6/6 [00:02<00:00,  2.05it/s, loss=0.00145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 100.0, 'train_loss': 0.001767653040587902}\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "cls_trained_model = cls_train(cls_trained_model, 2, 6, optimizer, 84.3, cls_train_loader, val_loader , True, '/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/cls/third')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "1rV219Xfv-4T"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "cls_trained_model, optimizer , x, xx = load_ckp('/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/cls/third/curr.pt',Cls_AraElectra, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_4kTQ-fwSBN",
    "outputId": "5b0317c9-ee94-4f79-cd7b-8115c91907cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.00133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 100.0, 'train_loss': 0.0016433807516780992}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 6/6 [00:02<00:00,  2.02it/s, loss=0.00103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 100.0, 'train_loss': 0.0012254234946643312}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 6/6 [00:02<00:00,  2.00it/s, loss=0.00104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 100.0, 'train_loss': 0.0012242689457101126}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 6/6 [00:02<00:00,  2.01it/s, loss=0.00127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 100.0, 'train_loss': 0.0010488863529947896}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 6/6 [00:03<00:00,  1.98it/s, loss=0.000906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 100.0, 'train_loss': 0.0009476618918900688}\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "cls_trained_model = cls_train(cls_trained_model, 3, 8, optimizer, 85.1, cls_train_loader, val_loader , True, '/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/cls/third')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "m0SeZ8njwlG6"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "cls_model = ElectraForSequenceClassification.from_pretrained(model_namex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I44eRQ0kwrUu",
    "outputId": "51de151f-b922-4489-c6ab-1b34128f8784"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "learning_rate = 3e-5\n",
    "optimizer = torch.optim.AdamW(cls_model.parameters(), lr=learning_rate)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "#criterion_span = nn.CrossEntropyLoss(reduction='none')\n",
    "#cls_criterion = nn.CrossEntropyLoss()\n",
    "cls_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "o_WjSebvwvBR"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "cls_model, optimizer, start_epoch, result_dict = load_ckp('/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/cls/third/best.pt', cls_model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "hOU6Cv1OxK9x"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def get_raw_preds(data_loader, model,ids_to_index,offset,contexts, max_answer_length, n_best_size): \n",
    "  model.eval()\n",
    "  imd_predictions,script_predictions = dict(), dict()\n",
    "  with torch.no_grad():\n",
    "    #F1 = EM = Total = 0\n",
    "    total_loss = 0.0\n",
    "    total_predictions = dict()\n",
    "    no_probs_pred = dict()\n",
    "    #loop = tqdm(data_loader)\n",
    "    loop = tqdm(data_loader, leave=True)\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "      tokens = batch['input_ids'].to(device)\n",
    "      masks = batch['attention_mask'].to(device)\n",
    "      tokens_type = batch['token_type_ids'].to(device)\n",
    "      gt_start = batch['start_positions'].to(device)\n",
    "      gt_end = batch['end_positions'].to(device)\n",
    "      IDs = batch['IDs'].to(device)\n",
    "      outputs = model(tokens, masks, tokens_type, start_positions=gt_start, end_positions=gt_end)\n",
    "      #calculating loss\n",
    "      loss = outputs.loss\n",
    "      #update average total loss \n",
    "      total_loss = total_loss + ((1 / (batch_idx + 1)) * (loss.item() - total_loss)) \n",
    "      #calculating f1 score and EM\n",
    "      curr_batch_size = tokens.shape[0]\n",
    "      post_raw_preds(IDs, outputs.start_logits, outputs.end_logits, ids_to_index, offset, contexts,max_answer_length, n_best_size, imd_predictions, script_predictions )\n",
    "    #saving evaluation results\n",
    "    #evaluation\n",
    "\n",
    "    model.train()\n",
    "    return imd_predictions,script_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xksq_AurTKLA"
   },
   "source": [
    "here to rexplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "DdpOi4kRxYUo"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def post_raw_preds(IDs, total_start_logits, total_end_logits,ids_to_index,offset,contexts, max_answer_length, n_best_size,\n",
    " imd_predictions,script_predictions ):\n",
    "    total_start_logits = total_start_logits.cpu().numpy()\n",
    "    total_end_logits = total_end_logits.cpu().numpy()\n",
    "    IDs = IDs.cpu().numpy()\n",
    "    for i in range(IDs.shape[0]):\n",
    "        offset_mapping = offset[ids_to_index[IDs[i].squeeze()]]\n",
    "        # The first feature comes from the first example. For the more general case, we will need to be match the example_id to\n",
    "        # an example index\n",
    "        context = contexts[ids_to_index[IDs[i].squeeze()]]\n",
    "        start_logits = total_start_logits[i]\n",
    "        end_logits = total_end_logits[i]\n",
    "        # Gather the indices the best start/end logits:\n",
    "        start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "        end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "        valid_answers = []\n",
    "        for start_index in start_indexes:\n",
    "            for end_index in end_indexes:\n",
    "                # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
    "                # to part of the input_ids that are not in the context.\n",
    "                if (\n",
    "                    start_index >= len(offset_mapping)\n",
    "                    or end_index >= len(offset_mapping)\n",
    "                    or offset_mapping[start_index] is None\n",
    "                    or offset_mapping[end_index] is None\n",
    "                ):\n",
    "                    continue\n",
    "                # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
    "                if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                    continue\n",
    "                if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char: end_char]\n",
    "                        }\n",
    "                    )\n",
    "        if len(valid_answers) ==0:\n",
    "            valid_answers.append({\"text\":\"\", \"score\":\"\"})\n",
    "\n",
    "        valid_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        imd_predictions[str(IDs[i].squeeze())] = valid_answer\n",
    "        script_predictions[str(IDs[i].squeeze())] = valid_answer['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "8DzOcnfqxna3"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def get_preds(total_preds, no_probs_preds,data_path, log_path):\n",
    "    preds_path = os.path.join(log_path, 'preds')\n",
    "    if not os.path.exists(preds_path):\n",
    "        os.mkdir(preds_path)\n",
    "    no_probs_path = os.path.join(preds_path, 'na_probs.json')\n",
    "    text_preds_path = os.path.join(preds_path, 'preds.json')\n",
    "    jsonString = json.dumps(total_preds)\n",
    "    jsonFile = open(text_preds_path, \"w\")\n",
    "    jsonFile.write(jsonString)\n",
    "    jsonFile.close()\n",
    "    if no_probs_preds is not None:\n",
    "        jsonString = json.dumps(no_probs_preds)\n",
    "        jsonFile = open(no_probs_path, \"w\")\n",
    "        jsonFile.write(jsonString)\n",
    "        jsonFile.close()\n",
    "        #!python evaluatev2.py data_path text_preds_path electra --na-prob-file no_probs_path --na-prob-thresh 0.4 --out-file log_path\n",
    "        #os.system(f\"python evaluatev2.py {data_path} {text_preds_path} electra --na-prob-file {no_probs_path} --na-prob-thresh 0.5 --out-file {log_path}\")\n",
    "        !python /content/Arabic-MRC/evaluatev2.py /content/asquadv2-val.json /content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth/preds/preds.json electra --na-prob-file /content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/second/preds/na_probs.json  --na-prob-thresh 0.5  \n",
    "    else:\n",
    "        !python /content/Arabic-MRC/evaluatev2.py /content/asquadv2-val.json /content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth/preds/preds.json electra  --out-file /content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth\n",
    "    if log_path:\n",
    "        with open(os.path.join(log_path, 'res.csv')) as f:\n",
    "            DictReader_obj = csv.DictReader(f)\n",
    "            lastrow = None\n",
    "            for item in DictReader_obj:\n",
    "                lastrow = dict(item)\n",
    "        #print(lastrow)\n",
    "        return lastrow\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "DT9K2j33xqG8"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def span_train(model,start_epoch, num_epochs, optimizer,max_compined_metric, train_loader, val_loader, log, exp_name):\n",
    "  curr_ckp_path, best_ckp_path, exp_path = order_exp('/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span', exp_name)\n",
    "  model.train()\n",
    "  for epoch in range(start_epoch,num_epochs):\n",
    "    total_loss = 0.0\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "      tokens = batch['input_ids'].to(device)\n",
    "      masks = batch['attention_mask'].to(device)\n",
    "      tokens_type = batch['token_type_ids'].to(device)\n",
    "      gt_start = batch['start_positions'].to(device)\n",
    "      gt_end = batch['end_positions'].to(device)\n",
    "      outputs = model(tokens, masks, tokens_type, start_positions=gt_start, end_positions=gt_end)\n",
    "      loss = outputs.loss\n",
    "      loss = 2*loss\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "      total_loss = total_loss + ((1 / (batch_idx + 1)) * (loss.item() - total_loss)) \n",
    "      loop.set_description(f'Epoch {epoch}')\n",
    "      loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    imd_preds, script_preds = get_raw_preds(val_loader, model,val_ids_to_idx,val_offset,asquad_val_contexts, 30, 10)\n",
    "    result_dict = get_preds(script_preds, None,'/content/asquadv2-val.json',exp_path )\n",
    "    checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'result_dict':result_dict,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "    curr_compined_metric = float(result_dict['HasAns_exact'])+1.5*float(result_dict['HasAns_f1'])\n",
    "    if curr_compined_metric>=max_compined_metric:\n",
    "      max_compined_metric = curr_compined_metric\n",
    "      save_ckp(checkpoint, True, curr_ckp_path, best_ckp_path)\n",
    "    else:\n",
    "      save_ckp(checkpoint, False, curr_ckp_path, best_ckp_path)\n",
    "    print(\"ckp saved\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mclF7krmxwOa",
    "outputId": "91b8700b-cdce-41e2-82df-c91bb3649c96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134602752 42527232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForQuestionAnswering(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "QA_AraElectra = ElectraForQuestionAnswering.from_pretrained(model_namexx)\n",
    "freeze(QA_AraElectra.electra, 6)\n",
    "span_num_epochs = 4\n",
    "span_learning_rate = 3e-5\n",
    "span_optimizer = torch.optim.AdamW(QA_AraElectra.parameters(), lr=span_learning_rate)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "#criterion_span = nn.CrossEntropyLoss(reduction='none')\n",
    "#cls_criterion = nn.CrossEntropyLoss()\n",
    "QA_AraElectra.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LVwbZUkqx2c7",
    "outputId": "53d6c9b0-b3be-4d82-ca63-8692151980ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 6/6 [00:03<00:00,  1.99it/s, loss=4.1]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 16.666666666666668,\n",
      "  \"f1\": 29.583333333333332,\n",
      "  \"total\": 6,\n",
      "  \"HasAns_exact\": 16.666666666666668,\n",
      "  \"HasAns_f1\": 29.583333333333332,\n",
      "  \"HasAns_total\": 6\n",
      "}\n",
      "ckp saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 6/6 [00:03<00:00,  1.97it/s, loss=4.41]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 16.666666666666668,\n",
      "  \"f1\": 27.083333333333332,\n",
      "  \"total\": 6,\n",
      "  \"HasAns_exact\": 16.666666666666668,\n",
      "  \"HasAns_f1\": 27.083333333333332,\n",
      "  \"HasAns_total\": 6\n",
      "}\n",
      "ckp saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 6/6 [00:03<00:00,  1.96it/s, loss=1.37]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 16.666666666666668,\n",
      "  \"f1\": 27.083333333333332,\n",
      "  \"total\": 6,\n",
      "  \"HasAns_exact\": 16.666666666666668,\n",
      "  \"HasAns_f1\": 27.083333333333332,\n",
      "  \"HasAns_total\": 6\n",
      "}\n",
      "ckp saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.903]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 33.333333333333336,\n",
      "  \"f1\": 42.30769230769231,\n",
      "  \"total\": 6,\n",
      "  \"HasAns_exact\": 33.333333333333336,\n",
      "  \"HasAns_f1\": 42.30769230769231,\n",
      "  \"HasAns_total\": 6\n",
      "}\n",
      "ckp saved\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "span_trained_model = span_train(QA_AraElectra,0, 4, span_optimizer,0.0, span_train_loader, val_loader, True, '/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "8vj7pnFjyEed"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "span_trained_model, span_optim , x, xx = load_ckp('/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth/curr.pt', QA_AraElectra,span_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qgMvx6EhyOau",
    "outputId": "21211b51-f211-4683-af4b-db6c5bacdac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.7948717948718\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "max_metric = float(xx['HasAns_exact'])+1.5*float(xx['HasAns_f1'])\n",
    "print(max_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8K9eGYDyQ3g",
    "outputId": "f38da0b3-3c1b-49c5-92ad-b1d8fe7f76f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 6/6 [00:03<00:00,  1.93it/s, loss=nan]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 33.333333333333336,\n",
      "  \"f1\": 35.0,\n",
      "  \"total\": 6,\n",
      "  \"HasAns_exact\": 33.333333333333336,\n",
      "  \"HasAns_f1\": 35.0,\n",
      "  \"HasAns_total\": 6\n",
      "}\n",
      "ckp saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 6/6 [00:03<00:00,  1.95it/s, loss=0.174]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 33.333333333333336,\n",
      "  \"f1\": 35.0,\n",
      "  \"total\": 6,\n",
      "  \"HasAns_exact\": 33.333333333333336,\n",
      "  \"HasAns_f1\": 35.0,\n",
      "  \"HasAns_total\": 6\n",
      "}\n",
      "ckp saved\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "span_trained_model = span_train(span_trained_model,2, 4, span_optim,max_metric, span_train_loader, val_loader, True, '/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "IYb_Z_sTyZ-v"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "cls_model = ElectraForSequenceClassification.from_pretrained(model_namex, num_labels = 2)\n",
    "learning_rate = 3e-5\n",
    "optimizer = torch.optim.AdamW(cls_model.parameters(), lr=learning_rate)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "#criterion_span = nn.CrossEntropyLoss(reduction='none')\n",
    "#cls_criterion = nn.CrossEntropyLoss()\n",
    "cls_model.to(device)\n",
    "cls_model , cls_optim, x, xx = load_ckp('/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/cls/third/best.pt', cls_model,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lrLOdXHhyevy",
    "outputId": "922f6727-15ab-44fc-cc92-e662eb5c0519"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('AraElectra-ASQuADv2-CLS/tokenizer_config.json',\n",
       " 'AraElectra-ASQuADv2-CLS/special_tokens_map.json',\n",
       " 'AraElectra-ASQuADv2-CLS/vocab.txt',\n",
       " 'AraElectra-ASQuADv2-CLS/added_tokens.json',\n",
       " 'AraElectra-ASQuADv2-CLS/tokenizer.json')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "cls_model.save_pretrained('AraElectra-ASQuADv2-CLS')\n",
    "araelectra_tokenizer.save_pretrained('AraElectra-ASQuADv2-CLS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "rwFstKXmyh3Q"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "qa_model = ElectraForQuestionAnswering.from_pretrained(model_namexx)\n",
    "span_learning_rate = 3e-5\n",
    "span_optimizer = torch.optim.AdamW(qa_model.parameters(), lr=span_learning_rate)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "qa_model.to(device)\n",
    "qa_model , qa_optim, x, xx = load_ckp('/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth/best.pt', qa_model,span_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QPG81zYOykSo",
    "outputId": "35693b69-732a-4693-e485-0477c47e64d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('AraElectra-ASQuADv2-QA/tokenizer_config.json',\n",
       " 'AraElectra-ASQuADv2-QA/special_tokens_map.json',\n",
       " 'AraElectra-ASQuADv2-QA/vocab.txt',\n",
       " 'AraElectra-ASQuADv2-QA/added_tokens.json',\n",
       " 'AraElectra-ASQuADv2-QA/tokenizer.json')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "qa_model.save_pretrained('AraElectra-ASQuADv2-QA')\n",
    "araelectra_tokenizer.save_pretrained('AraElectra-ASQuADv2-QA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MaBtt2seyp6t",
    "outputId": "4d67ed9b-b77e-4f9f-d1e0-686b7917989f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "qa_model = ElectraForQuestionAnswering.from_pretrained('AraElectra-ASQuADv2-QA')\n",
    "cls_model = ElectraForSequenceClassification.from_pretrained('AraElectra-ASQuADv2-CLS',num_labels=2)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "qa_model.to(device)\n",
    "cls_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "DJ-RULEMytAj"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "cls_res_dict = cls_eval(cls_model, test_loader,'/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/cls/third',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0VKXrWqGyxo4",
    "outputId": "26563a3d-4814-49aa-a911-518f9573342e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 100.0, 'train_loss': None}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "cls_res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8bC2VNAyz1l",
    "outputId": "f25351c3-d2cd-41e5-dabe-ddea619e47f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "cls_preds_dict = dict()\n",
    "with open('/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/cls/third/preds.txt','r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        elements = line.split(',')\n",
    "        cls_preds_dict[elements[0]] = float(elements[1])\n",
    "print(len(cls_preds_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LTshlB9ry2gV",
    "outputId": "0bd6d2fd-6f9c-4e4c-c79d-8e7b4753e1d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.12it/s]\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "imd_preds, script_preds = get_raw_preds(test_loader, qa_model,test_ids_to_idx,test_offset,asquad_test_contexts, 30, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZGmfPBmQAR0G",
    "outputId": "3e8c6ec7-1a86-4c04-9e28-2fc759d72001"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3': {'score': 10.855261, 'text': 'العبء الدراسي هو عدد ساعات الدراسة خلال الفصل الدراسي الواحد'}, '4': {'score': -3.7347002, 'text': 'هو'}, '6': {'score': 9.322868, 'text': 'المعدل المطلوب للطالب الغير مقيد هو معدل عام 2 . 50 نقاط من أصل 4 . 00 نقاط'}, '5': {'score': 1.7065122, 'text': 'ويتم قبوله قبولا مشروطا بتحويله لطالب مقيد بعد اجتياز 12 وحدة دراسية بمعدل لا يقل عن 3 . 00 نقاط من أصل 4 . 00 نقاط'}, '1': {'score': 0.89066315, 'text': 'نوعان'}, '2': {'score': 9.026323, 'text': 'شروط التقديم على كلية الدراسات العليا متغيرة حسب البرامج المطروحة في كل سنة وتكون الشروط مذكورة في اعلان التقديم الذي يتم نشره على الموقع الالكتروني الخاص بكلية الدراسات العليا'}}\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "print(imd_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "iNcX6e7ezB_B"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def get_preds2(total_preds, no_probs_preds,data_path):\n",
    "    preds_path = os.path.join('preds')\n",
    "    if not os.path.exists(preds_path):\n",
    "        os.mkdir(preds_path)\n",
    "    no_probs_path = os.path.join(preds_path, 'na_probs.json')\n",
    "    text_preds_path = os.path.join(preds_path, 'preds.json')\n",
    "    jsonString = json.dumps(total_preds)\n",
    "    jsonFile = open(text_preds_path, \"w\")\n",
    "    jsonFile.write(jsonString)\n",
    "    jsonFile.close()\n",
    "    if no_probs_preds is not None:\n",
    "        jsonString = json.dumps(no_probs_preds)\n",
    "        jsonFile = open(no_probs_path, \"w\")\n",
    "        jsonFile.write(jsonString)\n",
    "        jsonFile.close()\n",
    "        #!python evaluatev2.py data_path text_preds_path electra --na-prob-file no_probs_path --na-prob-thresh 0.4 --out-file log_path\n",
    "        #os.system(f\"python evaluatev2.py {data_path} {text_preds_path} electra --na-prob-file {no_probs_path} --na-prob-thresh 0.5 --out-file {log_path}\")\n",
    "        !python /content/Arabic-MRC/evaluatev2.py /content/asquadv2-test.json /content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth/preds/preds.json electra --na-prob-file /content/preds/na_probs.json  --na-prob-thresh 0.5  \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnSeFWgoYRSK",
    "outputId": "a62c02ae-b085-4a3c-aac8-ffc3a136e9f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 0.0,\n",
      "  \"f1\": 1.9607843137254901,\n",
      "  \"total\": 6,\n",
      "  \"HasAns_exact\": 0.0,\n",
      "  \"HasAns_f1\": 1.9607843137254901,\n",
      "  \"HasAns_total\": 6,\n",
      "  \"best_exact\": 0.0,\n",
      "  \"best_exact_thresh\": 0.0,\n",
      "  \"best_f1\": 1.9607843137254901,\n",
      "  \"best_f1_thresh\": 0.00025343577726744115\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "qa_result_dict = get_preds2(script_preds, cls_preds_dict,'/content/Arabic-MRC/Runs/AraElectraDecoupledAsquadv2/train/span/fourth/preds' )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "XfoSwdpsIcuM",
    "5EHDXGMxGHpS",
    "-823FrXxGU-G",
    "rFGZoBl2G5fL"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "000a4ad8840042d798d57c3bc8678979": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0615f6816b6d4ad8ac7688a0a3ac5193": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "064c4d8c864b48d88135fdb93cc853b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06503c92b2d04f1b898163a8b9583741": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08c418a7c1ca4a4da60f8373cd953147": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0ab612c6e90e4ee09ce8ffb0b6b603b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0b765e0f90fe4ee0ae72aceae44cb5d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d9017fb0936420ba3bb9aabd68f21fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e8a0a8c83584856a82281c28e9ccbdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0ef25984b04b442ea7d66451037cdbec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0fb47c9963b04c0db4b04739d51893db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1035b3d53d484ffe8e0c9c6ab2c99e9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10e1bc273fcb41d09f3001048157c23f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d12197dd13c24493aa1c872172c7e234",
      "placeholder": "​",
      "style": "IPY_MODEL_b796a6d1707d482b84a8ffc301372018",
      "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
     }
    },
    "1182976732e2448abce96f45dba0a8ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "11d51caf3b1e429db31f5174298030d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "131733d1e4994e32973f4b83da3c4c78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61b61332907a4b67847c6b8545e510f4",
      "placeholder": "​",
      "style": "IPY_MODEL_720af14c3f344c70b2d6dc46eabd275f",
      "value": "Generating train split: "
     }
    },
    "15e5605f657b41c5a799f0189c8e12f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1614656c3d9a431e8d4e55aea72ba8ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2cf62d2389a940e4824857b31f5f0fd4",
      "placeholder": "​",
      "style": "IPY_MODEL_70e0b8d910514582be69f3c39a0113cc",
      "value": " 112/112 [00:00&lt;00:00, 4.04kB/s]"
     }
    },
    "16316f23dfaa43899810eca09b7a051d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1680e30cd1af45659951a4fa6e8b0cb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c8ec8998a444caca2a112fa53a8741e",
      "placeholder": "​",
      "style": "IPY_MODEL_3a225a4909c94200976db2a2a9357173",
      "value": " 857/857 [00:00&lt;00:00, 39.0kB/s]"
     }
    },
    "171b86ecf305422b94d31f6248230307": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "196c2ade28e14fa0b4ae9879c61d6a1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8f7b403065f4e1fbe34631a1abe5881",
      "max": 824793,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f1a54f32f1e6409b87e84658c9162089",
      "value": 824793
     }
    },
    "1b529ac77c134ca6bb8929f07522a6b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1035b3d53d484ffe8e0c9c6ab2c99e9c",
      "placeholder": "​",
      "style": "IPY_MODEL_5804ae2ab5084942934399ed4f621085",
      "value": " 1/1 [00:07&lt;00:00,  7.55s/it]"
     }
    },
    "2131168451d447ea8b614276b40b8ebb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e562d0c7ad87476e8f078fbaafaed409",
      "max": 174970659,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0ab612c6e90e4ee09ce8ffb0b6b603b0",
      "value": 174970659
     }
    },
    "22fca5802b834baf8d349a0f51c0febf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26388ede28624e5c92b20f12e7b8c74d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "27c766ee31684eb4ac31507088580195": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2bc85cdaa11f41f990fc46e9bf6140b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b019d94b0084be592882615837bdac2",
      "placeholder": "​",
      "style": "IPY_MODEL_26388ede28624e5c92b20f12e7b8c74d",
      "value": "Extracting data files: 100%"
     }
    },
    "2c367e5b50b34f0c89fc27067eb73be8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6077d913f11b45d88e251fcac820aad8",
      "placeholder": "​",
      "style": "IPY_MODEL_32615ff938604385978cf6bc49167cda",
      "value": " 392/392 [00:00&lt;00:00, 10.2kB/s]"
     }
    },
    "2cf62d2389a940e4824857b31f5f0fd4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2df02be8d7f34d69b079e5289c662953": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46bfab55e5e041c78864ec964013680b",
      "placeholder": "​",
      "style": "IPY_MODEL_da02ed14350d435997914c8bb5ffc4a2",
      "value": " 851/851 [00:00&lt;00:00, 39.5kB/s]"
     }
    },
    "2e10b8c62de9419493f8ee4714e27ac0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f92bfa57cc34cc5bc454194d60c5fa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ec2a6a9ad03f4834a037de4cbca6095e",
       "IPY_MODEL_8bc99859620e460fa9f5968073ea66ef",
       "IPY_MODEL_2df02be8d7f34d69b079e5289c662953"
      ],
      "layout": "IPY_MODEL_68013c6f50b740bd9f4f17568bc0798d"
     }
    },
    "32615ff938604385978cf6bc49167cda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35650f40623a434c97c8aecdb142e1a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d739003cb1a456490a3628d470b8389",
      "placeholder": "​",
      "style": "IPY_MODEL_99a11033c6d14a77bc8974f6d940bee6",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "37a511e1a79c4c37843f2fb44fc8348e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39582197f76c4e279bee702f41bc035e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "39c5233a832442ea836fc5f405f44432": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3a225a4909c94200976db2a2a9357173": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3bfa8666af4b4b98bd494150e2b9ec42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_729d8b0e2f414f928a24928949dd0604",
      "placeholder": "​",
      "style": "IPY_MODEL_85f16718913a4228b5517b606fb6d07d",
      "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
     }
    },
    "3c8ec8998a444caca2a112fa53a8741e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d14824c8aa04bc0ab6517b1968f9afc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d8087fddd2a48199732737fb4f2e1b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41e2fe39171845688d1f41897c158d3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2bc85cdaa11f41f990fc46e9bf6140b2",
       "IPY_MODEL_54bd585c006a4d06a2a5153fe9ecd9d5",
       "IPY_MODEL_bf90c8944f31454288a5bdfe3d065f7d"
      ],
      "layout": "IPY_MODEL_d9997e34d75042cfb7222bb61ac500e9"
     }
    },
    "45c5d6b1431a41fe8e8203cbc2d00337": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fd91a05872ec420ca308474a6471a921",
       "IPY_MODEL_86efa8e815b341d89a2b4f8e21f43524",
       "IPY_MODEL_1680e30cd1af45659951a4fa6e8b0cb4"
      ],
      "layout": "IPY_MODEL_560712fcda95450f8235ff50add74706"
     }
    },
    "46bfab55e5e041c78864ec964013680b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4aa5c1072cd74d4e9d66ce721a3a292f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7884180dc346496db0cdbb90dada18bc",
      "placeholder": "​",
      "style": "IPY_MODEL_db982adddeff48088c05eabc29c89db5",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "4d739003cb1a456490a3628d470b8389": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52b6e26c188c4c1d985ba9c6a2080cd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "53b804755cc049228a7c2ac564770d3b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54bd585c006a4d06a2a5153fe9ecd9d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa4326673dbd4d69948f4c609b355a40",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0ef25984b04b442ea7d66451037cdbec",
      "value": 1
     }
    },
    "54fd8561f22646289638cfd5d4d6f039": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_131733d1e4994e32973f4b83da3c4c78",
       "IPY_MODEL_81eab8c6a699452bb12f8033cee6eb73",
       "IPY_MODEL_8c8e61761df842e1b9642692c614a450"
      ],
      "layout": "IPY_MODEL_5c6df69d8be940bfa167f0626f292e9a"
     }
    },
    "560712fcda95450f8235ff50add74706": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5804ae2ab5084942934399ed4f621085": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59e7609502424d7aa735d28b00bf3c3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b019d94b0084be592882615837bdac2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c6df69d8be940bfa167f0626f292e9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "5d6c42c1057c42c7a3e29cb5a04ed2c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99a83e39880a4251a0929e4dadd1fe97",
      "placeholder": "​",
      "style": "IPY_MODEL_bf6f9af431714ce281de717ef35e8126",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "5ec6af70f9ed411287ec2c90a8db6f01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5d6c42c1057c42c7a3e29cb5a04ed2c0",
       "IPY_MODEL_196c2ade28e14fa0b4ae9879c61d6a1f",
       "IPY_MODEL_d6d78188526b4e2eb1fb67a9d63f6d95"
      ],
      "layout": "IPY_MODEL_8aa0851d6f5f4aaa8d711faa772986ed"
     }
    },
    "60064dfff525411fa1a6584bf6dac7d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6077d913f11b45d88e251fcac820aad8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61b61332907a4b67847c6b8545e510f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "661d4b3ea00a4d839b130e043fe0266f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6781fd5159bc4495b0d105203a583b9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68013c6f50b740bd9f4f17568bc0798d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b0e89231e2a452588d0bb8f7d7300e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6c8a589295454e188871f3c8dd707f58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fd2ed96c8faa4b5abe527042fc33f197",
       "IPY_MODEL_8a09c6b2e8644fb7b850527098137cbd",
       "IPY_MODEL_1b529ac77c134ca6bb8929f07522a6b7"
      ],
      "layout": "IPY_MODEL_11d51caf3b1e429db31f5174298030d4"
     }
    },
    "6dc6962a844b4870bfcaf9aa901f80ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85c19587d95b468187f9deed9ef66a30",
      "max": 2642361,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a116dae153944f31bad2308c6f6866fd",
      "value": 2642361
     }
    },
    "70e0b8d910514582be69f3c39a0113cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71616382b393460ba4337e52d37d366d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ed31b1b1d5714b398426da46ce9f790d",
       "IPY_MODEL_d5fd24ef28cf4dd0aafb95c4c4d68cca",
       "IPY_MODEL_1614656c3d9a431e8d4e55aea72ba8ef"
      ],
      "layout": "IPY_MODEL_b2b63a8e9440448abf2bf5497115b3fa"
     }
    },
    "720af14c3f344c70b2d6dc46eabd275f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "729d8b0e2f414f928a24928949dd0604": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7779c82868944e8cbff7ea825bee092e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "782d38e303e1463a8e2d14b4b75c15c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_10e1bc273fcb41d09f3001048157c23f",
       "IPY_MODEL_e07c5aa04c9e492a87098e012d3e23df",
       "IPY_MODEL_d6cf026691b547c6b3b8e5f339b2b289"
      ],
      "layout": "IPY_MODEL_f7ef21a5238e4f648ad0413673b60cfe"
     }
    },
    "7884180dc346496db0cdbb90dada18bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79219ea38aba40ce99d58d296b846a60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7b479e6b74934476b068037af7f148d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7bd0eefea82b42c8884cbc65d92861f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3bfa8666af4b4b98bd494150e2b9ec42",
       "IPY_MODEL_80595b69dbb949049bfb89a6d031f7bb",
       "IPY_MODEL_fa135a3b63444ef5a210dab7c941d17b"
      ],
      "layout": "IPY_MODEL_dc8c672f6fac480b9822912f92850486"
     }
    },
    "7d3c83362c4f45aca326732f47a05c7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7eeaec8211414d2d93b60e1351a8adf4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7fc9fb117c024527a77041901fdc082f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80595b69dbb949049bfb89a6d031f7bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a57c9d09fdc74cfbab5a6a71141bb96f",
      "max": 540848301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_15e5605f657b41c5a799f0189c8e12f4",
      "value": 540848301
     }
    },
    "81eab8c6a699452bb12f8033cee6eb73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db501948d1d148a29977a85b88eed860",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8fd03680baca4154afc5f32419490176",
      "value": 1
     }
    },
    "82e18e571a354972952310f397b8cdb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85a7df6412b54bbeb15eba4b9765787e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7eeaec8211414d2d93b60e1351a8adf4",
      "max": 392,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1182976732e2448abce96f45dba0a8ea",
      "value": 392
     }
    },
    "85c19587d95b468187f9deed9ef66a30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85f16718913a4228b5517b606fb6d07d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "86efa8e815b341d89a2b4f8e21f43524": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d3c83362c4f45aca326732f47a05c7a",
      "max": 857,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_39582197f76c4e279bee702f41bc035e",
      "value": 857
     }
    },
    "8922e243365c412b95be7d25ce91fb44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a09c6b2e8644fb7b850527098137cbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6620bec34dd4ea7b53d0c5bbcee4cff",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_39c5233a832442ea836fc5f405f44432",
      "value": 1
     }
    },
    "8aa0851d6f5f4aaa8d711faa772986ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bc99859620e460fa9f5968073ea66ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d8087fddd2a48199732737fb4f2e1b3",
      "max": 851,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_79219ea38aba40ce99d58d296b846a60",
      "value": 851
     }
    },
    "8c8e61761df842e1b9642692c614a450": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06503c92b2d04f1b898163a8b9583741",
      "placeholder": "​",
      "style": "IPY_MODEL_08c418a7c1ca4a4da60f8373cd953147",
      "value": " 130319/0 [00:20&lt;00:00, 27283.68 examples/s]"
     }
    },
    "8fd03680baca4154afc5f32419490176": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "92f7912f081a4a369567156c307cd354": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93ffd6e701ff4869b02ad4e4763b9469": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d385cf2a9494442ca3874c387297f8b7",
      "placeholder": "​",
      "style": "IPY_MODEL_171b86ecf305422b94d31f6248230307",
      "value": "Downloading data: 100%"
     }
    },
    "97bb20443249423f9c3ba7b9d21c3d5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4aa5c1072cd74d4e9d66ce721a3a292f",
       "IPY_MODEL_f92fae07611a4011812c111a95adfe6b",
       "IPY_MODEL_c0314b6cfae14bbaa499ffbbcccab3cf"
      ],
      "layout": "IPY_MODEL_a42e5f811a3d4d8a8750f445aab6b775"
     }
    },
    "99a11033c6d14a77bc8974f6d940bee6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "99a83e39880a4251a0929e4dadd1fe97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a116dae153944f31bad2308c6f6866fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a42e5f811a3d4d8a8750f445aab6b775": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a57c9d09fdc74cfbab5a6a71141bb96f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a66d4a21a0914ddb980e44db84eaf024": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa4326673dbd4d69948f4c609b355a40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad81f61ce6df4b3295613a5fed6ba6a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b24f6fed241a425d95190f61ab6bac70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_93ffd6e701ff4869b02ad4e4763b9469",
       "IPY_MODEL_2131168451d447ea8b614276b40b8ebb",
       "IPY_MODEL_fbd86e127f964081957643f20c3f28fe"
      ],
      "layout": "IPY_MODEL_dd323521333a40db938dbe2af3a57a1e"
     }
    },
    "b2b63a8e9440448abf2bf5497115b3fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b796a6d1707d482b84a8ffc301372018": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd66c9d0d7dc4d8cb3ccaf3f71f44698": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59e7609502424d7aa735d28b00bf3c3f",
      "placeholder": "​",
      "style": "IPY_MODEL_16316f23dfaa43899810eca09b7a051d",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "bf6f9af431714ce281de717ef35e8126": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf90c8944f31454288a5bdfe3d065f7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8922e243365c412b95be7d25ce91fb44",
      "placeholder": "​",
      "style": "IPY_MODEL_7b479e6b74934476b068037af7f148d8",
      "value": " 1/1 [00:00&lt;00:00, 32.09it/s]"
     }
    },
    "c0314b6cfae14bbaa499ffbbcccab3cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_faf432c7ccd84d25834f852069db1113",
      "placeholder": "​",
      "style": "IPY_MODEL_a66d4a21a0914ddb980e44db84eaf024",
      "value": " 503/503 [00:00&lt;00:00, 19.2kB/s]"
     }
    },
    "c8f7b403065f4e1fbe34631a1abe5881": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d12197dd13c24493aa1c872172c7e234": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d385cf2a9494442ca3874c387297f8b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5fd24ef28cf4dd0aafb95c4c4d68cca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7779c82868944e8cbff7ea825bee092e",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f889e5bd292645a0b52a63ea8a2014b7",
      "value": 112
     }
    },
    "d6cf026691b547c6b3b8e5f339b2b289": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92f7912f081a4a369567156c307cd354",
      "placeholder": "​",
      "style": "IPY_MODEL_0e8a0a8c83584856a82281c28e9ccbdf",
      "value": " 538M/538M [00:05&lt;00:00, 99.6MB/s]"
     }
    },
    "d6d78188526b4e2eb1fb67a9d63f6d95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_53b804755cc049228a7c2ac564770d3b",
      "placeholder": "​",
      "style": "IPY_MODEL_0615f6816b6d4ad8ac7688a0a3ac5193",
      "value": " 825k/825k [00:01&lt;00:00, 720kB/s]"
     }
    },
    "d9997e34d75042cfb7222bb61ac500e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da02ed14350d435997914c8bb5ffc4a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db501948d1d148a29977a85b88eed860": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "db982adddeff48088c05eabc29c89db5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc8c672f6fac480b9822912f92850486": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd323521333a40db938dbe2af3a57a1e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfb800463b774ea989e890f42da41796": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_35650f40623a434c97c8aecdb142e1a4",
       "IPY_MODEL_6dc6962a844b4870bfcaf9aa901f80ce",
       "IPY_MODEL_e06ddf92c7d54867893a753d78becca8"
      ],
      "layout": "IPY_MODEL_661d4b3ea00a4d839b130e043fe0266f"
     }
    },
    "e06ddf92c7d54867893a753d78becca8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60064dfff525411fa1a6584bf6dac7d3",
      "placeholder": "​",
      "style": "IPY_MODEL_52b6e26c188c4c1d985ba9c6a2080cd3",
      "value": " 2.64M/2.64M [00:01&lt;00:00, 1.70MB/s]"
     }
    },
    "e07c5aa04c9e492a87098e012d3e23df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27c766ee31684eb4ac31507088580195",
      "max": 538485425,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0fb47c9963b04c0db4b04739d51893db",
      "value": 538485425
     }
    },
    "e2c6c1279df648f8a737bd6aacea9d09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e55678f7981d4af6b371b2615609ce9b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e562d0c7ad87476e8f078fbaafaed409": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6620bec34dd4ea7b53d0c5bbcee4cff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec2a6a9ad03f4834a037de4cbca6095e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_000a4ad8840042d798d57c3bc8678979",
      "placeholder": "​",
      "style": "IPY_MODEL_0b765e0f90fe4ee0ae72aceae44cb5d9",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "ed31b1b1d5714b398426da46ce9f790d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7fc9fb117c024527a77041901fdc082f",
      "placeholder": "​",
      "style": "IPY_MODEL_82e18e571a354972952310f397b8cdb9",
      "value": "Downloading (…)cial_tokens_map.json: 100%"
     }
    },
    "f1a54f32f1e6409b87e84658c9162089": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f7ef21a5238e4f648ad0413673b60cfe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f889e5bd292645a0b52a63ea8a2014b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f92fae07611a4011812c111a95adfe6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_064c4d8c864b48d88135fdb93cc853b9",
      "max": 503,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6b0e89231e2a452588d0bb8f7d7300e7",
      "value": 503
     }
    },
    "fa135a3b63444ef5a210dab7c941d17b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6781fd5159bc4495b0d105203a583b9a",
      "placeholder": "​",
      "style": "IPY_MODEL_22fca5802b834baf8d349a0f51c0febf",
      "value": " 541M/541M [00:04&lt;00:00, 89.1MB/s]"
     }
    },
    "faf432c7ccd84d25834f852069db1113": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbd86e127f964081957643f20c3f28fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d9017fb0936420ba3bb9aabd68f21fe",
      "placeholder": "​",
      "style": "IPY_MODEL_3d14824c8aa04bc0ab6517b1968f9afc",
      "value": " 175M/175M [00:05&lt;00:00, 36.0MB/s]"
     }
    },
    "fbf0e5cf51374c0ab505b35386e48d59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bd66c9d0d7dc4d8cb3ccaf3f71f44698",
       "IPY_MODEL_85a7df6412b54bbeb15eba4b9765787e",
       "IPY_MODEL_2c367e5b50b34f0c89fc27067eb73be8"
      ],
      "layout": "IPY_MODEL_e55678f7981d4af6b371b2615609ce9b"
     }
    },
    "fd2ed96c8faa4b5abe527042fc33f197": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2c6c1279df648f8a737bd6aacea9d09",
      "placeholder": "​",
      "style": "IPY_MODEL_37a511e1a79c4c37843f2fb44fc8348e",
      "value": "Downloading data files: 100%"
     }
    },
    "fd91a05872ec420ca308474a6471a921": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad81f61ce6df4b3295613a5fed6ba6a8",
      "placeholder": "​",
      "style": "IPY_MODEL_2e10b8c62de9419493f8ee4714e27ac0",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
